{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mutformer_run_pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRCkU78mPzra"
      },
      "source": [
        "Note: If using a TPU from Google Cloud (not the Colab TPU), make sure to run this notebook on a VM with access to all GCP APIs, and make sure TPUs are enabled for the GCP project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3MXrOYYTnZv"
      },
      "source": [
        "Note: Run multiple copies of this notebook in multiple VMs to train multiple models in parallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_"
      },
      "source": [
        "# Configure settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozmx1LCLw3SQ"
      },
      "source": [
        "#@markdown ## General Config\n",
        "USE_GCP_TPU = False #@param {type:\"boolean\"}\n",
        "MAX_SEQ_LENGTH =  1024#@param {type:\"integer\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "DO_LOWER_CASE = False #@param {type:\"boolean\"}\n",
        "PROCESSES = 2 #@param {type:\"integer\"}\n",
        "BUCKET_NAME = \"theodore_jiang\" #@param {type:\"string\"}\n",
        "MODEL_DIR_format = \"bert_model_xxx\" #@param {type:\"string\"}\n",
        "#@markdown ###### The model identifier (replaces xxx in MODEL_DIR_format)\n",
        "MODEL_ID = \"modified_large_v2\" #@param {type:\"string\"}\n",
        "PRETRAINING_DATA_DIR = \"pretraining_data_1024_modified_large_v2\" #@param {type:\"string\"}\n",
        "LOGGING_DIR = \"bert_model_pretraining_loss_spam\" #@param {type:\"string\"}\n",
        "#@markdown ######for miscellaneous temporary storage (MUST BE SAME NAME AS USED IN DATA GENERATION SCRIPT)\n",
        "TEMP_DIR = \"modified_large_v2_temp\" #@param {type:\"string\"}\n",
        "RUN_NAME = \"bert_model_modified_large_v2\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Input data pipeline config\n",
        "DATA_COPIES = 20 #@param {type:\"integer\"}\n",
        "TRAIN_BATCH_SIZE =  32 #@param {type:\"integer\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "#@markdown ######When checking data, how long to wait between each check (to minimize interaction with GCS, should be around the same time it takes for the data generation script to generate 1 epoch worth of data)\n",
        "CHECK_DATA_EVERY_N_SECS = 1200 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Training procedure config\n",
        "EVAL_BATCH_SIZE = 64\n",
        "INIT_LEARNING_RATE =  2e-5#@param {type:\"number\"}\n",
        "END_LEARNING_RATE = 1e-9\n",
        "SAVE_CHECKPOINTS_STEPS =  1000#@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8\n",
        "PLANNED_TOTAL_SEQUENCES_SEEN =  1e9 #@param {type:\"number\"}\n",
        "#@markdown ###### (PLANNED_TOTAL_STEPS will override PLANNED_TOTAL_SEQUENCES_SEEN; if you wish to use PLANNED_TOTAL_SEQUENCES_SEEN, set PLANNED_TOTAL_STEPS to -1)\n",
        "PLANNED_TOTAL_STEPS =  2e6#@param {type:\"number\"}\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_SEQUENCES_SEEN/TRAIN_BATCH_SIZE if PLANNED_TOTAL_STEPS==-1 else PLANNED_TOTAL_STEPS\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/PLANNED_TOTAL_STEPS\n",
        "#@markdown ## Model Config:\n",
        "#@markdown ######Possible values for MODEL_TO_USE: orig, Mutformerv1:\n",
        "MODEL_TO_USE = \"Mutformerv2\" #@param {type:\"string\"}\n",
        "HIDDEN_SIZE =   768#@param {type:\"integer\"}\n",
        "HIDDEN_LAYERS =  12#@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "CUSTOM_MODEL = None #### <<<<< change this to a class usable by a model_fn style\n",
        "                    ####       function if you wish to use a custom model (see\n",
        "                    ####       modeling.py for BertModel class and\n",
        "                    ####       run_pretraining.py for model_fn_builder function)\n",
        "bert_config = {\n",
        "  \"hidden_size\": HIDDEN_SIZE, \n",
        "  \"hidden_act\": \"gelu\", \n",
        "  \"initializer_range\": 0.02, \n",
        "  \"hidden_dropout_prob\": 0.1, \n",
        "  \"num_attention_heads\": HIDDEN_LAYERS, \n",
        "  \"type_vocab_size\": 2, \n",
        "  \"max_position_embeddings\": MAX_SEQ_LENGTH, \n",
        "  \"num_hidden_layers\": HIDDEN_LAYERS, \n",
        "  \"intermediate_size\": 3072, \n",
        "  \"attention_probs_dropout_prob\": 0.1\n",
        "}\n",
        "\n",
        "vocab = \\\n",
        "'''[PAD]\n",
        "[UNK]\n",
        "[CLS]\n",
        "[SEP]\n",
        "[MASK]\n",
        "L\n",
        "S\n",
        "B\n",
        "J\n",
        "E\n",
        "A\n",
        "P\n",
        "T\n",
        "G\n",
        "V\n",
        "K\n",
        "R\n",
        "D\n",
        "Q\n",
        "I\n",
        "N\n",
        "F\n",
        "H\n",
        "Y\n",
        "C\n",
        "M\n",
        "W'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMeXHe0mPDwY"
      },
      "source": [
        "#If running on a GCP TPU, use these commands prior to running this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqoH1BZfkOJE"
      },
      "source": [
        "To ssh into the VM:\n",
        "\n",
        "```\n",
        "gcloud beta compute ssh --zone <COMPUTE ZONE> <VM NAME> --project <PROJECT NAME> -- -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "Make sure the port above matches the port below (in this case it's 8888)\n",
        "\n",
        "```\n",
        "sudo apt-get update\n",
        "sudo apt-get -y install python3 python3-pip\n",
        "sudo apt-get install pkg-config\n",
        "sudo apt-get install libhdf5-serial-dev\n",
        "sudo apt-get install libffi6 libffi-dev\n",
        "sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm\n",
        "sudo -H pip3 install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "\n",
        "(one command):sudo apt-get update ; sudo apt-get -y install python3 python3-pip ; sudo apt-get install pkg-config ; sudo apt-get -y install libhdf5-serial-dev ; sudo apt-get install libffi6 libffi-dev; sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm ; sudo -H pip3 install jupyter_http_over_ws ; jupyter serverextension enable --py jupyter_http_over_ws ; jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "And then copy and paste the outputted link with \"locahost: ...\" into the colab connect to local runtime option\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AKPxJa2kSo6"
      },
      "source": [
        "###Also run this code segment, which creates a TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bieoa9XIPMXx"
      },
      "source": [
        "GCE_PROJECT_NAME = \"genome-project-319100\" #@param {type:\"string\"}\n",
        "TPU_ZONE = \"us-central1-f\" #@param {type:\"string\"}\n",
        "TPU_NAME = \"mutformer-tpu\" #@param {type:\"string\"}\n",
        "\n",
        "!gcloud alpha compute tpus create $TPU_NAME --accelerator-type=tpu-v2 --version=1.15.5 --zone=$TPU_ZONE ##create new TPU\n",
        "\n",
        "!gsutil iam ch serviceAccount:`gcloud alpha compute tpus describe $TPU_NAME | grep serviceAccount | cut -d' ' -f2`:admin gs://theodore_jiang && echo 'Successfully set permissions!' ##give TPU access to GCS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O8Q2nFs5RHb"
      },
      "source": [
        "#Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5whu5PjE5Q56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9c7fc1-f40d-40be-a0c7-f82ee42d53f2"
      },
      "source": [
        "if USE_GCP_TPU:\n",
        "  !sudo apt-get -y install git\n",
        "#@markdown ######where to clone the repo into (only value that it can't be is \"mutformer\"):\n",
        "REPO_DESTINATION_PATH = \"code/mutformer\" #@param {type:\"string\"}\n",
        "import os,shutil\n",
        "if not os.path.exists(REPO_DESTINATION_PATH):\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "else:\n",
        "  shutil.rmtree(REPO_DESTINATION_PATH)\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "cmd = \"git clone https://github.com/WGLab/mutformer.git \\\"\" + REPO_DESTINATION_PATH + \"\\\"\"\n",
        "!{cmd}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code/mutformer'...\n",
            "remote: Enumerating objects: 427, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 427 (delta 161), reused 27 (delta 27), pack-reused 199\u001b[K\n",
            "Receiving objects: 100% (427/427), 1.99 MiB | 13.65 MiB/s, done.\n",
            "Resolving deltas: 100% (272/272), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj1mClhQQE_n"
      },
      "source": [
        "#Imports/Authenticate for GCP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc1bf81-b9d1-49cc-81b9-5b4d5d01d520"
      },
      "source": [
        "if not USE_GCP_TPU:\n",
        "  %tensorflow_version 1.x\n",
        "  from google.colab import auth\n",
        "  print(\"Authorize for GCS:\")\n",
        "  auth.authenticate_user()\n",
        "  print(\"Authorize done\")\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import tensorflow.compat.v1 as tf\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if not os.path.exists(\"mutformer\"):\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "else:\n",
        "  shutil.rmtree(\"mutformer\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "if \"mutformer\" in sys.path:\n",
        "  sys.path.remove(\"mutformer\")\n",
        "sys.path.append(\"mutformer\")\n",
        "\n",
        "from mutformer import modeling, optimization, tokenization\n",
        "from mutformer.modeling import BertModel,BertModelModified,MutFormer\n",
        "from mutformer.run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "if MODEL_TO_USE==\"orig\":\n",
        "  MODEL = BertModel\n",
        "  print(\"Using model: orig\")\n",
        "elif MODEL_TO_USE == \"Mutformerv1\":\n",
        "  MODEL = BertModelModified\n",
        "  print(\"Using model: Mutformerv1\")\n",
        "elif MODEL_TO_USE == \"Mutformerv2\":\n",
        "  MODEL = MutFormer\n",
        "  print(\"Using model: Mutformerv2\")\n",
        "else:\n",
        "  raise Exception(\"The model specified was not one of the available models: [\\\"orig\\\", \\\"Mutformerv1\\\"].\")\n",
        "\n",
        "  \n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "log.handlers = []\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "#@markdown ###### Whether or not to write logs to a file\n",
        "DO_FILE_LOGGING = True #@param {type:\"boolean\"}\n",
        "if DO_FILE_LOGGING:\n",
        "  #@markdown ###### If using file logging, what path to write logs to\n",
        "  FILE_LOGGING_PATH = 'file_logging/spam.log' #@param {type:\"string\"}\n",
        "  if not os.path.exists(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1])):\n",
        "    os.makedirs(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1]))\n",
        "  fh = logging.FileHandler(FILE_LOGGING_PATH)\n",
        "  fh.setLevel(logging.INFO)\n",
        "  fh.setFormatter(formatter)\n",
        "  log.addHandler(fh)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "if USE_GCP_TPU:\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_NAME, zone=TPU_ZONE, project=GCE_PROJECT_NAME)\n",
        "  TPU_ADDRESS = tpu_cluster_resolver.get_master()\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "      log.info('TPU address is ' + TPU_ADDRESS)\n",
        "      # Upload credentials to TPU.\n",
        "      tf.contrib.cloud.configure_gcs(session)\n",
        "else:\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    log.info(\"Using TPU runtime\")\n",
        "    TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "    with tf.Session(TPU_ADDRESS) as session:\n",
        "      log.info('TPU address is ' + TPU_ADDRESS)\n",
        "      # Upload credentials to TPU.\n",
        "      with tf.gfile.Open('/content/adc.json', 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "      tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "      \n",
        "  else:\n",
        "    raise Exception('Not connected to TPU runtime, TPU required to run mutformer')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-10 21:49:37,341 - tensorflow - INFO - Using TPU runtime\n",
            "2021-12-10 21:49:37,343 - tensorflow - INFO - TPU address is grpc://10.82.169.26:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authorize for GCS:\n",
            "Authorize done\n",
            "Using model: Mutformerv2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb0TXw9GtCKz"
      },
      "source": [
        "#Auto Detect amount of train steps per epoch in the source data/Mount Drive if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYsYBUCJMTdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf404e58-7b53-4f78-db96-0dd6c665e3a8"
      },
      "source": [
        "#@markdown ###### if not USE_GCP_TPU and data was stored in drive, folder where the original data was stored (if data was stored in GCS or USE_GCP_TPU is true, leave this item blank)\n",
        "data_folder = \"/content/drive/My Drive/BERT pretraining/mutformer_pretraining_data\" #@param {type: \"string\"}\n",
        "\n",
        "if not USE_GCP_TPU and \"/content/drive\" in data_folder:\n",
        "  from google.colab import drive\n",
        "  !fusermount -u /content/drive\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  DRIVE_PATH = \"/content/drive/My Drive\"\n",
        "\n",
        "  data_path_train = data_folder+\"/train.txt\" \n",
        "\n",
        "  lines = tf.gfile.Open(data_path_train).read().split(\"\\n\")\n",
        "  SEQUENCES_PER_EPOCH = len(lines)\n",
        "  STEPS_PER_EPOCH = int(SEQUENCES_PER_EPOCH/TRAIN_BATCH_SIZE)\n",
        "\n",
        "  print(\"sequences per epoch:\",SEQUENCES_PER_EPOCH, \"steps per epoch:\",STEPS_PER_EPOCH)\n",
        "else:\n",
        "  from tqdm import tqdm\n",
        "  def steps_getter(input_files):\n",
        "    tot_sequences = 0\n",
        "    for input_file in input_files:\n",
        "      print(\"reading:\",input_file)\n",
        "\n",
        "      d = tf.data.TFRecordDataset(input_file)\n",
        "\n",
        "      with tf.Session() as sess:\n",
        "        tot_sequences+=sess.run(d.reduce(0, lambda x,_: x+1))\n",
        "\n",
        "    return tot_sequences\n",
        "\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "  got_data = False\n",
        "  while not got_data: ##will keep trying to access the data until available\n",
        "    for f in range(0,DATA_COPIES):\n",
        "        DATA_GCS_DIR_train = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DATA_DIR+\"/\"+str(f))\n",
        "        train_input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR_train,'*tfrecord'))\n",
        "        print(\"Using:\",train_input_files)\n",
        "        if len(train_input_files)>0:\n",
        "          got_data = True\n",
        "          try:\n",
        "            SEQUENCES_PER_EPOCH = steps_getter(train_input_files)\n",
        "            STEPS_PER_EPOCH = int(SEQUENCES_PER_EPOCH/TRAIN_BATCH_SIZE)\n",
        "            print(\"sequences per epoch:\",SEQUENCES_PER_EPOCH, \"steps per epoch:\",STEPS_PER_EPOCH)\n",
        "            break\n",
        "          except:\n",
        "            got_data=False\n",
        "    if got_data:\n",
        "      break\n",
        "    print(\"Could not find data, waiting for data generation...trying again in another \"+str(CHECK_DATA_EVERY_N_SECS)+\" seconds.\")\n",
        "    time.sleep(CHECK_DATA_EVERY_N_SECS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n",
            "sequences per epoch: 150533 steps per epoch: 4704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0ZQ6OJXjXMp"
      },
      "source": [
        "#Upload config to GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8re3mRujW3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ec50da-f545-4e9f-c286-0ab500220c35"
      },
      "source": [
        "bert_config[\"vocab_size\"] = len(vocab.split(\"\\n\"))\n",
        "\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.makedirs(MODEL_DIR)\n",
        "with tf.gfile.Open(\"{}/config.json\".format(MODEL_DIR), \"w\") as fo:\n",
        "  json.dump(bert_config, fo, indent=2)\n",
        "\n",
        "!gsutil -m cp -r $MODEL_DIR gs://$BUCKET_NAME"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://bert_model_modified_large_v2/config.json [Content-Type=application/json]...\n",
            "/ [1/1 files][  310.0 B/  310.0 B] 100% Done                                    \n",
            "Operation completed over 1 objects/310.0 B.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkFC96e0cK6n"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCuEbr6dv8U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "709493bb-95b6-4d7f-e917-187e0ed4f568"
      },
      "source": [
        "import time\n",
        "\n",
        "operating_files = [\"available_indexes\",\"epoch\"]\n",
        "\n",
        "def download_tmp_files(operating_files): ##for downloading tmp files from drive or GCS\n",
        "  for op_file in operating_files:\n",
        "    if USE_GCP_TPU or \"/content/drive\" in data_folder: ##If using GCP TPU, drive isn't available, so we need to store temporary files in GCS\n",
        "      cmd = \"gsutil -m cp -r gs://\"+BUCKET_NAME+\"/\"+TEMP_DIR+\"/\"+op_file+\".txt \"+TEMP_DIR+\"/\"+op_file+\".txt\"\n",
        "      !{cmd}\n",
        "    else:\n",
        "      shutil.copy(DRIVE_PATH+\"/\"+TEMP_DIR+\"/\"+op_file+\".txt\",TEMP_DIR+\"/\"+op_file+\".txt\")\n",
        "\n",
        "def upload_tmp_files(operating_files): ##for uploading tmp files to drive or GCS\n",
        "  for op_file in operating_files:\n",
        "    if USE_GCP_TPU or \"/content/drive\" in data_folder: ##doing the same thing as above^^\n",
        "      cmd = \"gsutil -m cp -r \"+TEMP_DIR+\"/\"+op_file+\".txt gs://\"+BUCKET_NAME+\"/\"+TEMP_DIR+\"/\"+op_file+\".txt\"\n",
        "      !{cmd}\n",
        "    else:\n",
        "      shutil.copy(TEMP_DIR+\"/\"+op_file+\".txt\",DRIVE_PATH+\"/\"+TEMP_DIR+\"/\"+op_file+\".txt\")\n",
        "\n",
        "download_tmp_files(operating_files)\n",
        "\n",
        "if os.path.exists(TEMP_DIR+\"/epoch.txt\"): ##detect the current epoch\n",
        "  current_epoch = int(tf.gfile.Open(TEMP_DIR+\"/epoch.txt\").read())\n",
        "else:\n",
        "  current_epoch=0\n",
        "\n",
        "\n",
        "BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "GCS_LOGGING_DIR = \"{}/{}\".format(BUCKET_PATH, LOGGING_DIR+\"/\"+RUN_NAME)\n",
        "\n",
        "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"config.json\")\n",
        "\n",
        "while True: ##training loop\n",
        "  print(\"\\n\\n\\n\\n\\nEPOCH:\"+str(current_epoch)+\"\\n\\n\\n\\n\\n\\n\")\n",
        "  \n",
        "  got_data = False\n",
        "  while not got_data:\n",
        "    for f in range(0,DATA_COPIES): ##try to access any of the data bins\n",
        "      print(\"trying to access training data from saved sector number \"+str(f))\n",
        "      DATA_GCS_DIR_train = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DATA_DIR+\"/\"+str(f))\n",
        "      train_input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR_train,'*tfrecord'))\n",
        "      print(\"train_input_files:\",train_input_files)\n",
        "      if len(train_input_files)>0:\n",
        "        got_data = True\n",
        "        break\n",
        "      else:\n",
        "        current_available_indexes = tf.gfile.Open(TEMP_DIR+\"/available_indexes.txt\").read().split(\"\\n\")[:-1]\n",
        "        print(\"current:\",current_available_indexes)\n",
        "\n",
        "        new_inds = \"\"\n",
        "        for ind in current_available_indexes:\n",
        "          if int(ind) != f:\n",
        "            new_inds += ind +\"\\n\"\n",
        "        print(\"new_inds\",new_inds)\n",
        "        tf.gfile.Open(TEMP_DIR+\"/available_indexes.txt\",\"w+\").write(new_inds)\n",
        "    upload_tmp_files([\"available_indexes\"])\n",
        "    if not got_data:\n",
        "      time.sleep(CHECK_DATA_EVERY_N_SECS)\n",
        "        \n",
        "\n",
        "  INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "  try:\n",
        "    INIT_CHECKPOINT_STEP = INIT_CHECKPOINT.split(\"-\")[-1]\n",
        "    print(\"CURRENT STEP:\",INIT_CHECKPOINT_STEP)\n",
        "    if int(INIT_CHECKPOINT_STEP)>=PLANNED_TOTAL_STEPS: ##if reached planed total steps, stop\n",
        "      break\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "\n",
        "  log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "  log.info(\"Using {} data shards for training\".format(len(train_input_files)))\n",
        "  model_fn = model_fn_builder(\n",
        "      bert_config=config,\n",
        "      logging_dir=GCS_LOGGING_DIR,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      init_learning_rate=INIT_LEARNING_RATE,\n",
        "      decay_per_step=DECAY_PER_STEP,\n",
        "      num_warmup_steps=10,\n",
        "      use_tpu=True,\n",
        "      use_one_hot_embeddings=True,\n",
        "      bert=MODEL)\n",
        "\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      model_dir=BERT_GCS_DIR,\n",
        "      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "          num_shards=NUM_TPU_CORES,\n",
        "          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=True,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=TRAIN_BATCH_SIZE,\n",
        "      eval_batch_size=EVAL_BATCH_SIZE)\n",
        "    \n",
        "  train_input_fn = input_fn_builder(\n",
        "          input_files=train_input_files,\n",
        "          max_seq_length=MAX_SEQ_LENGTH,\n",
        "          max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "          is_training=True)\n",
        "  try:\n",
        "    estimator.train(input_fn=train_input_fn, steps=STEPS_PER_EPOCH)\n",
        "    current_epoch+=1\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  # For dynamic masking, a parallel data generation is used. This portion deletes the current data and \n",
        "  # updates the list of available data via a txt (to minimize interaction with GCS) so that the data \n",
        "  # generation algortihm can generate the data with different masking positions \n",
        "  cmd = \"gsutil -m rm -r \"+DATA_GCS_DIR_train\n",
        "  !{cmd}\n",
        "  current_available_indexes = tf.gfile.Open(TEMP_DIR+\"/available_indexes.txt\").read().split(\"\\n\")[:-1]\n",
        "  print(\"current:\",current_available_indexes)\n",
        "\n",
        "  new_inds = \"\"\n",
        "  for ind in current_available_indexes:\n",
        "    if int(ind) != f:\n",
        "      new_inds += ind +\"\\n\"\n",
        "  print(\"new_inds\",new_inds)\n",
        "  tf.gfile.Open(TEMP_DIR+\"/available_indexes.txt\",\"w+\").write(new_inds)\n",
        "  tf.gfile.Open(TEMP_DIR+\"/epoch.txt\",\"w+\").write(str(current_epoch))\n",
        "  upload_tmp_files(operating_files)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://theodore_jiang/modified_large_v2_temp/available_indexes.txt...\n",
            "/ [0/1 files][    0.0 B/   42.0 B]   0% Done                                    \r/ [1/1 files][   42.0 B/   42.0 B] 100% Done                                    \r\n",
            "Operation completed over 1 objects/42.0 B.                                       \n",
            "CommandException: No URLs matched: gs://theodore_jiang/modified_large_v2_temp/epoch.txt\n",
            "CommandException: 1 file/object could not be transferred.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "EPOCH:0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "trying to access training data from saved sector number 0\n",
            "train_input_files: []\n",
            "current: ['4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
            "new_inds 4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "\n",
            "trying to access training data from saved sector number 1\n",
            "train_input_files: ['gs://theodore_jiang/pretraining_data_1024_modified_large_v2/1/shard_0.tfrecord']\n",
            "Copying file://modified_large_v2_temp/available_indexes.txt [Content-Type=text/plain]...\n",
            "/ [1/1 files][   42.0 B/   42.0 B] 100% Done                                    \n",
            "Operation completed over 1 objects/42.0 B.                                       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-10 21:49:52,541 - tensorflow - WARNING - From /content/mutformer/modeling.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "2021-12-10 21:49:53,079 - tensorflow - INFO - Using checkpoint: None\n",
            "2021-12-10 21:49:53,080 - tensorflow - INFO - Using 1 data shards for training\n",
            "2021-12-10 21:49:54,086 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f87ac2c9680>) includes params argument, but params are not passed to Estimator.\n",
            "2021-12-10 21:49:54,088 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_modified_large_v2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.82.169.26:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f881e9d5050>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.82.169.26:8470', '_evaluation_master': 'grpc://10.82.169.26:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f881e9bfed0>}\n",
            "2021-12-10 21:49:54,090 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2021-12-10 21:49:54,091 - tensorflow - INFO - Querying Tensorflow master (grpc://10.82.169.26:8470) for TPU system metadata.\n",
            "2021-12-10 21:49:54,108 - tensorflow - INFO - Found TPU system:\n",
            "2021-12-10 21:49:54,109 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2021-12-10 21:49:54,110 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2021-12-10 21:49:54,112 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2021-12-10 21:49:54,113 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 791429300759548201)\n",
            "2021-12-10 21:49:54,114 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13421168695563710885)\n",
            "2021-12-10 21:49:54,115 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 14250240054759611841)\n",
            "2021-12-10 21:49:54,116 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3129788427424487024)\n",
            "2021-12-10 21:49:54,117 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5008547424272168907)\n",
            "2021-12-10 21:49:54,118 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14442936030835599399)\n",
            "2021-12-10 21:49:54,119 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11661339757049622426)\n",
            "2021-12-10 21:49:54,120 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3080905597651785981)\n",
            "2021-12-10 21:49:54,121 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17454030403055813631)\n",
            "2021-12-10 21:49:54,122 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12342719583448794898)\n",
            "2021-12-10 21:49:54,131 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11230540237091807105)\n",
            "2021-12-10 21:49:54,144 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2021-12-10 21:49:54,146 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2021-12-10 21:49:54,304 - tensorflow - INFO - Calling model_fn.\n",
            "2021-12-10 21:49:54,306 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:314: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2021-12-10 21:49:54,314 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:343: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "2021-12-10 21:49:54,316 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "2021-12-10 21:49:54,341 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:360: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2021-12-10 21:49:54,343 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2021-12-10 21:49:54,355 - tensorflow - WARNING - Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f8821aa2e60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2021-12-10 21:49:54,356 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:368: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2021-12-10 21:49:54,373 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:375: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-12-10 21:49:54,457 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:35: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "2021-12-10 21:49:54,459 - tensorflow - INFO - *** Features ***\n",
            "2021-12-10 21:49:54,461 - tensorflow - INFO -   name = input_ids, shape = (4, 1024)\n",
            "2021-12-10 21:49:54,462 - tensorflow - INFO -   name = input_mask, shape = (4, 1024)\n",
            "2021-12-10 21:49:54,463 - tensorflow - INFO -   name = masked_lm_ids, shape = (4, 20)\n",
            "2021-12-10 21:49:54,464 - tensorflow - INFO -   name = masked_lm_positions, shape = (4, 20)\n",
            "2021-12-10 21:49:54,467 - tensorflow - INFO -   name = masked_lm_weights, shape = (4, 20)\n",
            "2021-12-10 21:49:54,468 - tensorflow - INFO -   name = segment_ids, shape = (4, 1024)\n",
            "2021-12-10 21:49:54,470 - tensorflow - WARNING - From /content/mutformer/modeling.py:417: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2021-12-10 21:49:54,474 - tensorflow - WARNING - From /content/mutformer/modeling.py:657: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2021-12-10 21:49:54,510 - tensorflow - WARNING - From /content/mutformer/modeling.py:738: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f8821aa2e60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-10 21:49:54,566 - tensorflow - WARNING - From /content/mutformer/modeling.py:606: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2021-12-10 21:49:54,740 - tensorflow - WARNING - From /content/mutformer/modeling.py:989: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2021-12-10 21:49:54,742 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2021-12-10 21:49:57,507 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:62: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "2021-12-10 21:49:57,509 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2021-12-10 21:49:57,510 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768)\n",
            "2021-12-10 21:49:57,511 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "2021-12-10 21:49:57,512 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768)\n",
            "2021-12-10 21:49:57,513 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,515 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,516 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768)\n",
            "2021-12-10 21:49:57,517 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,518 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768)\n",
            "2021-12-10 21:49:57,519 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,520 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/kernel:0, shape = (3, 768, 768)\n",
            "2021-12-10 21:49:57,521 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,523 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/kernel:0, shape = (3, 768, 768)\n",
            "2021-12-10 21:49:57,524 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,525 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,526 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,527 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,529 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,530 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,531 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,532 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,533 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,534 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,535 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,537 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,538 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,540 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,541 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,542 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,544 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,545 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,546 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,547 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,548 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,550 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,551 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,552 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,554 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,555 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,556 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,557 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,558 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,559 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,560 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,561 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,562 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,564 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,565 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,566 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,567 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,569 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,570 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,571 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,572 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,573 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,574 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,575 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,576 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,578 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,579 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,580 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,581 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,582 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,583 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,585 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,586 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,587 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,588 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,589 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,591 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,592 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,593 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,594 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,595 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,596 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,597 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,598 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,600 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,600 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,601 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,602 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,603 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,605 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,606 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,607 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,608 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,610 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,611 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,612 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,614 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,615 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,617 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,618 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,619 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,620 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,621 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,623 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,624 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,625 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,626 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,627 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,629 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,630 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,631 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,632 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,633 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,634 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,635 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,637 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,638 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,640 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,641 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,642 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,643 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,644 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,645 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,646 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,648 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,649 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,650 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,651 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,652 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,655 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,656 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,657 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,658 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,659 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,660 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,660 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,662 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,663 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,664 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,665 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,666 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,667 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,668 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,669 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,670 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,671 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,673 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,674 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,675 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,676 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,677 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,678 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,679 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,681 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,682 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,683 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,685 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,686 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,687 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,688 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,689 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,691 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,692 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,693 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,694 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,695 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,696 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,697 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,699 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,700 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,701 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,702 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,704 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,705 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,706 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,707 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,709 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,709 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,711 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,712 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,713 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,714 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,716 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,717 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,718 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,719 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,720 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,721 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,723 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,725 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,726 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,727 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,729 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,729 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,731 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,732 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,733 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,734 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,735 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,736 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,737 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,738 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,739 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,740 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,741 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,742 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,744 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,745 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2021-12-10 21:49:57,746 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "2021-12-10 21:49:57,747 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "2021-12-10 21:49:57,749 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,750 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,751 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,752 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,753 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,754 - tensorflow - INFO -   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "2021-12-10 21:49:57,755 - tensorflow - INFO -   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "2021-12-10 21:49:57,756 - tensorflow - INFO -   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "2021-12-10 21:49:57,757 - tensorflow - INFO -   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "2021-12-10 21:49:57,759 - tensorflow - INFO -   name = cls/predictions/output_bias:0, shape = (27,)\n",
            "2021-12-10 21:49:57,760 - tensorflow - WARNING - From /content/mutformer/run_pretraining.py:87: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2021-12-10 21:49:58,103 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2021-12-10 21:50:01,919 - tensorflow - INFO - training_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing gs://theodore_jiang/pretraining_data_1024_modified_large_v2/1/shard_0.tfrecord#1639107182994457...\n",
            "/ [1/1 objects] 100% Done                                                       \n",
            "Operation completed over 1 objects.                                              \n",
            "current: ['4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
            "new_inds 4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "\n",
            "Copying file://modified_large_v2_temp/available_indexes.txt [Content-Type=text/plain]...\n",
            "/ [1/1 files][   42.0 B/   42.0 B] 100% Done                                    \n",
            "Operation completed over 1 objects/42.0 B.                                       \n",
            "Copying file://modified_large_v2_temp/epoch.txt [Content-Type=text/plain]...\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "Exception in UIThread: \n",
            "^C\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "EPOCH:0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "trying to access training data from saved sector number 0\n",
            "train_input_files: []\n",
            "current: ['4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
            "new_inds 4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "\n",
            "trying to access training data from saved sector number 1\n",
            "train_input_files: []\n",
            "current: ['4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
            "new_inds 4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "\n",
            "trying to access training data from saved sector number 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3707f36609bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trying to access training data from saved sector number \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mDATA_GCS_DIR_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUCKET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRETRAINING_DATA_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0mtrain_input_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_GCS_DIR_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*tfrecord'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_input_files:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_input_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfilesystem\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mlisting\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m   \"\"\"\n\u001b[0;32m--> 363\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_matching_files_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         for matching_filename in pywrap_tensorflow.GetMatchingFiles(\n\u001b[0;32m--> 384\u001b[0;31m             compat.as_bytes(pattern))\n\u001b[0m\u001b[1;32m    385\u001b[0m     ]\n\u001b[1;32m    386\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
