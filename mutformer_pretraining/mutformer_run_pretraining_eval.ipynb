{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mutformer_run_pretraining_eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax01prh8N_AC"
      },
      "source": [
        "Note: If using a TPU from Google Cloud (not the Colab TPU), make sure to run this notebook on a VM with access to all GCP APIs, and make sure TPUs are enabled for the GCP project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCSKVkPiYFHs"
      },
      "source": [
        "This file can evaluate in parallel multiple models at the same time. However, if more frequent evaluations on more models are desired, run multiple copies of this notebook in multiple VMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_"
      },
      "source": [
        "# Configure settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozmx1LCLw3SQ"
      },
      "source": [
        "#@markdown ### General Config\n",
        "USE_GCP_TPU = False #@param {type:\"boolean\"}\n",
        "MAX_SEQ_LENGTH =  1024 #@param {type:\"integer\"}\n",
        "PROCESSES = 2 #@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8 #@param {type:\"integer\"}\n",
        "BUCKET_NAME = \"theodore_jiang\" #@param {type:\"string\"}\n",
        "#@markdown ###### The name of the models to be evaluated (must correspond to the names saved from the pretraining script) Note: if multiple models need to be evaluated at the same time: xxx is the placeholder for the individual model identifier (if only one is being evaluated xxx will only placehold for that single model)\n",
        "MODEL_NAME_FORMAT = \"bert_model_xxx\" #@param {type:\"string\"}\n",
        "PRETRAINING_DIR = \"pretraining_data_1024\" #@param {type:\"string\"}\n",
        "EVAL_DIR = \"eval_data_1024\" #@param {type:\"string\"}\n",
        "TESTING_DIR = \"testing_data_1024\" #@param {type:\"string\"}\n",
        "#@markdown ###### Folder within EVAL_DIR for where evaluation results should be written to\n",
        "RUN_NAME_format = \"bert_model_xxx\" #@param {type:\"string\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Evaluation procedure config\n",
        "EVAL_TEST_BATCH_SIZE = 64 #@param {type:\"integer\"}\n",
        "#@markdown ######When checking for newly trained models during evaluation, how long to wait between each check (to minimize interaction with GCS, should be around the same time it takes for the training script to get train and save 1 checkpoint)\n",
        "CHECK_MODEL_EVERY_N_SECS = 600 #@param {type:\"integer\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hc9aPdWODjZ"
      },
      "source": [
        "#If running on a GCP TPU, use these commands prior to running this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5HqITT8OGmo"
      },
      "source": [
        "To ssh into the VM:\n",
        "\n",
        "```\n",
        "gcloud beta compute ssh --zone <COMPUTE ZONE> <VM NAME> --project <PROJECT NAME> -- -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "Make sure the port above matches the port below (in this case it's 8888)\n",
        "\n",
        "```\n",
        "sudo apt-get update\n",
        "sudo apt-get -y install python3 python3-pip\n",
        "sudo apt-get install pkg-config\n",
        "sudo apt-get install libhdf5-serial-dev\n",
        "sudo apt-get install libffi6 libffi-dev\n",
        "sudo -H pip3 install jupyter tensorflow google-api-python-client tqdm\n",
        "sudo -H pip3 install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "\n",
        "(one command):sudo apt-get update ; sudo apt-get -y install python3 python3-pip ; sudo apt-get install pkg-config ; sudo apt-get -y install libhdf5-serial-dev ; sudo apt-get install libffi6 libffi-dev; sudo -H pip3 install jupyter tensorflow google-api-python-client tqdm ; sudo -H pip3 install jupyter_http_over_ws ; jupyter serverextension enable --py jupyter_http_over_ws ; jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "And then copy and paste the outputted link with \"locahost: ...\" into the colab connect to local runtime option\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bME72K_8OJIY"
      },
      "source": [
        "###Also run this code segment, which creates a TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRLBsRo-OLqA"
      },
      "source": [
        "GCE_PROJECT_NAME = \"genome-project-319100\" #@param {type:\"string\"}\n",
        "TPU_ZONE = \"us-central1-f\" #@param {type:\"string\"}\n",
        "TPU_NAME = \"mutformer-tpu\" #@param {type:\"string\"}\n",
        "\n",
        "!gcloud alpha compute tpus create $TPU_NAME --accelerator-type=tpu-v2 --version=1.15.5 --zone=$TPU_ZONE ##create new TPU\n",
        "\n",
        "!gsutil iam ch serviceAccount:`gcloud alpha compute tpus describe $TPU_NAME | grep serviceAccount | cut -d' ' -f2`:admin gs://theodore_jiang && echo 'Successfully set permissions!' ##give TPU access to GCS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVqP04jiFF1"
      },
      "source": [
        "#Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SanOExwkiEC_"
      },
      "source": [
        "#@markdown ######where to clone the repo into (only value that it can't be is \"mutformer\"):\n",
        "REPO_DESTINATION_PATH = \"code/mutformer\" #@param {type:\"string\"}\n",
        "import os,shutil\n",
        "if not os.path.exists(REPO_DESTINATION_PATH):\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "else:\n",
        "  shutil.rmtree(REPO_DESTINATION_PATH)\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "cmd = \"git clone https://github.com/WGLab/mutformer.git \\\"\" + REPO_DESTINATION_PATH + \"\\\"\"\n",
        "!{cmd}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj1mClhQQE_n"
      },
      "source": [
        "#Imports/Authenticate for GCP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW"
      },
      "source": [
        "if not USE_GCP_TPU:\n",
        "  from google.colab import auth\n",
        "  print(\"Authorize for GCS:\")\n",
        "  auth.authenticate_user()\n",
        "  print(\"Authorize done\")\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if not os.path.exists(\"mutformer\"):\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "else:\n",
        "  shutil.rmtree(\"mutformer\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "if \"mutformer\" in sys.path:\n",
        "  sys.path.remove(\"mutformer\")\n",
        "sys.path.append(\"mutformer\")\n",
        "\n",
        "from mutformer import modeling, optimization, tokenization\n",
        "from mutformer.modeling import BertModel,BertModelModified\n",
        "from mutformer.run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "  \n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "log.handlers = []\n",
        "#@markdown ###### Whether or not to write logs to a file\n",
        "DO_FILE_LOGGING = False #@param {type:\"boolean\"}\n",
        "if DO_FILE_LOGGING:\n",
        "  #@markdown ###### If using file logging, what path to write logs to\n",
        "  FILE_LOGGING_PATH = '/content/drive/My Drive/spam.log' #@param {type:\"string\"}\n",
        "  fh = logging.FileHandler(FILE_LOGGING_PATH)\n",
        "  fh.setLevel(logging.INFO)\n",
        "  fh.setFormatter(formatter)\n",
        "  log.addHandler(fh)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "if USE_GCP_TPU:\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_NAME, zone=TPU_ZONE, project=GCE_PROJECT_NAME)\n",
        "  TPU_ADDRESS = tpu_cluster_resolver.get_master()\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "      log.info('TPU address is ' + TPU_ADDRESS)\n",
        "      # Upload credentials to TPU.\n",
        "      tf.contrib.cloud.configure_gcs(session)\n",
        "else:\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    log.info(\"Using TPU runtime\")\n",
        "    TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "    with tf.Session(TPU_ADDRESS) as session:\n",
        "      log.info('TPU address is ' + TPU_ADDRESS)\n",
        "      # Upload credentials to TPU.\n",
        "      with tf.gfile.Open('/content/adc.json', 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "      tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "      \n",
        "  else:\n",
        "    raise Exception('Not connected to TPU runtime, TPU required to run mutformer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzRqYyB-Mesv"
      },
      "source": [
        "#Auto Detect amount of train steps per epoch in the source data/Mount Drive if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYsYBUCJMTdz"
      },
      "source": [
        "#@markdown ###### Note: for all of these, if using USE_GCP_TPU, all of these parameters must use GCS, because a GCP TPU can't access google drive\n",
        "#@markdown \\#@markdown ###### if not USE_GCP_TPU and data was stored in drive, folder where the original data was stored (if data was stored in GCS or USE_GCP_TPU is true, leave this item blank)\n",
        "data_folder = \"/content/drive/My Drive/BERT pretraining/mutformer_pretraining_data\" #@param {type: \"string\"}\n",
        "BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "\n",
        "#@markdown whether to use GCS for writing eval results, if not, defaults to drive\n",
        "GCS_EVAL = False #@param {type:\"boolean\"}\n",
        "EVALS_PATH = BUCKET_PATH if GCS_EVAL else DRIVE_PATH\n",
        "\n",
        "if not USE_GCP_TPU and \"/content/drive\" in data_folder:\n",
        "  from google.colab import drive\n",
        "  !fusermount -u /content/drive\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  DRIVE_PATH = \"/content/drive/My Drive\"\n",
        "\n",
        "  data_path_train = drive_data_folder+\"/train.txt\" \n",
        "\n",
        "  lines = tf.gfile.Open(data_path_train).read().split(\"\\n\")\n",
        "  SEQUENCES_PER_EPOCH = len(lines)\n",
        "  STEPS_PER_EPOCH = int(SEQUENCES_PER_EPOCH/TRAIN_BATCH_SIZE)\n",
        "\n",
        "  print(\"sequences per epoch:\",SEQUENCES_PER_EPOCH, \"steps per epoch:\",STEPS_PER_EPOCH)\n",
        "else:\n",
        "  from tqdm import tqdm\n",
        "  def steps_getter(input_files):\n",
        "    tot_sequences = 0\n",
        "    for input_file in input_files:\n",
        "      print(\"reading:\",input_file)\n",
        "\n",
        "      d = tf.data.TFRecordDataset(input_file)\n",
        "\n",
        "      with tf.Session() as sess:\n",
        "        tot_sequences+=sess.run(d.reduce(0, lambda x,_: x+1))\n",
        "\n",
        "    return tot_sequences\n",
        "\n",
        "  got_data = False\n",
        "  while not got_data: ##will keep trying to access the data until available\n",
        "    for f in range(0,DATA_COPIES):\n",
        "        DATA_GCS_DIR_train = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR+\"/\"+str(f))\n",
        "        train_input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR_train,'*tfrecord'))\n",
        "        print(\"Using:\",train_input_files)\n",
        "        if len(train_input_files)>0:\n",
        "          got_data = True\n",
        "          try:\n",
        "            SEQUENCES_PER_EPOCH = steps_getter(train_input_files)\n",
        "            STEPS_PER_EPOCH = int(SEQUENCES_PER_EPOCH/TRAIN_BATCH_SIZE)\n",
        "            print(\"sequences per epoch:\",SEQUENCES_PER_EPOCH, \"steps per epoch:\",STEPS_PER_EPOCH)\n",
        "            break\n",
        "          except:\n",
        "            got_data=False\n",
        "    if got_data:\n",
        "      break\n",
        "    print(\"Could not find data, waiting for data generation...trying again in another \"+str(CHECK_DATA_EVERY_N_SECS)+\" seconds.\")\n",
        "    time.sleep(CHECK_MODEL_EVERY_N_SECS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhZV6JNh3Qxg"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3V5T3cT9-Bl"
      },
      "source": [
        "###Evaluation operation definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stkmJtg2tnyR"
      },
      "source": [
        "def reload_ckpt(model_dir,logging_dir,current_ckpt,model,data_dir):\n",
        "  BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, model_dir)\n",
        "\n",
        "  CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"config.json\")\n",
        "\n",
        "  INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "  print(\"init chkpt:\",INIT_CHECKPOINT)\n",
        "  print(\"current chkpt:\",current_ckpt)\n",
        "  if INIT_CHECKPOINT != current_ckpt:\n",
        "    config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "    test_input_files = tf.gfile.Glob(os.path.join(data_dir,'*tfrecord'))\n",
        "    log.info(\"Using {} data shards for testing\".format(len(test_input_files)))\n",
        "    model_fn = model_fn_builder(\n",
        "          bert_config=config,\n",
        "          init_checkpoint=INIT_CHECKPOINT,\n",
        "          init_learning_rate=0,\n",
        "          decay_per_step=0,\n",
        "          num_warmup_steps=10,\n",
        "          use_tpu=True,\n",
        "          use_one_hot_embeddings=True,\n",
        "          bert=model)\n",
        "\n",
        "    \n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "    run_config = tf.contrib.tpu.RunConfig(\n",
        "        cluster=tpu_cluster_resolver,\n",
        "        model_dir=BERT_GCS_DIR,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "            num_shards=NUM_TPU_CORES,\n",
        "            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "    estimator = tf.contrib.tpu.TPUEstimator(\n",
        "        use_tpu=True,\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        train_batch_size=1,\n",
        "        eval_batch_size=EVAL_TEST_BATCH_SIZE)\n",
        "    \n",
        "    input_fn = input_fn_builder(\n",
        "        input_files=test_input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=False)\n",
        "    return INIT_CHECKPOINT,estimator,input_fn,True\n",
        "  else:\n",
        "    return None,None,None,False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAVF8hSXHVv"
      },
      "source": [
        "###Run Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCuEbr6dv8U"
      },
      "source": [
        "#@markdown ###### whether to evaluate on the test set or the dev set (value can be \"test\" or \"dev\")\n",
        "dataset = \"test\" #@param{type:\"string\"}\n",
        "#@markdown ###### whether to continuously evaluate in a while loop\n",
        "REPEAT_EVAL = True #@param{type:\"boolean\"}\n",
        "#@markdown what folder to write evaluation results into \n",
        "EVALUATIONS_DIR = \"bert_model_pretraining_loss_spam\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if dataset==\"test\":\n",
        "  DATA_DIR = TESTING_DIR\n",
        "elif dataset==\"dev\":\n",
        "  DATA_DIR = EVAL_DIR\n",
        "else:\n",
        "  raise Exception(\"only datasets supported are dev and test\")\n",
        "\n",
        "#@markdown ######if running multiple models in parallel, which model identifiers to evaluate (Make sure to indicate the model architecture corresponding to teach model identifier in the dictionary in the code below)\n",
        "models_to_evaluate = [\"modified_large_v2\"] #@param #list of models to evaluate\n",
        "\n",
        "\n",
        "### vvv CHANGE THIS vvv\n",
        "\n",
        "name2model = {      ##dictionary mapping model architecture to each model name\n",
        "    \"modified\":BertModelModified,\n",
        "    \"modified_medium\":BertModelModified,\n",
        "    \"modified_large\":BertModelModified,\n",
        "    \"modified_largev2\":MutFormer,\n",
        "    \"orig\":BertModel,\n",
        "    \"large\":BertModel\n",
        "}\n",
        "\n",
        "### ^^^ CHANGE THIS ^^^\n",
        "\n",
        "\n",
        "def write_metrics(metrics,dir):\n",
        "  gs = metrics[\"global_step\"]\n",
        "  print(\"global step\",gs)\n",
        "\n",
        "  tf.disable_eager_execution()\n",
        "  tf.reset_default_graph()  \n",
        "  for key,value in metrics.items():\n",
        "    print(key,value)\n",
        "    x_scalar = tf.constant(value)\n",
        "    first_summary = tf.summary.scalar(name=key, tensor=x_scalar)\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        writer = tf.summary.FileWriter(dir)\n",
        "        sess.run(init)\n",
        "        summary = sess.run(first_summary)\n",
        "        writer.add_summary(summary, gs)\n",
        "        writer.flush()\n",
        "        print('Done with writing the scalar summary')\n",
        "    time.sleep(1)\n",
        "  if not os.path.exists(EVALS_PATH+\"/\"+dir):\n",
        "    os.makedirs(EVALS_PATH+\"/\"+dir)\n",
        "  if \"gs:\" in EVALS_PATH:\n",
        "    cmd = \"gsutil cp -r \\\"\"+dir+\"/.\\\" \\\"\"+EVALS_PATH+\"/\"+dir+\"\\\"\"\n",
        "  else:\n",
        "    cmd = \"cp -r \\\"\"+dir+\"/.\\\" \\\"\"+EVALS_PATH+\"/\"+dir+\"\\\"\"\n",
        "  !{cmd}\n",
        "\n",
        "current_ckpts = [\"N/A\" for i in range(len(models_to_evaluate))]\n",
        "\n",
        "total_metrics = {}\n",
        "\n",
        "while True:\n",
        "  for n,model in enumerate(models_to_evaluate):\n",
        "    MODEL_DIR = MODEL_NAME_FORMAT.replace(\"xxx\",model)\n",
        "    LOCAL_EVALUATIONS_DIR = \"{}/{}\".format(EVALUATIONS_DIR,RUN_NAME_format.replace(\"xxx\",model))\n",
        "    current_ckpt = current_ckpts[n]\n",
        "    current_ckpt,estimator,test_input_fn,new = reload_ckpt(MODEL_DIR,GCS_LOGGING_DIR,current_ckpt,name2model[model],BUCKET_PATH+\"/\"+DATA_DIR)\n",
        "    current_ckpts[n] = current_ckpt\n",
        "    if new:\n",
        "      print(\"\\n\\nEVALUATING \"+model+\" MODEL\\n\\n\")\n",
        "      log.info(\"Using checkpoint: {}\".format(current_ckpt))\n",
        "      metrics = estimator.evaluate(input_fn=test_input_fn, steps=(TEST_STEPS if dataset==\"test\" else EVAL_STEPS))\n",
        "      if REPEAT_EVAL:\n",
        "        write_metrics(metrics,LOCAL_EVALUATIONS_DIR)\n",
        "      else:\n",
        "        total_metrics[LOCAL_EVALUATIONS_DIR] = metrics\n",
        "\n",
        "  print(\"finished 1 eval loop\")\n",
        "  if not REPEAT_EVAL:\n",
        "    break\n",
        "  time.sleep(CHECK_MODEL_EVERY_N_SECS)\n",
        "if dataset == \"test\":\n",
        "  for logging_dir,metrics in total_metrics.items():\n",
        "    print(\"Printing metrics for:\",logging_dir,\"\\n\")\n",
        "    for key,metric in metrics.items():\n",
        "      print(key+\":\",metric)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
