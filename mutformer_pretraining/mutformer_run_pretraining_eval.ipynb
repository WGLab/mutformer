{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzJfcGJFJiEl"
      },
      "source": [
        "#Pretraining Evaluation script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rHK9_cjJlOi"
      },
      "source": [
        "This script evaluates pretrained models on protein sequences.\n",
        "\n",
        "Note: If using a TPU from Google Cloud (not the Colab TPU), make sure to run this notebook on a VM with access to all GCP APIs, and make sure TPUs are enabled for the GCP project\n",
        "\n",
        "This file can evaluate in parallel multiple models at the same time. However, if more frequent evaluations on more models are desired, run multiple copies of this notebook in multiple VMs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downgrade Python and Tensorflow \n",
        "\n",
        "(the default python version in Colab does not support Tensorflow 1.15)\n",
        "\n",
        "* **Note** that because the Python used in this notebook is not the default path, syntax highlighting most likely will not function."
      ],
      "metadata": {
        "id": "PZQPSwPNgJAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. First, download and install Python version 3.7:"
      ],
      "metadata": {
        "id": "mx3IeyygQD6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py37_22.11.1-1-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y jupyter\n",
        "!conda install -q -y google-colab -c conda-forge\n",
        "!python -m ipykernel install --name \"py37\" --user"
      ],
      "metadata": {
        "id": "_YSYC2wygIyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Then, reload the webpage (not restart runtime) to allow Colab to recognize the newly installed python\n",
        "####3. Finally, run the following commands to install tensorflow 1.15:"
      ],
      "metadata": {
        "id": "8Qx8I25bQHTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorflow==1.15"
      ],
      "metadata": {
        "id": "uSst1RI-QInD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_"
      },
      "source": [
        "# Configure settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozmx1LCLw3SQ"
      },
      "outputs": [],
      "source": [
        "#@markdown ### General Config\n",
        "GCP_RUNTIME = False #@param {type:\"boolean\"}\n",
        "PROCESSES = 2 #@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8 #@param {type:\"integer\"}\n",
        "#@markdown Name of the GCS bucket to use (Make sure to set this to the name of your own GCS  bucket):\n",
        "BUCKET_NAME = \"\" #@param {type:\"string\"}\n",
        "#@markdown Evaluation and testing data location:\n",
        "DATA_DIR = \"pretraining_data_1024_embedded_mutformer\" #@param {type:\"string\"}\n",
        "#@markdown What folder to write evaluation results into:\n",
        "EVALUATIONS_LOGS_DIR = \"mutformer2_0_pretraining_logs\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hc9aPdWODjZ"
      },
      "source": [
        "#If running on a GCP TPU, use these commands prior to running this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5HqITT8OGmo"
      },
      "source": [
        "To ssh into the VM:\n",
        "\n",
        "```\n",
        "gcloud beta compute ssh --zone <COMPUTE ZONE> <VM NAME> --project <PROJECT NAME> -- -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "Make sure the port above matches the port below (in this case it's 8888)\n",
        "\n",
        "```\n",
        "sudo apt-get update\n",
        "sudo apt-get -y install python3 python3-pip\n",
        "sudo apt-get install pkg-config\n",
        "sudo apt-get install libhdf5-serial-dev\n",
        "sudo apt-get install libffi6 libffi-dev\n",
        "sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm\n",
        "sudo -H pip3 install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "\n",
        "(one command):sudo apt-get update ; sudo apt-get -y install python3 python3-pip ; sudo apt-get install pkg-config ; sudo apt-get -y install libhdf5-serial-dev ; sudo apt-get install libffi6 libffi-dev; sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm ; sudo -H pip3 install jupyter_http_over_ws ; jupyter serverextension enable --py jupyter_http_over_ws ; jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "And then copy and paste the outputted link with \"locahost: ...\" into the colab connect to local runtime option\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bME72K_8OJIY"
      },
      "source": [
        "###Also run this code segment, which creates a TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRLBsRo-OLqA"
      },
      "outputs": [],
      "source": [
        "GCE_PROJECT_NAME = \"\" #@param {type:\"string\"}\n",
        "TPU_ZONE = \"us-central1-f\" #@param {type:\"string\"}\n",
        "TPU_NAME = \"mutformer-tpu\" #@param {type:\"string\"}\n",
        "\n",
        "!gcloud alpha compute tpus create $TPU_NAME --accelerator-type=tpu-v2 --version=1.15.5 --zone=$TPU_ZONE ##create new TPU\n",
        "\n",
        "!gsutil iam ch serviceAccount:`gcloud alpha compute tpus describe $TPU_NAME | grep serviceAccount | cut -d' ' -f2`:admin $BUCKET_PATH && echo 'Successfully set permissions!' ##give TPU access to GCS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVqP04jiFF1"
      },
      "source": [
        "#Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SanOExwkiEC_",
        "outputId": "86625375-6bee-49a7-af0e-34fedf9d9559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mutformer'...\n",
            "remote: Enumerating objects: 1217, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 1217 (delta 78), reused 56 (delta 46), pack-reused 1120\u001b[K\n",
            "Receiving objects: 100% (1217/1217), 2.30 MiB | 13.95 MiB/s, done.\n",
            "Resolving deltas: 100% (867/867), done.\n"
          ]
        }
      ],
      "source": [
        "if GCP_RUNTIME:\n",
        "  !sudo apt-get -y install git\n",
        "#@markdown Where to clone the repo into:\n",
        "REPO_DESTINATION_PATH = \"mutformer\" #@param {type:\"string\"}\n",
        "import os,shutil\n",
        "if not os.path.exists(REPO_DESTINATION_PATH):\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "else:\n",
        "  shutil.rmtree(REPO_DESTINATION_PATH)\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "cmd = \"git clone https://github.com/WGLab/mutformer.git \\\"\" + REPO_DESTINATION_PATH + \"\\\"\"\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj1mClhQQE_n"
      },
      "source": [
        "#Imports/Authenticate for GCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S4CiOh3RzFW"
      },
      "outputs": [],
      "source": [
        "if not GCP_RUNTIME:\n",
        "  def authenticate_user(): ##authentication function that uses link authentication instead of popup\n",
        "    if os.path.exists(\"/content/.config/application_default_credentials.json\"): \n",
        "      return\n",
        "    print(\"Authorize for runtime GCS:\")\n",
        "    !gcloud auth login --no-launch-browser\n",
        "    print(\"Authorize for TPU GCS:\")\n",
        "    !gcloud auth application-default login  --no-launch-browser\n",
        "  authenticate_user()\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import importlib\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if REPO_DESTINATION_PATH == \"mutformer\":\n",
        "  if os.path.exists(\"mutformer_code\"):\n",
        "    shutil.rmtree(\"mutformer_code\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH,\"mutformer_code\")\n",
        "  REPO_DESTINATION_PATH = \"mutformer_code\"\n",
        "if not os.path.exists(\"mutformer\"):\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "else:\n",
        "  shutil.rmtree(\"mutformer\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "if \"mutformer\" in sys.path:\n",
        "  sys.path.remove(\"mutformer\")\n",
        "sys.path.append(\"mutformer\")\n",
        "\n",
        "from mutformer import modeling, optimization, tokenization, run_pretraining\n",
        "\n",
        "##reload modules so that you don't need to restart the runtime to reload modules in case that's needed\n",
        "modules2reload = [modeling, \n",
        "                  optimization, \n",
        "                  tokenization,\n",
        "                  run_pretraining]\n",
        "for module in modules2reload:\n",
        "    importlib.reload(module)\n",
        "\n",
        "from modeling import *\n",
        "\n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "log.handlers = []\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "#@markdown Whether or not to write logs to a file\n",
        "DO_FILE_LOGGING = False #@param {type:\"boolean\"}\n",
        "if DO_FILE_LOGGING:\n",
        "  #@markdown * If using file logging, what path to write logs to\n",
        "  FILE_LOGGING_PATH = 'file_logging/spam.log' #@param {type:\"string\"}\n",
        "  if not os.path.exists(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1])):\n",
        "    os.makedirs(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1]))\n",
        "  fh = logging.FileHandler(FILE_LOGGING_PATH)\n",
        "  fh.setLevel(logging.INFO)\n",
        "  fh.setFormatter(formatter)\n",
        "  log.addHandler(fh)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    ##upload credentials to TPU.\n",
        "    with open(\"/content/.config/application_default_credentials.json\", 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzRqYyB-Mesv"
      },
      "source": [
        "#Specify original data location for detection of steps per epoch (optional)/specify GCS or Drive preference for saving evaluation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYsYBUCJMTdz"
      },
      "outputs": [],
      "source": [
        "#@markdown To minimize interaction with GCS, for sequences per dataset detection, if not USE_GCP_TPU and data was stored in drive, folder where the original data (tsv format) was stored (for detecting the # of steps per epoch) (this variable should match up with the \"INPUT_DATA_FOLDER\" variable in the data generation script). Alternatively, this item can also be left blank and steps will be autodetected using tfrecords on GCS. (if data was stored in GCS or USE_GCP_TPU is true, leave this item blank, as steps must be detected from tfrecords in this case)\n",
        "orig_data_folder = \"\" #@param {type:\"string\"}\n",
        "BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "DRIVE_PATH = \"/content/drive/My Drive\"\n",
        "\n",
        "#@markdown whether to use GCS for writing eval results, if not, defaults to drive\n",
        "GCS_EVAL = True #@param {type:\"boolean\"}\n",
        "EVALS_PATH = BUCKET_PATH if GCS_EVAL else DRIVE_PATH\n",
        "if EVALS_PATH==DRIVE_PATH:\n",
        "  from google.colab import drive\n",
        "  !fusermount -u /content/drive\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhZV6JNh3Qxg"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3V5T3cT9-Bl"
      },
      "source": [
        "###General Setup and definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stkmJtg2tnyR"
      },
      "outputs": [],
      "source": [
        "def write_metrics(metrics,dir):\n",
        "  gs = metrics[\"global_step\"]\n",
        "  print(\"global step\",gs)\n",
        "\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "  tf.reset_default_graph()  \n",
        "  if os.path.exists(dir):\n",
        "    shutil.rmtree(dir)\n",
        "  for key,value in metrics.items():\n",
        "    if key==\"global_step\":\n",
        "      continue\n",
        "    print(key,value)\n",
        "    x_scalar = tf.constant(value)\n",
        "    first_summary = tf.summary.scalar(name=f\"eval_{key}\", tensor=x_scalar)\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "   \n",
        "    with tf.Session() as sess:\n",
        "        writer = tf.summary.FileWriter(dir)\n",
        "        sess.run(init)\n",
        "        summary = sess.run(first_summary)\n",
        "        writer.add_summary(summary, gs)\n",
        "        writer.flush()\n",
        "        print('Done with writing the scalar summary')\n",
        "    time.sleep(1)\n",
        "  \n",
        "  if \"gs:\" in EVALS_PATH:\n",
        "    cmd = \"gsutil -m cp -r \\\"\"+dir+\"/.\\\" \\\"\"+EVALS_PATH+\"/\"+dir+\"\\\"\"\n",
        "  else:\n",
        "    if not os.path.exists(EVALS_PATH+\"/\"+dir):\n",
        "      os.makedirs(EVALS_PATH+\"/\"+dir)\n",
        "    shutil.copytree(dir,EVALS_PATH+\"/\"+dir)\n",
        "  !{cmd}\n",
        "\n",
        "\n",
        "def reload_ckpt(model_dir,current_ckpt,model,data_dir):\n",
        "  BERT_GCS_DIR = f\"{BUCKET_PATH}/{model_dir}\"\n",
        "\n",
        "\n",
        "  CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"config.json\")\n",
        "\n",
        "  INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "  log.info(f\"init chkpt: {INIT_CHECKPOINT}\")\n",
        "  log.info(f\"current chkpt: {current_ckpt}\")\n",
        "  if INIT_CHECKPOINT != current_ckpt:\n",
        "    log.info(f\"Using data from {data_dir}\")\n",
        "    config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "    test_input_files = tf.gfile.Glob(os.path.join(data_dir,'*tfrecord'))\n",
        "    log.info(f\"Using {len(test_input_files)} data shards for testing\")\n",
        "    model_fn = run_pretraining.model_fn_builder(\n",
        "          bert_config=config,\n",
        "          init_checkpoint=INIT_CHECKPOINT,\n",
        "          init_learning_rate=0,\n",
        "          decay_per_step=0,\n",
        "          num_warmup_steps=10,\n",
        "          use_tpu=True,\n",
        "          use_one_hot_embeddings=True,\n",
        "          bert=model)\n",
        "\n",
        "    \n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "    run_config = tf.contrib.tpu.RunConfig(\n",
        "        cluster=tpu_cluster_resolver,\n",
        "        model_dir=BERT_GCS_DIR,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "            num_shards=NUM_TPU_CORES,\n",
        "            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "    estimator = tf.contrib.tpu.TPUEstimator(\n",
        "        use_tpu=True,\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        train_batch_size=1,\n",
        "        eval_batch_size=EVAL_BATCH_SIZE)\n",
        "\n",
        "    DATA_INFO = json.load(tf.gfile.Open(data_dir+\"/info.json\")) \n",
        "    MAX_SEQ_LENGTH = DATA_INFO[\"sequence_length\"]\n",
        "    MAX_PREDICTIONS = DATA_INFO[\"max_num_predictions\"]\n",
        "\n",
        "    \n",
        "    input_fn = run_pretraining.input_fn_builder(\n",
        "        input_files=test_input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=False)\n",
        "    return INIT_CHECKPOINT,estimator,input_fn,True\n",
        "  else:\n",
        "    return None,None,None,False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAVF8hSXHVv"
      },
      "source": [
        "###Run Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run evaluation for the pretraining task.\n",
        "\n",
        "Note: All evaluation results will be written into the previously specified logging directory either under google drive or GCS, depending on the values of GCS_EVAL specified before. To view the results, use the colab notebook titled \"mutformer processing and viewing pretraining results.\""
      ],
      "metadata": {
        "id": "OVNMq9IlhCZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrCuEbr6dv8U"
      },
      "outputs": [],
      "source": [
        "#@markdown ###IO config\n",
        "#@markdown Whether to evaluate on the test set or the dev set (value can be \"test\" or \"dev\")\n",
        "dataset = \"dev\" #@param{type:\"string\"}\n",
        "#@markdown Whether to continuously evaluate in a while loop\n",
        "REPEAT_EVAL = False #@param{type:\"boolean\"}\n",
        "#@markdown * List of pretrained models to evaluate (should indicate the names of the pretrained model folders inside GCS):\n",
        "MODELS = [\"bert_model_embedded_mutformer_8L\"] #@param\n",
        "#@markdown * List of model architectures for each model in the \"MODELS\" list defined in the entry above: each position in this list must correctly indicate the model architecture of its corresponding model folder in the list \"MODELS\" (BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture).\n",
        "MODEL_ARCHITECTURES = [\"MutFormer_embedded_convs\"] #@param\n",
        "#@markdown Folders within EVALUATIONS_LOGS_DIR for where evaluation logs should be written to (each run name should correspond to a model and model architecture)\n",
        "RUN_NAMES = [\"bert_model_embedded_mutformer_8L\"] #@param {type:\"string\"}\n",
        "#@markdown \\\n",
        "#@markdown ### Evaluation procedure config\n",
        "EVAL_BATCH_SIZE = 64 #@param {type:\"integer\"}\n",
        "#@markdown How many seconds to wait in between each evaluation loop (to minimize interaction with GCS, should be around the same time it takes for the training script to train and save 1 checkpoint)\n",
        "SECS_BETWEEN_EVALS = 1200 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "if dataset==\"test\":\n",
        "  using_DATA_DIR = f\"{DATA_DIR}/test\"\n",
        "elif dataset==\"dev\":\n",
        "  using_DATA_DIR = f\"{DATA_DIR}/train\"\n",
        "else:\n",
        "  raise Exception(\"only datasets supported are dev and test\")\n",
        "\n",
        "current_ckpts = [\"N/A\" for i in range(len(MODELS))]\n",
        "\n",
        "total_metrics = {}\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    for n,model in enumerate(MODELS):\n",
        "      MODEL_ARCHITECTURE = getattr(modeling, MODEL_ARCHITECTURES[n])\n",
        "      RUN_NAME=  RUN_NAMES[n]\n",
        "      LOCAL_EVALUATIONS_LOGS_DIR = f\"{EVALUATIONS_LOGS_DIR}/{RUN_NAME}\"\n",
        "      current_ckpt = current_ckpts[n]\n",
        "      current_ckpt,estimator,test_input_fn,new = reload_ckpt(model,current_ckpt,MODEL_ARCHITECTURE,BUCKET_PATH+\"/\"+using_DATA_DIR)\n",
        "      current_ckpts[n] = current_ckpt\n",
        "      if new:\n",
        "        print(\"\\n\\nEVALUATING \"+model+\"\\n\\n\")\n",
        "        log.info(f\"Using checkpoint: {current_ckpt}\")\n",
        "        def steps_getter(input_files):\n",
        "          tot_sequences = 0\n",
        "          for input_file in input_files:\n",
        "            tf.logging.info(f\"reading: {input_file} for steps\")\n",
        "\n",
        "            d = tf.data.TFRecordDataset(input_file)\n",
        "\n",
        "            with tf.Session() as sess:\n",
        "              tot_sequences+=sess.run(d.reduce(0, lambda x,_: x+1))\n",
        "\n",
        "          return tot_sequences\n",
        "    \n",
        "        try:\n",
        "          if dataset==\"dev\":\n",
        "            data_path_eval = orig_data_folder+\"/train.tsv\"\n",
        "          else: ##dataset == \"test\"\n",
        "            data_path_eval = orig_data_folder+\"/test.tsv\"\n",
        "          lines = open(data_path_eval).read().split(\"\\n\")\n",
        "          EVAL_STEPS = int(len(lines)/EVAL_BATCH_SIZE)\n",
        "        except Exception:\n",
        "          DATA_GCS_DIR_train = f\"{BUCKET_PATH}/{using_DATA_DIR}\"\n",
        "          eval_input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR_train,'*tfrecord'))\n",
        "          SEQUENCES_PER_EPOCH = steps_getter(eval_input_files)\n",
        "          EVAL_STEPS = int(SEQUENCES_PER_EPOCH/EVAL_BATCH_SIZE)\n",
        "\n",
        "        tf.logging.info(\"eval steps:\"+str(EVAL_STEPS))\n",
        "        metrics = estimator.evaluate(input_fn=test_input_fn, steps=EVAL_STEPS)\n",
        "        if REPEAT_EVAL:\n",
        "          write_metrics(metrics,LOCAL_EVALUATIONS_LOGS_DIR)\n",
        "        else:\n",
        "          total_metrics[LOCAL_EVALUATIONS_LOGS_DIR] = metrics\n",
        "      else:\n",
        "        log.info(f\"\\n\\nNo new checkpoints were found for evaluation. Checking again in {SECS_BETWEEN_EVALS} seconds.\\n\\n\")\n",
        "    print(\"finished 1 eval loop\")\n",
        "    if not REPEAT_EVAL:\n",
        "      break\n",
        "  except Exception as e:\n",
        "    log.info(f\"\\n\\nEvaluation failed. error: {e}\\n\\n\")\n",
        "  if not REPEAT_EVAL:\n",
        "      break\n",
        "  time.sleep(SECS_BETWEEN_EVALS)\n",
        "if dataset == \"test\":\n",
        "  for logging_dir,metrics in total_metrics.items():\n",
        "    print(\"Printing metrics for:\",logging_dir,\"\\n\")\n",
        "    for key,metric in metrics.items():\n",
        "      print(key+\":\",metric)\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "4hc9aPdWODjZ"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "name": "py37",
      "display_name": "Python 3.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}