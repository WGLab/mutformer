{"cells":[{"cell_type":"markdown","metadata":{"id":"dzJfcGJFJiEl"},"source":["#Pretraining Evaluation script"]},{"cell_type":"markdown","metadata":{"id":"3rHK9_cjJlOi"},"source":["This script evaluates pretrained models on protein sequences.\n","\n","Note: If using a TPU from Google Cloud (not the Colab TPU), make sure to run this notebook on a VM with access to all GCP APIs, and make sure TPUs are enabled for the GCP project\n","\n","This file can evaluate in parallel multiple models at the same time. However, if more frequent evaluations on more models are desired, run multiple copies of this notebook in multiple VMs"]},{"cell_type":"markdown","metadata":{"id":"E2XB_l-Hgzq_"},"source":["# Configure settings"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ozmx1LCLw3SQ","executionInfo":{"status":"ok","timestamp":1653971726527,"user_tz":420,"elapsed":183,"user":{"displayName":"Theodore Jiang","userId":"00217167587796603699"}}},"outputs":[],"source":["#@markdown ### General Config\n","GCP_RUNTIME = False #@param {type:\"boolean\"}\n","PROCESSES = 2 #@param {type:\"integer\"}\n","NUM_TPU_CORES = 8 #@param {type:\"integer\"}\n","BUCKET_NAME = \"theodore_jiang\" #@param {type:\"string\"}\n","#@markdown Evaluation and Testing data location\n","DATA_DIR = \"pretraining_data_1024_embedded_mutformer\" #@param {type:\"string\"}\n","#@markdown What folder to write evaluation results into:\n","EVALUATIONS_LOGS_DIR = \"mutformer2_0_pretraining_logs\" #@param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"4hc9aPdWODjZ"},"source":["#If running on a GCP TPU, use these commands prior to running this notebook"]},{"cell_type":"markdown","metadata":{"id":"e5HqITT8OGmo"},"source":["To ssh into the VM:\n","\n","```\n","gcloud beta compute ssh --zone <COMPUTE ZONE> <VM NAME> --project <PROJECT NAME> -- -L 8888:localhost:8888\n","```\n","\n","Make sure the port above matches the port below (in this case it's 8888)\n","\n","```\n","sudo apt-get update\n","sudo apt-get -y install python3 python3-pip\n","sudo apt-get install pkg-config\n","sudo apt-get install libhdf5-serial-dev\n","sudo apt-get install libffi6 libffi-dev\n","sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm\n","sudo -H pip3 install jupyter_http_over_ws\n","jupyter serverextension enable --py jupyter_http_over_ws\n","jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n","\n","(one command):sudo apt-get update ; sudo apt-get -y install python3 python3-pip ; sudo apt-get install pkg-config ; sudo apt-get -y install libhdf5-serial-dev ; sudo apt-get install libffi6 libffi-dev; sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm ; sudo -H pip3 install jupyter_http_over_ws ; jupyter serverextension enable --py jupyter_http_over_ws ; jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n","```\n","And then copy and paste the outputted link with \"locahost: ...\" into the colab connect to local runtime option\n"]},{"cell_type":"markdown","metadata":{"id":"bME72K_8OJIY"},"source":["###Also run this code segment, which creates a TPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRLBsRo-OLqA"},"outputs":[],"source":["GCE_PROJECT_NAME = \"genome-project-319100\" #@param {type:\"string\"}\n","TPU_ZONE = \"us-central1-f\" #@param {type:\"string\"}\n","TPU_NAME = \"mutformer-tpu\" #@param {type:\"string\"}\n","\n","!gcloud alpha compute tpus create $TPU_NAME --accelerator-type=tpu-v2 --version=1.15.5 --zone=$TPU_ZONE ##create new TPU\n","\n","!gsutil iam ch serviceAccount:`gcloud alpha compute tpus describe $TPU_NAME | grep serviceAccount | cut -d' ' -f2`:admin gs://theodore_jiang && echo 'Successfully set permissions!' ##give TPU access to GCS"]},{"cell_type":"markdown","metadata":{"id":"XIVqP04jiFF1"},"source":["#Clone the repo"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1383,"status":"ok","timestamp":1653971729560,"user":{"displayName":"Theodore Jiang","userId":"00217167587796603699"},"user_tz":420},"id":"SanOExwkiEC_","outputId":"86625375-6bee-49a7-af0e-34fedf9d9559"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mutformer'...\n","remote: Enumerating objects: 1217, done.\u001b[K\n","remote: Counting objects: 100% (97/97), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 1217 (delta 78), reused 56 (delta 46), pack-reused 1120\u001b[K\n","Receiving objects: 100% (1217/1217), 2.30 MiB | 13.95 MiB/s, done.\n","Resolving deltas: 100% (867/867), done.\n"]}],"source":["if GCP_RUNTIME:\n","  !sudo apt-get -y install git\n","#@markdown Where to clone the repo into:\n","REPO_DESTINATION_PATH = \"mutformer\" #@param {type:\"string\"}\n","import os,shutil\n","if not os.path.exists(REPO_DESTINATION_PATH):\n","  os.makedirs(REPO_DESTINATION_PATH)\n","else:\n","  shutil.rmtree(REPO_DESTINATION_PATH)\n","  os.makedirs(REPO_DESTINATION_PATH)\n","cmd = \"git clone https://github.com/WGLab/mutformer.git \\\"\" + REPO_DESTINATION_PATH + \"\\\"\"\n","!{cmd}"]},{"cell_type":"markdown","metadata":{"id":"Yj1mClhQQE_n"},"source":["#Imports/Authenticate for GCP"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56672,"status":"ok","timestamp":1653971786228,"user":{"displayName":"Theodore Jiang","userId":"00217167587796603699"},"user_tz":420},"id":"9S4CiOh3RzFW","outputId":"e72415d4-ccc1-4e61-8c03-63b18afc7212"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n","Authorize for runtime GCS:\n","\u001b[1;33mWARNING:\u001b[0m The --[no-]launch-browser flags are deprecated and will be removed on June 7th 2022 (Release 389.0.0). Use --no-browser to replace --no-launch-browser.\n","\n","Go to the following link in your browser:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=e4QLb40udAQur1vazGnE2BA6WL9rbS&prompt=consent&access_type=offline&code_challenge=rTozKYZHvz0tHlmyc7a4a_O_QDvGNltP1qrLR6WZ5Fc&code_challenge_method=S256\n","\n","Enter verification code: 4/1AX4XfWivOEeaKiLbbjTqCxLl2x9RDDaTUBvkQBzIJIxKlmxUBXrl70vpcis\n","\n","You are now logged in as [tianqitheodorejiang@gmail.com].\n","Your current project is [None].  You can change this setting by running:\n","  $ gcloud config set project PROJECT_ID\n","Authorize for TPU GCS:\n","\u001b[1;33mWARNING:\u001b[0m The --[no-]launch-browser flags are deprecated and will be removed on June 7th 2022 (Release 389.0.0). Use --no-browser to replace --no-launch-browser.\n","\n","Go to the following link in your browser:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=2KC2yXXiikzUZ1TM3rUF7FvaXe5Alw&prompt=consent&access_type=offline&code_challenge=t5ROHnP3uCar9kBTdN4J2Y6OasWbJLfbERQ0My-7Mhg&code_challenge_method=S256\n","\n","Enter verification code: 4/1AX4XfWi0AAIBpC6X9CpTfxBq37wdGELjqURZShE7_TZ4Ikj7t-jL3ctwFog\n","\n","Credentials saved to file: [/content/.config/application_default_credentials.json]\n","\n","These credentials will be used by any library that requests Application Default Credentials (ADC).\n","\u001b[1;33mWARNING:\u001b[0m \n","Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n","WARNING:tensorflow:From /content/mutformer/optimization.py:85: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-31 04:36:21,281 - tensorflow - INFO - Using TPU runtime\n","2022-05-31 04:36:21,405 - tensorflow - INFO - TPU address is grpc://10.21.223.66:8470\n","2022-05-31 04:36:21,408 - tensorflow - WARNING - \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"]}],"source":["if not GCP_RUNTIME:\n","  %tensorflow_version 1.x\n","  def authenticate_user(): ##authentication function that uses link authentication instead of popup\n","    if os.path.exists(\"/content/.config/application_default_credentials.json\"): \n","      return\n","    print(\"Authorize for runtime GCS:\")\n","    !gcloud auth login --no-launch-browser\n","    print(\"Authorize for TPU GCS:\")\n","    !gcloud auth application-default login  --no-launch-browser\n","  authenticate_user()\n","\n","import sys\n","import json\n","import random\n","import logging\n","import tensorflow as tf\n","import time\n","import importlib\n","import os\n","import shutil\n","\n","if REPO_DESTINATION_PATH == \"mutformer\":\n","  if os.path.exists(\"mutformer_code\"):\n","    shutil.rmtree(\"mutformer_code\")\n","  shutil.copytree(REPO_DESTINATION_PATH,\"mutformer_code\")\n","  REPO_DESTINATION_PATH = \"mutformer_code\"\n","if not os.path.exists(\"mutformer\"):\n","  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n","else:\n","  shutil.rmtree(\"mutformer\")\n","  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n","if \"mutformer\" in sys.path:\n","  sys.path.remove(\"mutformer\")\n","sys.path.append(\"mutformer\")\n","\n","from mutformer import modeling, optimization, tokenization, run_pretraining\n","\n","##reload modules so that you don't need to restart the runtime to reload modules in case that's needed\n","modules2reload = [modeling, \n","                  optimization, \n","                  tokenization,\n","                  run_pretraining]\n","for module in modules2reload:\n","    importlib.reload(module)\n","\n","from modeling import *\n","\n","# configure logging\n","log = logging.getLogger('tensorflow')\n","log.setLevel(logging.INFO)\n","\n","log.handlers = []\n","\n","formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","\n","#@markdown Whether or not to write logs to a file\n","DO_FILE_LOGGING = False #@param {type:\"boolean\"}\n","if DO_FILE_LOGGING:\n","  #@markdown * If using file logging, what path to write logs to\n","  FILE_LOGGING_PATH = 'file_logging/spam.log' #@param {type:\"string\"}\n","  if not os.path.exists(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1])):\n","    os.makedirs(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1]))\n","  fh = logging.FileHandler(FILE_LOGGING_PATH)\n","  fh.setLevel(logging.INFO)\n","  fh.setFormatter(formatter)\n","  log.addHandler(fh)\n","\n","ch = logging.StreamHandler()\n","ch.setLevel(logging.INFO)\n","ch.setFormatter(formatter)\n","log.addHandler(ch)\n","\n","\n","if 'COLAB_TPU_ADDR' in os.environ:\n","  log.info(\"Using TPU runtime\")\n","  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","\n","  with tf.Session(TPU_ADDRESS) as session:\n","    log.info('TPU address is ' + TPU_ADDRESS)\n","    ##upload credentials to TPU.\n","    with open(\"/content/.config/application_default_credentials.json\", 'r') as f:\n","      auth_info = json.load(f)\n","    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","    \n","else:\n","  log.warning('Not connected to TPU runtime')"]},{"cell_type":"markdown","metadata":{"id":"YzRqYyB-Mesv"},"source":["#Specify original data location for detection of steps per epoch (optional)/specify GCS or Drive preference for saving evaluation results"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"eYsYBUCJMTdz","executionInfo":{"status":"ok","timestamp":1653971786229,"user_tz":420,"elapsed":10,"user":{"displayName":"Theodore Jiang","userId":"00217167587796603699"}}},"outputs":[],"source":["#@markdown Note: for all of these, if using USE_GCP_TPU, all of these parameters must use GCS, because a GCP TPU can't access google drive\n","#@markdown \n","#@markdown \n","#@markdown To minimize interaction with GCS, for sequences per dataset detection, if not USE_GCP_TPU and data was stored in drive, folder where the original data was stored (tsv format). Alternatively, this item can also be left blank and steps will be autodetected using tfrecords on GCS. (if data was stored in GCS or USE_GCP_TPU is true, leave this item blank)\n","orig_data_folder = \"\" #@param {type:\"string\"}\n","BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n","DRIVE_PATH = \"/content/drive/My Drive\"\n","\n","#@markdown whether to use GCS for writing eval results, if not, defaults to drive\n","GCS_EVAL = True #@param {type:\"boolean\"}\n","EVALS_PATH = BUCKET_PATH if GCS_EVAL else DRIVE_PATH\n","if EVALS_PATH==DRIVE_PATH:\n","  from google.colab import drive\n","  !fusermount -u /content/drive\n","  drive.flush_and_unmount()\n","  drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"XhZV6JNh3Qxg"},"source":["#Evaluation"]},{"cell_type":"markdown","metadata":{"id":"O3V5T3cT9-Bl"},"source":["###General Setup and definitions"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"stkmJtg2tnyR","executionInfo":{"status":"ok","timestamp":1653971786229,"user_tz":420,"elapsed":8,"user":{"displayName":"Theodore Jiang","userId":"00217167587796603699"}}},"outputs":[],"source":["def write_metrics(metrics,dir):\n","  gs = metrics[\"global_step\"]\n","  print(\"global step\",gs)\n","\n","  tf.compat.v1.disable_eager_execution()\n","  tf.reset_default_graph()  \n","  if os.path.exists(dir):\n","    shutil.rmtree(dir)\n","  for key,value in metrics.items():\n","    if key==\"global_step\":\n","      continue\n","    print(key,value)\n","    x_scalar = tf.constant(value)\n","    first_summary = tf.summary.scalar(name=f\"eval_{key}\", tensor=x_scalar)\n","\n","    init = tf.global_variables_initializer()\n","   \n","    with tf.Session() as sess:\n","        writer = tf.summary.FileWriter(dir)\n","        sess.run(init)\n","        summary = sess.run(first_summary)\n","        writer.add_summary(summary, gs)\n","        writer.flush()\n","        print('Done with writing the scalar summary')\n","    time.sleep(1)\n","  \n","  if \"gs:\" in EVALS_PATH:\n","    cmd = \"gsutil -m cp -r \\\"\"+dir+\"/.\\\" \\\"\"+EVALS_PATH+\"/\"+dir+\"\\\"\"\n","  else:\n","    if not os.path.exists(EVALS_PATH+\"/\"+dir):\n","      os.makedirs(EVALS_PATH+\"/\"+dir)\n","    shutil.copytree(dir,EVALS_PATH+\"/\"+dir)\n","  !{cmd}\n","\n","\n","def reload_ckpt(model_dir,current_ckpt,model,data_dir):\n","  BERT_GCS_DIR = f\"{BUCKET_PATH}/{model_dir}\"\n","\n","\n","  CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"config.json\")\n","\n","  INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n","  log.info(f\"init chkpt: {INIT_CHECKPOINT}\")\n","  log.info(f\"current chkpt: {current_ckpt}\")\n","  if INIT_CHECKPOINT != current_ckpt:\n","    log.info(f\"Using data from {data_dir}\")\n","    config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n","    test_input_files = tf.gfile.Glob(os.path.join(data_dir,'*tfrecord'))\n","    log.info(f\"Using {len(test_input_files)} data shards for testing\")\n","    model_fn = run_pretraining.model_fn_builder(\n","          bert_config=config,\n","          init_checkpoint=INIT_CHECKPOINT,\n","          init_learning_rate=0,\n","          decay_per_step=0,\n","          num_warmup_steps=10,\n","          use_tpu=True,\n","          use_one_hot_embeddings=True,\n","          bert=model)\n","\n","    \n","    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n","\n","    run_config = tf.contrib.tpu.RunConfig(\n","        cluster=tpu_cluster_resolver,\n","        model_dir=BERT_GCS_DIR,\n","        tpu_config=tf.contrib.tpu.TPUConfig(\n","            num_shards=NUM_TPU_CORES,\n","            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n","\n","    estimator = tf.contrib.tpu.TPUEstimator(\n","        use_tpu=True,\n","        model_fn=model_fn,\n","        config=run_config,\n","        train_batch_size=1,\n","        eval_batch_size=EVAL_BATCH_SIZE)\n","\n","    DATA_INFO = json.load(tf.gfile.Open(data_dir+\"/info.json\")) \n","    MAX_SEQ_LENGTH = DATA_INFO[\"sequence_length\"]\n","    MAX_PREDICTIONS = DATA_INFO[\"max_num_predictions\"]\n","\n","    \n","    input_fn = run_pretraining.input_fn_builder(\n","        input_files=test_input_files,\n","        max_seq_length=MAX_SEQ_LENGTH,\n","        max_predictions_per_seq=MAX_PREDICTIONS,\n","        is_training=False)\n","    return INIT_CHECKPOINT,estimator,input_fn,True\n","  else:\n","    return None,None,None,False"]},{"cell_type":"markdown","metadata":{"id":"9pAVF8hSXHVv"},"source":["###Run Eval"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JrCuEbr6dv8U","outputId":"8d05a943-285e-4e7a-b3eb-50649462bd90","executionInfo":{"status":"error","timestamp":1653973882283,"user_tz":420,"elapsed":2096061,"user":{"displayName":"Theodore Jiang","userId":"00217167587796603699"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-31 04:36:26,245 - tensorflow - INFO - init chkpt: gs://theodore_jiang/bert_model_embedded_mutformer_8L/model.ckpt-1501056\n","2022-05-31 04:36:26,247 - tensorflow - INFO - current chkpt: N/A\n","2022-05-31 04:36:26,248 - tensorflow - INFO - Using data from gs://theodore_jiang/pretraining_data_1024_embedded_mutformer/train\n","2022-05-31 04:36:26,249 - tensorflow - WARNING - From /content/mutformer/modeling.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","2022-05-31 04:36:27,053 - tensorflow - INFO - Using 0 data shards for testing\n","2022-05-31 04:36:27,059 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f31ca1d5f80>) includes params argument, but params are not passed to Estimator.\n","2022-05-31 04:36:27,060 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_embedded_mutformer_8L', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","cluster_def {\n","  job {\n","    name: \"worker\"\n","    tasks {\n","      key: 0\n","      value: \"10.21.223.66:8470\"\n","    }\n","  }\n","}\n","isolate_session_state: true\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f31c8e8d3d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.21.223.66:8470', '_evaluation_master': 'grpc://10.21.223.66:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f31c8e69910>}\n","2022-05-31 04:36:27,062 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n","2022-05-31 04:36:27,506 - tensorflow - INFO - \n","\n","Evaluation failed. error: The specified path gs://theodore_jiang/pretraining_data_1024_embedded_mutformer/train/info.json was not found.\n","\n","\n","2022-05-31 04:56:28,376 - tensorflow - INFO - init chkpt: gs://theodore_jiang/bert_model_embedded_mutformer_8L/model.ckpt-1501056\n","2022-05-31 04:56:28,378 - tensorflow - INFO - current chkpt: N/A\n","2022-05-31 04:56:28,380 - tensorflow - INFO - Using data from gs://theodore_jiang/pretraining_data_1024_embedded_mutformer/train\n","2022-05-31 04:56:29,056 - tensorflow - INFO - Using 0 data shards for testing\n","2022-05-31 04:56:29,060 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f31c8e854d0>) includes params argument, but params are not passed to Estimator.\n","2022-05-31 04:56:29,062 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_embedded_mutformer_8L', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","cluster_def {\n","  job {\n","    name: \"worker\"\n","    tasks {\n","      key: 0\n","      value: \"10.21.223.66:8470\"\n","    }\n","  }\n","}\n","isolate_session_state: true\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f31c8e8d8d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.21.223.66:8470', '_evaluation_master': 'grpc://10.21.223.66:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f31c8e8d210>}\n","2022-05-31 04:56:29,063 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n","2022-05-31 04:56:29,506 - tensorflow - INFO - \n","\n","Evaluation failed. error: The specified path gs://theodore_jiang/pretraining_data_1024_embedded_mutformer/train/info.json was not found.\n","\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f0e238c36349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\nEvaluation failed. error: {e}\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSECS_BETWEEN_EVALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlogging_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtotal_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#@markdown ###IO config\n","#@markdown Whether to evaluate on the test set or the dev set (value can be \"test\" or \"dev\")\n","dataset = \"dev\" #@param{type:\"string\"}\n","#@markdown Whether to continuously evaluate in a while loop\n","REPEAT_EVAL = False #@param{type:\"boolean\"}\n","#@markdown * List of pretrained models to evaluate (should indicate the names of the pretrained model folders inside GCS):\n","MODELS = [\"bert_model_embedded_mutformer_8L\"] #@param\n","#@markdown * List of model architectures for each model in the \"MODELS\" list defined in the entry above: each position in this list must correctly indicate the model architecture of its corresponding model folder in the list \"MODELS\" (BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture).\n","MODEL_ARCHITECTURES = [\"MutFormer_embedded_convs\"] #@param\n","#@markdown Folders within EVALUATIONS_LOGS_DIR for where evaluation logs should be written to (each run name should correspond to a model and model architecture)\n","RUN_NAMES = [\"bert_model_embedded_mutformer_8L\"] #@param {type:\"string\"}\n","#@markdown \\\n","#@markdown ### Evaluation procedure config\n","EVAL_BATCH_SIZE = 64 #@param {type:\"integer\"}\n","#@markdown How many seconds to wait in between each evaluation loop (to minimize interaction with GCS, should be around the same time it takes for the training script to train and save 1 checkpoint)\n","SECS_BETWEEN_EVALS = 1200 #@param {type:\"integer\"}\n","\n","\n","if dataset==\"test\":\n","  using_DATA_DIR = f\"{DATA_DIR}/test\"\n","elif dataset==\"dev\":\n","  using_DATA_DIR = f\"{DATA_DIR}/train\"\n","else:\n","  raise Exception(\"only datasets supported are dev and test\")\n","\n","current_ckpts = [\"N/A\" for i in range(len(MODELS))]\n","\n","total_metrics = {}\n","\n","while True:\n","  try:\n","    for n,model in enumerate(MODELS):\n","      MODEL_ARCHITECTURE = getattr(modeling, MODEL_ARCHITECTURES[n])\n","      RUN_NAME=  RUN_NAMES[n]\n","      LOCAL_EVALUATIONS_LOGS_DIR = f\"{EVALUATIONS_LOGS_DIR}/{RUN_NAME}\"\n","      current_ckpt = current_ckpts[n]\n","      current_ckpt,estimator,test_input_fn,new = reload_ckpt(model,current_ckpt,MODEL_ARCHITECTURE,BUCKET_PATH+\"/\"+using_DATA_DIR)\n","      current_ckpts[n] = current_ckpt\n","      if new:\n","        print(\"\\n\\nEVALUATING \"+model+\"\\n\\n\")\n","        log.info(f\"Using checkpoint: {current_ckpt}\")\n","        def steps_getter(input_files):\n","          tot_sequences = 0\n","          for input_file in input_files:\n","            tf.logging.info(f\"reading: {input_file} for steps\")\n","\n","            d = tf.data.TFRecordDataset(input_file)\n","\n","            with tf.Session() as sess:\n","              tot_sequences+=sess.run(d.reduce(0, lambda x,_: x+1))\n","\n","          return tot_sequences\n","    \n","        try:\n","          if dataset==\"dev\":\n","            data_path_eval = orig_data_folder+\"/train.tsv\"\n","          else: ##dataset == \"test\"\n","            data_path_eval = orig_data_folder+\"/test.tsv\"\n","          lines = open(data_path_eval).read().split(\"\\n\")\n","          EVAL_STEPS = int(len(lines)/EVAL_BATCH_SIZE)\n","        except Exception:\n","          DATA_GCS_DIR_train = f\"{BUCKET_PATH}/{using_DATA_DIR}\"\n","          eval_input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR_train,'*tfrecord'))\n","          SEQUENCES_PER_EPOCH = steps_getter(eval_input_files)\n","          EVAL_STEPS = int(SEQUENCES_PER_EPOCH/EVAL_BATCH_SIZE)\n","\n","        tf.logging.info(\"eval steps:\"+str(EVAL_STEPS))\n","        metrics = estimator.evaluate(input_fn=test_input_fn, steps=EVAL_STEPS)\n","        if REPEAT_EVAL:\n","          write_metrics(metrics,LOCAL_EVALUATIONS_LOGS_DIR)\n","        else:\n","          total_metrics[LOCAL_EVALUATIONS_LOGS_DIR] = metrics\n","      else:\n","        log.info(f\"\\n\\nNo new checkpoints were found for evaluation. Checking again in {SECS_BETWEEN_EVALS} seconds.\\n\\n\")\n","    print(\"finished 1 eval loop\")\n","    if not REPEAT_EVAL:\n","      break\n","  except Exception as e:\n","    log.info(f\"\\n\\nEvaluation failed. error: {e}\\n\\n\")\n","  if not REPEAT_EVAL:\n","      break\n","  time.sleep(SECS_BETWEEN_EVALS)\n","if dataset == \"test\":\n","  for logging_dir,metrics in total_metrics.items():\n","    print(\"Printing metrics for:\",logging_dir,\"\\n\")\n","    for key,metric in metrics.items():\n","      print(key+\":\",metric)\n","    print(\"\\n\")"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":["4hc9aPdWODjZ"],"machine_shape":"hm","name":"Copy of mutformer_run_pretraining_eval.ipynb","provenance":[{"file_id":"177uAOqUy1EujiujPU486Jv_T50vhYqDO","timestamp":1644045420023},{"file_id":"https://github.com/WGLab/mutformer/blob/main/mutformer_pretraining/mutformer_run_pretraining_eval.ipynb","timestamp":1640327313227}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}