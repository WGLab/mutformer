{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "mutformer_finetuning_benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SaNhPg7sG2DS",
        "9AjnVKSMlVXz",
        "WQ322RGr5ykF"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WGLab/mutformer/blob/main/mutformer_finetuning/mutformer_finetuning_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finetuning Script"
      ],
      "metadata": {
        "id": "VudE2umODMnI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHNq3MSTTea"
      },
      "source": [
        "This notebook performs finetuning with varying models, batch sizes, and sequence lengths in order to find the best model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_"
      },
      "source": [
        "# Configure settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozmx1LCLw3SQ"
      },
      "source": [
        "#@markdown ## General Config\n",
        "#@markdown If preferred, a GCP TPU/runtime can be used to run this notebook (instructions below)\n",
        "USE_GCP_RUNTIME = False #@param {type:\"boolean\"}\n",
        "#@markdown Which task to perform: options are \"MRPC\" for paired sequence method, \"MRPC_w_ex_data\" for paired sequence method with external data, \"RE\" for single sequence method, or \"NER\" for single sequance per residue prediction (you can add more modes by editing the model code files downloaded from github, but if you add more modes make sure to change the corresponding code segments)\n",
        "MODE = \"MRPC_w_ex_data\" #@param {type:\"string\"}\n",
        "#@markdown Whether or not external data is being used\n",
        "USING_EX_DATA = True #@param {type:\"boolean\"}\n",
        "#@markdown If using external data, how many pieces of external data are included in total\n",
        "PRED_NUM =   27#@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH =  1024#@param {type:\"integer\"}\n",
        "BUCKET_NAME = \"theodore_jiang\" #@param {type:\"string\"}\n",
        "#@markdown Folder for where to save the finetuned model (if you want to save into GCS directly, leave this entry blank)\n",
        "OUTPUT_MODEL_DIR = \"bert_model_mrpc_adding_preds\" #@param {type:\"string\"}\n",
        "if OUTPUT_MODEL_DIR==\"\":\n",
        "  OUTPUT_MODEL_DIR = \":::::\"\n",
        "#@markdown Folder in GCS where the pretrained model needs to be loaded from (if saved directly into GCS, leave blank) (the specific model folders will be specified later)\n",
        "INIT_MODEL_DIR = \"\" #@param {type:\"string\"}\n",
        "if INIT_MODEL_DIR==\"\":\n",
        "  INIT_MODEL_DIR = \":::::\"\n",
        "#@markdown Where in GCS the data needs to be loaded from (should be the same as the DATA_DIR variable in the data generation script)\n",
        "DATA_DIR = \"MRPC_w_preds_all_loaded\" #@param {type:\"string\"}\n",
        "#@markdown Which folder to store the logs in (the LOGGING_DIR variable can be the same across all finetuning notebooks)\n",
        "LOGGING_DIR = \"mrpc_loss_spam_model_comparison_final\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Training procedure config\n",
        "INIT_LEARNING_RATE =  1e-5 #@param {type:\"number\"}\n",
        "END_LEARNING_RATE = 5e-7 #@param {type:\"number\"}\n",
        "#@markdown Save a checkpoint every this amount of steps\n",
        "SAVE_CHECKPOINTS_STEPS =  1000 #@param {type:\"integer\"}\n",
        "#@markdown ###### TPUEstimator will keep this number of checkpoints; older checkpoints will all be deleted\n",
        "KEEP_N_CHECKPOINTS_AT_A_TIME =  10#@param {type:\"integer\"}\n",
        "#@markdown If using colab, NUM_TPU_SCORES is 8\n",
        "NUM_TPU_CORES = 8 #@param {type:\"number\"}\n",
        "#@markdown How many sequences should the model train on before stopping\n",
        "PLANNED_TOTAL_SEQUENCES_SEEN =  2e5 #@param {type:\"number\"}\n",
        "#@markdown How many steps should the model train for before stopping (number of total sequences seen will depend on the batch size used). NOTE: PLANNED_TOTAL_STEPS will override PLANNED_TOTAL_SEQUENCES_SEEN; if using PLANNED_TOTAL_SEQUENCES_SEEN, set PLANNED_TOTAL_STEPS to -1 (PLANNED TOTAL STEPS will be based on the train batch size used, which can be specified later)\n",
        "PLANNED_TOTAL_STEPS = 8000 #@param {type:\"number\"}\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaNhPg7sG2DS"
      },
      "source": [
        "#If running on a GCP runtime, follow these instructions to set it up:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gicp021G3Xd"
      },
      "source": [
        "###1) Create a VM from the GCP website\n",
        "###2) Open a command prompt on your computer and perform the following steps\"\n",
        "To ssh into the VM:\n",
        "\n",
        "```\n",
        "gcloud beta compute ssh --zone <COMPUTE ZONE> <VM NAME> --project <PROJECT NAME> -- -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "Note: Make sure the port above matches the port below (in this case it's 8888)\n",
        "\\\n",
        "\\\n",
        "Run each of these commands individually, or copy and paste the one command below:\n",
        "```\n",
        "sudo apt-get update\n",
        "sudo apt-get -y install python3 python3-pip\n",
        "sudo apt-get install pkg-config\n",
        "sudo apt-get install libhdf5-serial-dev\n",
        "sudo apt-get install libffi6 libffi-dev\n",
        "sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm\n",
        "sudo -H pip3 install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "One command:\n",
        "```\n",
        "sudo apt-get update ; sudo apt-get -y install python3 python3-pip ; sudo apt-get install pkg-config ; sudo apt-get -y install libhdf5-serial-dev ; sudo apt-get install libffi6 libffi-dev; sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm ; sudo -H pip3 install jupyter_http_over_ws ; jupyter serverextension enable --py jupyter_http_over_ws ; jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "###3) In this notebook, to connect to this runtime, click the \"connect to local runtime\" option under the connect button, and copy and paste the outputted link with \"locahost: ...\"\n",
        "###4) Finally, run this code segment, which creates a TPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbFX7QwQG67i"
      },
      "source": [
        "GCE_PROJECT_NAME = \"genome-project-319100\" #@param {type:\"string\"}\n",
        "TPU_ZONE = \"us-central1-f\" #@param {type:\"string\"}\n",
        "TPU_NAME = \"mutformer-tpu\" #@param {type:\"string\"}\n",
        "\n",
        "!gcloud alpha compute tpus create $TPU_NAME --accelerator-type=tpu-v2 --version=1.15.5 --zone=$TPU_ZONE ##create new TPU\n",
        "\n",
        "!gsutil iam ch serviceAccount:`gcloud alpha compute tpus describe $TPU_NAME | grep serviceAccount | cut -d' ' -f2`:admin gs://theodore_jiang && echo 'Successfully set permissions!' ##give TPU access to GCS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXZaQIt1SXQv"
      },
      "source": [
        "#Clone the MutFormer repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L470I2VGCLTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb005ee-ffd1-4310-c903-fc0e2b730ea7"
      },
      "source": [
        "if USE_GCP_RUNTIME:\n",
        "  !sudo apt-get -y install git\n",
        "#@markdown ######Where to clone the repo into (only value that it can't be is \"mutformer\"):\n",
        "REPO_DESTINATION_PATH = \"code/mutformer\" #@param {type:\"string\"}\n",
        "import os,shutil\n",
        "if not os.path.exists(REPO_DESTINATION_PATH):\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "else:\n",
        "  shutil.rmtree(REPO_DESTINATION_PATH)\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "cmd = \"git clone https://github.com/WGLab/mutformer.git \\\"\" + REPO_DESTINATION_PATH + \"\\\"\"\n",
        "!{cmd}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code/mutformer'...\n",
            "remote: Enumerating objects: 462, done.\u001b[K\n",
            "remote: Counting objects: 100% (263/263), done.\u001b[K\n",
            "remote: Compressing objects: 100% (229/229), done.\u001b[K\n",
            "remote: Total 462 (delta 188), reused 38 (delta 33), pack-reused 199\u001b[K\n",
            "Receiving objects: 100% (462/462), 2.08 MiB | 12.34 MiB/s, done.\n",
            "Resolving deltas: 100% (299/299), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj1mClhQQE_n"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aad51d7-2a13-4ec3-d59a-5607d7575435"
      },
      "source": [
        "if not USE_GCP_RUNTIME:\n",
        "  %tensorflow_version 1.x\n",
        "  from google.colab import auth\n",
        "  print(\"Authorize for GCS:\")\n",
        "  auth.authenticate_user()\n",
        "  print(\"Authorize done\")\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import importlib\n",
        "\n",
        "if not os.path.exists(\"mutformer\"):\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "else:\n",
        "  shutil.rmtree(\"mutformer\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "if \"mutformer\" in sys.path:\n",
        "  sys.path.remove(\"mutformer\")\n",
        "sys.path.append(\"mutformer\")\n",
        "\n",
        "from mutformer import modeling, optimization, tokenization,run_classifier,run_ner_for_pathogenic\n",
        "from mutformer.modeling import BertModel,BertModelModified\n",
        "from mutformer.run_classifier import MrpcProcessor,REProcessor,MrpcWithPredsProcessor ##change this part if you add more modes--\n",
        "from mutformer.run_ner_for_pathogenic import NERProcessor      ##--\n",
        "\n",
        "##reload modules in case that's needed\n",
        "modules2reload = [modeling, \n",
        "                  optimization, \n",
        "                  tokenization,\n",
        "                  run_classifier,\n",
        "                  run_ner_for_pathogenic]\n",
        "for module in modules2reload:\n",
        "    importlib.reload(module)\n",
        "\n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "log.handlers = []\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "#@markdown ###### Whether or not to write logs to a file\n",
        "DO_FILE_LOGGING = True #@param {type:\"boolean\"}\n",
        "if DO_FILE_LOGGING:\n",
        "  #@markdown ###### If using file logging, what path to write logs to\n",
        "  FILE_LOGGING_PATH = 'file_logging/spam.log' #@param {type:\"string\"}\n",
        "  if not os.path.exists(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1])):\n",
        "    os.makedirs(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1]))\n",
        "  fh = logging.FileHandler(FILE_LOGGING_PATH)\n",
        "  fh.setLevel(logging.INFO)\n",
        "  fh.setFormatter(formatter)\n",
        "  log.addHandler(fh)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "log.handlers = [fh,ch]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "\n",
        "\n",
        "if MODE==\"MRPC\": ##change this part if you added more modes\n",
        "  processor = MrpcProcessor()\n",
        "  script = run_classifier\n",
        "elif MODE==\"MRPC_w_ex_data\":\n",
        "  processor = MrpcWithPredsProcessor()\n",
        "  script = run_classifier\n",
        "elif MODE==\"RE\":\n",
        "  processor = REProcessor()\n",
        "  script = run_classifier\n",
        "elif MODE==\"NER\":\n",
        "  processor = NERProcessor()\n",
        "  script = run_ner_for_pathogenic\n",
        "else:\n",
        "  raise Exception(\"The mode specified was not one of the available modes: [\\\"MRPC\\\",\\\"MRPC_w_ex_data\\\" \\\"RE\\\",\\\"NER\\\"].\")\n",
        "label_list = processor.get_labels()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-21 07:28:19,208 - tensorflow - INFO - Using TPU runtime\n",
            "2021-12-21 07:28:19,211 - tensorflow - INFO - TPU address is grpc://10.87.144.74:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authorize for GCS:\n",
            "Authorize done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb0TXw9GtCKz"
      },
      "source": [
        "#Select preference for communication with eval script/Mount drive if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYsYBUCJMTdz"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "#@markdown ###### Note: for all of these, if using USE_GCP_RUNTIME, all of these parameters must use GCS, because a GCP TPU can't access google drive\n",
        "#@markdown \\\n",
        "DRIVE_PATH = \"/content/drive/My Drive\"\n",
        "BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "#@markdown whether to use GCS for communicating with the evaluation script (to inform it of which model to evaluate during parallel training/eval), if set to False, communication will defaults to drive. If using USE_GCP_RUNTIME, communication will default to GCS\n",
        "GCS_COMS = True #@param {type:\"boolean\"}\n",
        "\n",
        "COMS_PATH = BUCKET_PATH if GCS_COMS or USE_GCP_RUNTIME else DRIVE_PATH\n",
        "\n",
        "if COMS_PATH==DRIVE_PATH:\n",
        "  from google.colab import drive,auth\n",
        "  !fusermount -u /content/drive\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  \n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkFC96e0cK6n"
      },
      "source": [
        "# Run Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This following section will perform finetuning tests for testing different models' performance with different parameters."
      ],
      "metadata": {
        "id": "pdWEQQ0vWBKU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ_lmHSa7ct_"
      },
      "source": [
        "###General definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bpaa3Eo7h8W"
      },
      "source": [
        "def latest_checkpoint(dir):\n",
        "  cmd = \"gsutil ls \"+dir\n",
        "  files = !{cmd}\n",
        "  for file in files:\n",
        "    if \"model.ckpt\" in file:\n",
        "      return file.replace(\".\"+file.split(\".\")[-1],\"\")\n",
        "\n",
        "def correct_path(path):\n",
        "  return path.replace(\"/:::::\",\"\")\n",
        "\n",
        "def training_loop(BATCH_SIZE,\n",
        "                  RESUMING,\n",
        "                  PLANNED_TOTAL_STEPS,\n",
        "                  DECAY_PER_STEP,\n",
        "                  DATA_SEQ_LENGTH,\n",
        "                  MODEL_NAME,\n",
        "                  MODEL,\n",
        "                  INIT_CHECKPOINT_DIR,\n",
        "                  BERT_GCS_DIR,\n",
        "                  DATA_GCS_DIR,\n",
        "                  USING_SHARDS,\n",
        "                  START_SHARD,\n",
        "                  USING_EX_DATA,\n",
        "                  PRED_NUM,\n",
        "                  GCS_LOGGING_DIR,\n",
        "                  CONFIG_FILE):\n",
        "  \n",
        "  RESTORE_CHECKPOINT = None if not RESUMING else tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "  if not RESUMING:\n",
        "    cmd = \"gsutil -m rm -r \"+BERT_GCS_DIR\n",
        "    !{cmd}\n",
        "\n",
        "  try: \n",
        "    INIT_CHECKPOINT = tf.train.latest_checkpoint(INIT_CHECKPOINT_DIR)\n",
        "  except:\n",
        "    INIT_CHECKPOINT = latest_checkpoint(INIT_CHECKPOINT_DIR)\n",
        "  print(\"init checkpoint:\",INIT_CHECKPOINT,\"restore/save checkpont:\",RESTORE_CHECKPOINT)\n",
        "\n",
        "  config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "  config.hidden_dropout_prob = 0.1\n",
        "  config.attention_probs_dropout_prob = 0.1\n",
        "\n",
        "  model_fn = script.model_fn_builder(\n",
        "      bert_config=config,\n",
        "      logging_dir=GCS_LOGGING_DIR,\n",
        "      num_labels=len(label_list),\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      restore_checkpoint=RESTORE_CHECKPOINT,\n",
        "      init_learning_rate=INIT_LEARNING_RATE,\n",
        "      decay_per_step=DECAY_PER_STEP,\n",
        "      num_warmup_steps=10,\n",
        "      use_tpu=True,\n",
        "      use_one_hot_embeddings=True,\n",
        "      bert=MODEL,\n",
        "      weight_decay=0.01,\n",
        "      epsilon=1e-6,\n",
        "      clip_grads=False,\n",
        "      using_preds=USING_EX_DATA)\n",
        "\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      model_dir=BERT_GCS_DIR,\n",
        "      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "      keep_checkpoint_max=KEEP_N_CHECKPOINTS_AT_A_TIME,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "          num_shards=NUM_TPU_CORES,\n",
        "          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=True,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=BATCH_SIZE)\n",
        "  \n",
        "  train_file_name = \"train.tf_record\"\n",
        "  train_file = os.path.join(DATA_GCS_DIR, train_file_name)\n",
        "\n",
        "  if USING_SHARDS:\n",
        "    shards_folder = DATA_GCS_DIR\n",
        "    input_file = os.path.join(DATA_GCS_DIR, train_file_name)\n",
        "    import re\n",
        "    file_name = input_file.split(\"/\")[-1]\n",
        "    shards = [shards_folder + \"/\" + file for file in tf.io.gfile.listdir(shards_folder) if\n",
        "              re.match(file_name + \"_\\d+\", file)]\n",
        "    shards = sorted(shards,key=lambda shard:int(shard.split(\"_\")[-1]))[START_SHARD:]\n",
        "  else:\n",
        "    shards = [train_file]\n",
        "\n",
        "  if USING_SHARDS:\n",
        "    print(\"\\nUSING SHARDs:\")\n",
        "    for shard in shards:\n",
        "      print(shard)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  tf.logging.info(\"***** Running training *****\")\n",
        "  tf.logging.info(\"  Batch size = %d\", BATCH_SIZE)\n",
        "  for n,shard in enumerate(shards):\n",
        "      train_input_fn = script.file_based_input_fn_builder(\n",
        "          input_file=shard,\n",
        "          seq_length=DATA_SEQ_LENGTH,\n",
        "          is_training=True,\n",
        "          drop_remainder=True,\n",
        "          pred_num=PRED_NUM if USING_EX_DATA else None)\n",
        "      try:\n",
        "        tf.gfile.Open(COMS_PATH+\"/finetuning_run_paired_model.txt\",\"w+\").write(MODEL_NAME)\n",
        "        tf.gfile.Open(COMS_PATH+\"/finetuning_run_paired_seq_length.txt\",\"w+\").write(str(DATA_SEQ_LENGTH))\n",
        "        tf.gfile.Open(COMS_PATH+\"/finetuning_run_paired_batch_size.txt\",\"w+\").write(str(BATCH_SIZE))\n",
        "      except:\n",
        "        pass\n",
        "      estimator.train(input_fn=train_input_fn, max_steps=PLANNED_TOTAL_STEPS)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training Loops"
      ],
      "metadata": {
        "id": "lrgQPrH4kZV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following are three code segments to run. These options are:\n",
        "1. Model/sequence length: different model architectures will be tested using a fixed batch size on data of varying sequence lengths \\\n",
        "2. Sequence length/batch size: one model architecture will be tested using varying batch sizes on data of varying sequence lengths\\\n",
        "3. One model: one model architecture will be tested using a fixed batch size on a fixed set of data of a given sequence length\n",
        "\n",
        "Note: During training, evaluation results on the training dataset will be written into GCS. To view these results, use the colab notebook titled \"mutformer processing and viewing finetuning results.\""
      ],
      "metadata": {
        "id": "Xqe2NOckb6OR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AjnVKSMlVXz"
      },
      "source": [
        "####Model/sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCuEbr6dv8U"
      },
      "source": [
        "#@markdown Train batch size to use\n",
        "BATCH_SIZE=16 #@param\n",
        "#@markdown List of folder names for models to test\n",
        "MODELS = [\"bert_model_modified_medium\",\"bert_model_modified_large\"] #@param\n",
        "#@markdown List of model architectures for the variable \"MODELS\" defined in the entry above. NOTE: each position in this list must correspond correctly with each position in \"MODELS.\" BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture\n",
        "MODEL_ARCHITECTURES = [BertModelModified,BertModelModified] #@param\n",
        "#@markdown List of maximum sequence lengths to test\n",
        "lengths = [256,512,1024] #@param\n",
        "#@markdown Which folder inside of LOGGING_DIR to store the logs in\n",
        "RUN_NAME = \"MRPC_adding_preds_mn_sl_testing\" #@param {type:\"string\"}\n",
        "#@markdown Whether or not to resume training from a previous finetuned checkpoint; if no, always train from pretrained model\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown whether or not training data was generated in shards (for really large databases)\n",
        "USING_SHARDS = True #@param {type:\"boolean\"}\n",
        "#@markdown if using shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD =   0#@param {type:\"integer\"}\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/BATCH_SIZE) \n",
        "\n",
        "for DATA_SEQ_LENGTH in lengths:\n",
        "  for m,MODEL_NAME in MODELS:\n",
        "    print(\"\\n\\n\\nMODEL NAME:\",MODEL_NAME,\n",
        "          \"\\nINPUT MAX SEQ LENGTH:\",DATA_SEQ_LENGTH,\n",
        "          \"\\nTRAIN_BATCH_SIZE:\",BATCH_SIZE,\"\\n\\n\\n\")\n",
        "\n",
        "    MODEL = MODEL_ARCHITECTURES[m]\n",
        "    INIT_CHECKPOINT_DIR = correct_path(BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME)\n",
        "    BERT_GCS_DIR = correct_path(BUCKET_PATH+\"/\"+OUTPUT_MODEL_DIR+\"/mn_\"+MODEL_NAME+\"_sl_\"+str(DATA_SEQ_LENGTH))\n",
        "    DATA_GCS_DIR = BUCKET_PATH+\"/\"+DATA_DIR+\"/\"+str(DATA_SEQ_LENGTH)\n",
        "    \n",
        "    GCS_LOGGING_DIR = BUCKET_PATH+\"/\"+LOGGING_DIR+\"/\"+RUN_NAME+\"/mn_\"+MODEL_NAME+\"_sl_\"+str(DATA_SEQ_LENGTH)\n",
        "\n",
        "    CONFIG_FILE = correct_path(BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME+\"/config.json\")\n",
        "\n",
        "    training_loop(BATCH_SIZE,\n",
        "                  RESUMING,\n",
        "                  PLANNED_TOTAL_STEPS,\n",
        "                  DECAY_PER_STEP,\n",
        "                  DATA_SEQ_LENGTH,\n",
        "                  MODEL_NAME,\n",
        "                  MODEL,\n",
        "                  INIT_CHECKPOINT_DIR,\n",
        "                  BERT_GCS_DIR,\n",
        "                  DATA_GCS_DIR,\n",
        "                  USING_SHARDS,\n",
        "                  START_SHARD,\n",
        "                  USING_EX_DATA,\n",
        "                  PRED_NUM,\n",
        "                  GCS_LOGGING_DIR,\n",
        "                  CONFIG_FILE)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ322RGr5ykF"
      },
      "source": [
        "####Batch size/sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IytLW0VbgOZz"
      },
      "source": [
        "#@markdown list of batch sizes to test\n",
        "batch_sizes = [64] #@param\n",
        "#@markdown list of maximum sequence lengths to test\n",
        "lengths = [1024] #@param\n",
        "#@markdown model to load from inside the specified INIT_MODEL_DIR\n",
        "MODEL_NAME=\"bert_model_modified_large\" #@param {type:\"string\"}\n",
        "#@markdown model architecture to use BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture\n",
        "MODEL_ARCHITECTURE = BertModelModified #@param\n",
        "#@markdown Which folder inside of LOGGING_DIR to store the logs in\n",
        "RUN_NAME = \"MRPC_adding_preds_bs_sl_testing\" #@param {type:\"string\"}\n",
        "#@markdown whether or not to resume training from a previous finetuned checkpoint; if no, always train from pretrained model\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown whether or not training data was generated in shards (for really large databases)\n",
        "USING_SHARDS = True #@param {type:\"boolean\"}\n",
        "#@markdown if using shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD =   0#@param {type:\"integer\"}\n",
        "\n",
        "BUCKET_PATH = \"gs://\"+BUCKET_NAME\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/BATCH_SIZE) \n",
        "\n",
        "for DATA_SEQ_LENGTH in lengths:\n",
        "    for BATCH_SIZE in batch_sizes:\n",
        "        print(\"\\n\\n\\nMODEL NAME:\",MODEL_NAME,\n",
        "              \"\\nINPUT MAX SEQ LENGTH:\",DATA_SEQ_LENGTH,\n",
        "              \"\\nTRAIN_BATCH_SIZE:\",BATCH_SIZE,\"\\n\\n\\n\")\n",
        "       \n",
        "        MODEL = MODEL_ARCHITECTURE\n",
        "        INIT_CHECKPOINT_DIR = correct_path(BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME)\n",
        "        BERT_GCS_DIR = correct_path(BUCKET_PATH+\"/\"+OUTPUT_MODEL_DIR+\"/mn_\"+MODEL_NAME+\"_sl_\"+str(DATA_SEQ_LENGTH)+\"_bs_\"+str(BATCH_SIZE))\n",
        "        DATA_GCS_DIR = BUCKET_PATH+\"/\"+DATA_DIR+\"/\"+str(DATA_SEQ_LENGTH)\n",
        "      \n",
        "        GCS_LOGGING_DIR = BUCKET_PATH+\"/\"+LOGGING_DIR+\"/\"+RUN_NAME+\"/mn_\"+MODEL_NAME+\"_sl_\"+str(DATA_SEQ_LENGTH)+\"_bs_\"+str(BATCH_SIZE)\n",
        "        \n",
        "        CONFIG_FILE = correct_path(BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME+\"/config.json\")\n",
        "\n",
        "        training_loop(BATCH_SIZE,\n",
        "                      RESUMING,\n",
        "                      PLANNED_TOTAL_STEPS,\n",
        "                      DECAY_PER_STEP,\n",
        "                      DATA_SEQ_LENGTH,\n",
        "                      MODEL_NAME,\n",
        "                      MODEL,\n",
        "                      INIT_CHECKPOINT_DIR,\n",
        "                      BERT_GCS_DIR,\n",
        "                      DATA_GCS_DIR,\n",
        "                      USING_SHARDS,\n",
        "                      START_SHARD,\n",
        "                      USING_EX_DATA,\n",
        "                      PRED_NUM,\n",
        "                      GCS_LOGGING_DIR,\n",
        "                      CONFIG_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tswiJYA_qCUq"
      },
      "source": [
        "####One model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK3tf7aWqIiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2577ae5-7839-4506-cb14-5239773031b5"
      },
      "source": [
        "#@markdown batch size to use\n",
        "BATCH_SIZE = 32 #@param\n",
        "#@markdown maximum sequence length to use\n",
        "DATA_SEQ_LENGTH = 512 #@param\n",
        "#@markdown model to load from inside the specified INIT_MODEL_DIR\n",
        "MODEL_NAME=\"bert_model_modified_large\" #@param {type:\"string\"}\n",
        "#@markdown model architecture to use BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture\n",
        "MODEL_ARCHITECTURE = BertModelModified #@param\n",
        "#@markdown Which folder inside of LOGGING_DIR to store the logs in\n",
        "RUN_NAME = \"MRPC_adding_preds_w_mutformer12L\" #@param {type:\"string\"}\n",
        "#@markdown whether or not to resume training from a previous checkpoint; if no, always train from scratch\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown whether or not training data was generated in shards (for really large databases)\n",
        "USING_SHARDS = False #@param {type:\"boolean\"}\n",
        "#@markdown if using shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD =   0#@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/BATCH_SIZE) \n",
        "\n",
        "\n",
        "print(\"\\n\\n\\nMODEL NAME:\",MODEL_NAME,\n",
        "      \"\\nINPUT MAX SEQ LENGTH:\",DATA_SEQ_LENGTH,\n",
        "      \"\\nTRAIN_BATCH_SIZE:\",BATCH_SIZE,\"\\n\\n\\n\")\n",
        "\n",
        "MODEL = MODEL_ARCHITECTURE\n",
        "INIT_CHECKPOINT_DIR = correct_path(BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME)\n",
        "BERT_GCS_DIR = correct_path(BUCKET_PATH+\"/\"+OUTPUT_MODEL_DIR)\n",
        "DATA_GCS_DIR = BUCKET_PATH+\"/\"+DATA_DIR+\"/\"+str(DATA_SEQ_LENGTH)\n",
        "\n",
        "GCS_LOGGING_DIR = BUCKET_PATH+\"/\"+LOGGING_DIR+\"/\"+RUN_NAME\n",
        "\n",
        "CONFIG_FILE = correct_path(BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME+\"/config.json\")\n",
        "\n",
        "\n",
        "training_loop(BATCH_SIZE,\n",
        "              RESUMING,\n",
        "              PLANNED_TOTAL_STEPS,\n",
        "              DECAY_PER_STEP,\n",
        "              DATA_SEQ_LENGTH,\n",
        "              MODEL_NAME,\n",
        "              MODEL,\n",
        "              INIT_CHECKPOINT_DIR,\n",
        "              BERT_GCS_DIR,\n",
        "              DATA_GCS_DIR,\n",
        "              USING_SHARDS,\n",
        "              START_SHARD,\n",
        "              USING_EX_DATA,\n",
        "              PRED_NUM,\n",
        "              GCS_LOGGING_DIR,\n",
        "              CONFIG_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "MODEL NAME: bert_model_modified_large \n",
            "INPUT MAX SEQ LENGTH: 512 \n",
            "TRAIN_BATCH_SIZE: 32 \n",
            "\n",
            "\n",
            "\n",
            "CommandException: 1 files/objects could not be removed.\n",
            "init checkpoint: gs://theodore_jiang/bert_model_modified_large/model.ckpt-2002192 restore/save checkpont: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-21 07:30:05,521 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fefade28dd0>) includes params argument, but params are not passed to Estimator.\n",
            "2021-12-21 07:30:05,524 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_adding_preds', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.87.144.74:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fefadcee8d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.87.144.74:8470', '_evaluation_master': 'grpc://10.87.144.74:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fefadcb3650>}\n",
            "2021-12-21 07:30:05,525 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2021-12-21 07:30:05,526 - tensorflow - INFO - ***** Running training *****\n",
            "2021-12-21 07:30:05,527 - tensorflow - INFO -   Batch size = 32\n",
            "2021-12-21 07:30:05,529 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:347: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2021-12-21 07:30:06,492 - tensorflow - INFO - Querying Tensorflow master (grpc://10.87.144.74:8470) for TPU system metadata.\n",
            "2021-12-21 07:30:06,507 - tensorflow - INFO - Found TPU system:\n",
            "2021-12-21 07:30:06,508 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2021-12-21 07:30:06,510 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2021-12-21 07:30:06,510 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2021-12-21 07:30:06,512 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 17538374278302925149)\n",
            "2021-12-21 07:30:06,513 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10337975717371395752)\n",
            "2021-12-21 07:30:06,514 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6993941311487397428)\n",
            "2021-12-21 07:30:06,515 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9264568310374662776)\n",
            "2021-12-21 07:30:06,516 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 2312544972306951951)\n",
            "2021-12-21 07:30:06,518 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15074723622036418906)\n",
            "2021-12-21 07:30:06,519 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4455409972076676999)\n",
            "2021-12-21 07:30:06,520 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7437987645505247514)\n",
            "2021-12-21 07:30:06,521 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17112906964965834592)\n",
            "2021-12-21 07:30:06,522 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 16580149862834910974)\n",
            "2021-12-21 07:30:06,523 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12405183274482745959)\n",
            "2021-12-21 07:30:06,536 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2021-12-21 07:30:06,538 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2021-12-21 07:30:06,550 - tensorflow - INFO - Calling model_fn.\n",
            "2021-12-21 07:30:06,713 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:403: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2021-12-21 07:30:06,715 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2021-12-21 07:30:06,728 - tensorflow - WARNING - Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fede9e5f050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2021-12-21 07:30:06,730 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:365: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2021-12-21 07:30:06,745 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:372: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-12-21 07:30:06,830 - tensorflow - INFO - *** Features ***\n",
            "2021-12-21 07:30:06,831 - tensorflow - INFO -   name = input_ids, shape = (4, 512)\n",
            "2021-12-21 07:30:06,832 - tensorflow - INFO -   name = input_mask, shape = (4, 512)\n",
            "2021-12-21 07:30:06,833 - tensorflow - INFO -   name = is_real_example, shape = (4,)\n",
            "2021-12-21 07:30:06,834 - tensorflow - INFO -   name = label_ids, shape = (4,)\n",
            "2021-12-21 07:30:06,835 - tensorflow - INFO -   name = preds, shape = (4, 27)\n",
            "2021-12-21 07:30:06,836 - tensorflow - INFO -   name = segment_ids, shape = (4, 512)\n",
            "2021-12-21 07:30:06,837 - tensorflow - WARNING - From /content/mutformer/modeling.py:299: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2021-12-21 07:30:06,844 - tensorflow - WARNING - From /content/mutformer/modeling.py:657: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2021-12-21 07:30:06,879 - tensorflow - WARNING - From /content/mutformer/modeling.py:738: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fede9e5f050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "step 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-21 07:30:06,936 - tensorflow - WARNING - From /content/mutformer/modeling.py:606: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2021-12-21 07:30:07,056 - tensorflow - WARNING - From /content/mutformer/modeling.py:989: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2021-12-21 07:30:07,058 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2021-12-21 07:30:09,835 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:525: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape1 (4, 768)\n",
            "shape2 (4, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-21 07:30:10,606 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2021-12-21 07:30:10,609 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,610 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,612 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,614 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,616 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,617 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,619 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,621 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,623 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,625 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,626 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,627 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,629 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,631 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,632 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,633 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,634 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,636 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,637 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,638 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,639 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,643 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,649 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,650 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,652 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,654 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,656 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,657 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,658 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,659 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,661 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,663 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,666 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,667 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,669 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,670 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,671 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,673 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,674 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,675 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,677 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,678 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,679 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,681 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,683 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,684 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,686 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,687 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,689 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,690 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,691 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,692 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,694 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,696 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,698 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,699 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,700 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,702 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,704 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,705 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,707 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,708 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,709 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,710 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,712 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,713 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,714 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,716 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,717 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,718 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,720 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,722 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,723 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,724 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,725 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,726 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,728 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,729 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,730 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,731 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,732 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,735 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,737 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,738 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,740 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,741 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,742 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,744 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,747 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,749 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,751 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,754 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,755 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,756 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,757 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,759 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,760 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,761 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,762 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,764 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,765 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,766 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,767 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,769 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,771 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,772 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,773 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,774 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,776 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,778 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,780 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,782 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,783 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,784 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,785 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,787 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,789 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,790 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,792 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,793 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,794 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,795 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,796 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,797 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,799 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,800 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,801 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,802 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,804 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,805 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,808 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,809 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,810 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,811 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,812 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,814 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,815 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,818 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,820 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,821 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,824 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,825 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,828 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,829 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,831 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,832 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,833 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,834 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,835 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,836 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,838 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,839 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,841 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,842 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,843 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,845 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,847 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,848 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,851 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,852 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,853 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,854 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,855 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,856 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,857 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,859 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,860 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,861 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,862 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,863 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,864 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,866 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,867 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,868 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,869 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,870 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,871 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,873 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,874 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,875 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,877 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,878 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,879 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,880 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,881 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,882 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,883 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,884 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,886 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,887 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,888 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,889 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,890 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,891 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,893 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,894 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,895 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,896 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,897 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,898 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,899 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,901 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,902 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-21 07:30:10,903 - tensorflow - INFO -   name = extra_data_layers/pred_dense/kernel:0, shape = (27, 768), *INIT_NEW*\n",
            "2021-12-21 07:30:10,906 - tensorflow - INFO -   name = extra_data_layers/pred_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2021-12-21 07:30:10,909 - tensorflow - INFO -   name = extra_data_layers/combine_dense/kernel:0, shape = (1536, 768), *INIT_NEW*\n",
            "2021-12-21 07:30:10,910 - tensorflow - INFO -   name = extra_data_layers/combine_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2021-12-21 07:30:10,911 - tensorflow - INFO -   name = output_weights:0, shape = (2, 768), *INIT_NEW*\n",
            "2021-12-21 07:30:10,912 - tensorflow - INFO -   name = output_bias:0, shape = (2,), *INIT_NEW*\n",
            "2021-12-21 07:30:10,913 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:571: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2021-12-21 07:30:11,286 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2021-12-21 07:30:21,268 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:534: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 2) (4, 2) (4, 1)\n",
            "acctot: Tensor(\"Sum_13:0\", shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-21 07:30:21,538 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:539: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "2021-12-21 07:30:22,796 - tensorflow - INFO - Create CheckpointSaverHook.\n",
            "2021-12-21 07:30:23,149 - tensorflow - INFO - Done calling model_fn.\n",
            "2021-12-21 07:30:26,113 - tensorflow - INFO - TPU job name worker\n",
            "2021-12-21 07:30:27,636 - tensorflow - INFO - Graph was finalized.\n",
            "2021-12-21 07:30:33,198 - tensorflow - INFO - Restoring parameters from gs://theodore_jiang/bert_model_modified_large/model.ckpt-2002192\n",
            "2021-12-21 07:30:45,436 - tensorflow - INFO - Running local_init_op.\n",
            "2021-12-21 07:30:45,891 - tensorflow - INFO - Done running local_init_op.\n",
            "2021-12-21 07:30:54,147 - tensorflow - INFO - Saving checkpoints for 0 into gs://theodore_jiang/bert_model_mrpc_adding_preds/model.ckpt.\n",
            "2021-12-21 07:31:10,313 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2021-12-21 07:31:11,312 - tensorflow - INFO - Initialized dataset iterators in 0 seconds\n",
            "2021-12-21 07:31:11,313 - tensorflow - INFO - Installing graceful shutdown hook.\n",
            "2021-12-21 07:31:11,319 - tensorflow - INFO - Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2021-12-21 07:31:11,324 - tensorflow - INFO - Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2021-12-21 07:31:11,328 - tensorflow - INFO - Init TPU system\n",
            "2021-12-21 07:31:37,470 - tensorflow - INFO - Initialized TPU in 26 seconds\n",
            "2021-12-21 07:31:38,999 - tensorflow - INFO - Starting infeed thread controller.\n",
            "2021-12-21 07:31:39,001 - tensorflow - INFO - Starting outfeed thread controller.\n",
            "2021-12-21 07:31:39,472 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-21 07:31:39,473 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-21 07:32:12,794 - tensorflow - INFO - Outfeed finished for iteration (0, 0)\n",
            "2021-12-21 07:33:13,031 - tensorflow - INFO - Outfeed finished for iteration (0, 260)\n",
            "2021-12-21 07:34:47,690 - tensorflow - INFO - Outfeed finished for iteration (0, 467)\n",
            "2021-12-21 07:35:49,355 - tensorflow - INFO - Outfeed finished for iteration (0, 652)\n",
            "2021-12-21 07:36:49,639 - tensorflow - INFO - Outfeed finished for iteration (0, 846)\n",
            "2021-12-21 07:37:00,667 - tensorflow - INFO - Saving checkpoints for 1000 into gs://theodore_jiang/bert_model_mrpc_adding_preds/model.ckpt.\n",
            "2021-12-21 07:37:24,718 - tensorflow - INFO - loss = 2.3006575, step = 1000\n",
            "2021-12-21 07:37:24,722 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-21 07:37:24,723 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-21 07:37:50,040 - tensorflow - INFO - Outfeed finished for iteration (0, 960)\n",
            "2021-12-21 07:38:50,633 - tensorflow - INFO - Outfeed finished for iteration (1, 103)\n",
            "2021-12-21 07:39:51,202 - tensorflow - INFO - Outfeed finished for iteration (1, 228)\n",
            "2021-12-21 07:40:52,193 - tensorflow - INFO - Outfeed finished for iteration (1, 374)\n",
            "2021-12-21 07:41:52,427 - tensorflow - INFO - Outfeed finished for iteration (1, 554)\n",
            "2021-12-21 07:42:52,532 - tensorflow - INFO - Outfeed finished for iteration (1, 785)\n",
            "2021-12-21 07:43:18,202 - tensorflow - INFO - Saving checkpoints for 2000 into gs://theodore_jiang/bert_model_mrpc_adding_preds/model.ckpt.\n",
            "2021-12-21 07:43:40,528 - tensorflow - INFO - loss = 0.21956101, step = 2000 (375.811 sec)\n",
            "2021-12-21 07:43:40,531 - tensorflow - INFO - global_step/sec: 2.66091\n",
            "2021-12-21 07:43:40,533 - tensorflow - INFO - examples/sec: 85.1492\n",
            "2021-12-21 07:43:40,537 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-21 07:43:40,538 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-21 07:43:52,954 - tensorflow - INFO - Outfeed finished for iteration (1, 990)\n"
          ]
        }
      ]
    }
  ]
}