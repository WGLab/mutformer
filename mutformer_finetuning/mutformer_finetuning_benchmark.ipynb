{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "mutformer finetuning benchmark",
      "provenance": [],
      "collapsed_sections": [
        "SaNhPg7sG2DS",
        "9AjnVKSMlVXz",
        "WQ322RGr5ykF"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHNq3MSTTea"
      },
      "source": [
        "Performs finetuning with varying batch sizes, models, and sequence lengths in order to find the best model. Note that support for running this file on a GCP TPU is not included since this file should not need more memory than google colab provides and does not require constant uptime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_"
      },
      "source": [
        "# Configure settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozmx1LCLw3SQ"
      },
      "source": [
        "#@markdown ## General Config\n",
        "#@markdown If preferred, a GCP TPU/runtime can be used to run this notebook\n",
        "USE_GCP_TPU = False #@param {type:\"boolean\"}\n",
        "#@markdown Which task to perform: options are \"MRPC\" for paired sequence method, \"MRPC_w_preds\" for paired sequence method with external data, \"RE\" for single sequence method, or \"NER\" for single sequance per residue prediction (if you add more modes make sure to change the corresponding code segments)\n",
        "MODE = \"MRPC_w_preds\" #@param {type:\"string\"}\n",
        "MAX_SEQ_LENGTH =  1024#@param {type:\"integer\"}\n",
        "PROCESSES = 2 #@param {type:\"integer\"}\n",
        "BUCKET_NAME = \"theodore_jiang\" #@param {type:\"string\"}\n",
        "#@markdown ###### For if multiple models fine tuned: xxx is the placeholder for the individual model identifier (if only one is being evaluated replace xx with the actual name of the model)\n",
        "#@markdown \\\n",
        "#@markdown folder for where to save the finetuned model\n",
        "MODEL_DIR_format = \"bert_model_mrpc_adding_preds_xxx\" #@param {type:\"string\"}\n",
        "#@markdown folder for the pretrained model\n",
        "INIT_MODEL_DIR_format = \"bert_model_xxx\" #@param {type:\"string\"}\n",
        "DATA_DIR_format = \"MRPC_adding_preds_xxx\" #@param {type:\"string\"}\n",
        "LOGGING_DIR = \"mrpc_loss_spam_model_comparison_final\" #@param {type:\"string\"}\n",
        "RUN_NAME_format = \"MRPC_adding_preds_xxx\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Training procedure config\n",
        "INIT_LEARNING_RATE =  1e-5 #@param {type:\"number\"}\n",
        "END_LEARNING_RATE = 5e-7 #@param {type:\"number\"}\n",
        "SAVE_CHECKPOINTS_STEPS =  1000 #@param {type:\"integer\"}\n",
        "#@markdown ###### TPUEstimator will keep this number of checkpoints; older checkpoints will all be deleted\n",
        "KEEP_N_CHECKPOINTS_AT_A_TIME =  10#@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8 #@param {type:\"number\"}\n",
        "PLANNED_TOTAL_SEQUENCES_SEEN =  2e5 #@param {type:\"number\"}\n",
        "#@markdown PLANNED_TOTAL_STEPS will override PLANNED_TOTAL_SEQUENCES_SEEN; if using PLANNED_TOTAL_SEQUENCES_SEEN, set PLANNED_TOTAL_STEPS to -1 (PLANNED TOTAL STEPS will be based on the train batch size used)\n",
        "PLANNED_TOTAL_STEPS = 8000 #@param {type:\"number\"}\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaNhPg7sG2DS"
      },
      "source": [
        "#If running on a GCP TPU, use these commands prior to running this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gicp021G3Xd"
      },
      "source": [
        "To ssh into the VM:\n",
        "\n",
        "```\n",
        "gcloud beta compute ssh --zone <COMPUTE ZONE> <VM NAME> --project <PROJECT NAME> -- -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "Make sure the port above matches the port below (in this case it's 8888)\n",
        "\n",
        "```\n",
        "sudo apt-get update\n",
        "sudo apt-get -y install python3 python3-pip\n",
        "sudo apt-get install pkg-config\n",
        "sudo apt-get install libhdf5-serial-dev\n",
        "sudo apt-get install libffi6 libffi-dev\n",
        "sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm\n",
        "sudo -H pip3 install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "\n",
        "(one command):sudo apt-get update ; sudo apt-get -y install python3 python3-pip ; sudo apt-get install pkg-config ; sudo apt-get -y install libhdf5-serial-dev ; sudo apt-get install libffi6 libffi-dev; sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm ; sudo -H pip3 install jupyter_http_over_ws ; jupyter serverextension enable --py jupyter_http_over_ws ; jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "And then copy and paste the outputted link with \"locahost: ...\" into the colab connect to local runtime option\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "art6GQEJG5ri"
      },
      "source": [
        "###Also run this code segment, which creates a TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbFX7QwQG67i",
        "outputId": "2bda1f42-a3fc-4ce6-95dc-c52bd336b699"
      },
      "source": [
        "GCE_PROJECT_NAME = \"genome-project-319100\" #@param {type:\"string\"}\n",
        "TPU_ZONE = \"us-central1-f\" #@param {type:\"string\"}\n",
        "TPU_NAME = \"mutformer-tpu\" #@param {type:\"string\"}\n",
        "\n",
        "!gcloud alpha compute tpus create $TPU_NAME --accelerator-type=tpu-v2 --version=1.15.5 --zone=$TPU_ZONE ##create new TPU\n",
        "\n",
        "!gsutil iam ch serviceAccount:`gcloud alpha compute tpus describe $TPU_NAME | grep serviceAccount | cut -d' ' -f2`:admin gs://theodore_jiang && echo 'Successfully set permissions!' ##give TPU access to GCS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tools/google-cloud-sdk/lib/gcloud.py\", line 104, in <module>\n",
            "    main()\n",
            "  File \"/tools/google-cloud-sdk/lib/gcloud.py\", line 76, in main\n",
            "    gcloud_main = _import_gcloud_main()\n",
            "  File \"/tools/google-cloud-sdk/lib/gcloud.py\", line 56, in _import_gcloud_main\n",
            "    import googlecloudsdk.gcloud_main\n",
            "  File \"/tools/google-cloud-sdk/lib/googlecloudsdk/gcloud_main.py\", line 37, in <module>\n",
            "    from googlecloudsdk.command_lib.util.apis import yaml_command_translator\n",
            "  File \"/tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/util/apis/yaml_command_translator.py\", line 38, in <module>\n",
            "    from googlecloudsdk.command_lib.iam import iam_util\n",
            "  File \"/tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/iam/iam_util.py\", line 58, in <module>\n",
            "    msgs = core_apis.GetMessagesModule('iam', 'v1')\n",
            "  File \"/tools/google-cloud-sdk/lib/googlecloudsdk/api_lib/util/apis.py\", line 338, in GetMessagesModule\n",
            "    return __import__(api_def.messages_full_modulepath, fromlist=['something'])\n",
            "  File \"/tools/google-cloud-sdk/lib/googlecloudsdk/third_party/apis/iam/v1/iam_v1_messages.py\", line 3445, in <module>\n",
            "    class WorkloadIdentityPoolProvider(_messages.Message):\n",
            "  File \"/tools/google-cloud-sdk/lib/googlecloudsdk/third_party/apis/iam/v1/iam_v1_messages.py\", line 3580, in WorkloadIdentityPoolProvider\n",
            "    class AttributeMappingValue(_messages.Message):\n",
            "  File \"/tools/google-cloud-sdk/lib/googlecloudsdk/third_party/apis/iam/v1/iam_v1_messages.py\", line 3632, in AttributeMappingValue\n",
            "    class AdditionalProperty(_messages.Message):\n",
            "  File \"/tools/google-cloud-sdk/lib/third_party/apitools/base/protorpclite/messages.py\", line 677, in __new__\n",
            "    return _DefinitionClass.__new__(cls, name, bases, dct)\n",
            "KeyboardInterrupt\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.alpha.compute.tpus.describe) Error parsing [tpu].\n",
            "The [tpu] resource is not properly specified.\n",
            "Failed to find attribute [project]. The attribute can be set in the following ways: \n",
            "- provide the argument `--project` on the command line\n",
            "- set the property `core/project`\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXZaQIt1SXQv"
      },
      "source": [
        "#Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L470I2VGCLTe",
        "outputId": "92eea7a9-e7c5-40cb-ca3a-9835fa09b804"
      },
      "source": [
        "if USE_GCP_TPU:\n",
        "  !sudo apt-get -y install git\n",
        "#@markdown ######where to clone the repo into (only value that it can't be is \"mutformer\"):\n",
        "REPO_DESTINATION_PATH = \"code/mutformer\" #@param {type:\"string\"}\n",
        "import os,shutil\n",
        "if not os.path.exists(REPO_DESTINATION_PATH):\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "else:\n",
        "  shutil.rmtree(REPO_DESTINATION_PATH)\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "cmd = \"git clone https://tianqitheodorejiang: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@github.com/WGLab/mutformer.git \\\"\" + REPO_DESTINATION_PATH + \"\\\"\"\n",
        "!{cmd}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code/mutformer'...\n",
            "remote: Enumerating objects: 378, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 378 (delta 129), reused 27 (delta 27), pack-reused 199\u001b[K\n",
            "Receiving objects: 100% (378/378), 1.88 MiB | 12.45 MiB/s, done.\n",
            "Resolving deltas: 100% (240/240), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj1mClhQQE_n"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S4CiOh3RzFW",
        "outputId": "c9b073d7-e901-4aff-adbe-2a263e34b6a8"
      },
      "source": [
        "if not USE_GCP_TPU:\n",
        "  %tensorflow_version 1.x\n",
        "  from google.colab import auth\n",
        "  print(\"Authorize for GCS:\")\n",
        "  auth.authenticate_user()\n",
        "  print(\"Authorize done\")\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import importlib\n",
        "\n",
        "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
        "\n",
        "if not os.path.exists(\"mutformer\"):\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "else:\n",
        "  shutil.rmtree(\"mutformer\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "if \"mutformer\" in sys.path:\n",
        "  sys.path.remove(\"mutformer\")\n",
        "sys.path.append(\"mutformer\")\n",
        "\n",
        "from mutformer import modeling, optimization, tokenization,run_classifier,run_ner_for_pathogenic\n",
        "from mutformer.modeling import BertModel,BertModelModified\n",
        "from mutformer.run_classifier import MrpcProcessor,REProcessor,MrpcWithPredsProcessor ##change this part if you add more modes--\n",
        "from mutformer.run_ner_for_pathogenic import NERProcessor      ##--\n",
        "\n",
        "##reload modules in case that's needed\n",
        "modules2reload = [modeling, \n",
        "                  optimization, \n",
        "                  tokenization,\n",
        "                  run_classifier,\n",
        "                  run_ner_for_pathogenic]\n",
        "for module in modules2reload:\n",
        "    importlib.reload(module)\n",
        "\n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "log.handlers = []\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "#@markdown ###### Whether or not to write logs to a file\n",
        "DO_FILE_LOGGING = True #@param {type:\"boolean\"}\n",
        "if DO_FILE_LOGGING:\n",
        "  #@markdown ###### If using file logging, what path to write logs to\n",
        "  FILE_LOGGING_PATH = 'file_logging/spam.log' #@param {type:\"string\"}\n",
        "  if not os.path.exists(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1])):\n",
        "    os.makedirs(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1]))\n",
        "  fh = logging.FileHandler(FILE_LOGGING_PATH)\n",
        "  fh.setLevel(logging.INFO)\n",
        "  fh.setFormatter(formatter)\n",
        "  log.addHandler(fh)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "log.handlers = [fh,ch]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "\n",
        "\n",
        "if MODE==\"MRPC\": ##change this part if you added more modes\n",
        "  processor = MrpcProcessor()\n",
        "  script = run_classifier\n",
        "elif MODE==\"MRPC_w_preds\":\n",
        "  processor = MrpcWithPredsProcessor()\n",
        "  script = run_classifier\n",
        "elif MODE==\"RE\":\n",
        "  processor = REProcessor()\n",
        "  script = run_classifier\n",
        "elif MODE==\"NER\":\n",
        "  processor = NERProcessor()\n",
        "  script = run_ner_for_pathogenic\n",
        "else:\n",
        "  raise Exception(\"The mode specified was not one of the available modes: [\\\"MRPC\\\", \\\"RE\\\",\\\"NER\\\"].\")\n",
        "label_list = processor.get_labels()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Authorize for GCS:\n",
            "Authorize done\n",
            "2021-12-04 23:55:03\n",
            "WARNING:tensorflow:From /content/mutformer/optimization.py:82: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-04 23:55:04,208 - tensorflow - INFO - Using TPU runtime\n",
            "2021-12-04 23:55:04,222 - tensorflow - INFO - TPU address is grpc://10.117.234.18:8470\n",
            "2021-12-04 23:55:04,224 - tensorflow - WARNING - \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb0TXw9GtCKz"
      },
      "source": [
        "#Select preference for communication with eval script/Mount drive if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYsYBUCJMTdz",
        "outputId": "70766790-ba10-429a-cc31-0ad25cea1e79"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "#@markdown ###### Note: for all of these, if using USE_GCP_TPU, all of these parameters must use GCS, because a GCP TPU can't access google drive\n",
        "#@markdown \\\n",
        "DRIVE_PATH = \"/content/drive/My Drive\"\n",
        "BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "#@markdown whether to use GCS for communicating with eval script, if not, defaults to drive. Note that by defualt, training logs have to be stored in GCS because the Google TPU requires it\n",
        "GCS_COMS = False #@param {type:\"boolean\"}\n",
        "\n",
        "COMS_PATH = BUCKET_PATH if GCS_COMS else DRIVE_PATH\n",
        "\n",
        "if not GCS_COMS:\n",
        "  from google.colab import drive,auth\n",
        "  !fusermount -u /content/drive\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkFC96e0cK6n"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ_lmHSa7ct_"
      },
      "source": [
        "###General definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bpaa3Eo7h8W"
      },
      "source": [
        "name2model = {\n",
        "    \"modified_large\":BertModelModified,\n",
        "    \"modified_medium\":BertModelModified,\n",
        "    \"modified\":BertModelModified,\n",
        "    \"orig\":BertModel,\n",
        "    \"large\":BertModel\n",
        "}\n",
        "\n",
        "def latest_checkpoint(dir):\n",
        "  cmd = \"gsutil ls \"+dir\n",
        "  files = !{cmd}\n",
        "  for file in files:\n",
        "    if \"model.ckpt\" in file:\n",
        "      return file.replace(\".\"+file.split(\".\")[-1],\"\")\n",
        "\n",
        "def training_loop(BATCH_SIZE,\n",
        "                  RESUMING,\n",
        "                  PLANNED_TOTAL_STEPS,\n",
        "                  DECAY_PER_STEP,\n",
        "                  DATA_SEQ_LENGTH,\n",
        "                  MODEL_NAME,\n",
        "                  MODEL,\n",
        "                  INIT_CHECKPOINT_DIR,\n",
        "                  BERT_GCS_DIR,\n",
        "                  DATA_GCS_DIR,\n",
        "                  USING_SHARDS,\n",
        "                  START_SHARD,\n",
        "                  USING_PREDS,\n",
        "                  PRED_NUM,\n",
        "                  GCS_LOGGING_DIR,\n",
        "                  CONFIG_FILE):\n",
        "  \n",
        "  RESTORE_CHECKPOINT = None if not RESUMING else tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "  if not RESUMING:\n",
        "    cmd = \"gsutil -m rm -r \"+BERT_GCS_DIR\n",
        "    !{cmd}\n",
        "\n",
        "  ## if using a directory with only a single checkpoint and no \"checkpoint\" file, \n",
        "  ## tf.train.latest_checkpoint will not work, so get fold name manually via latest_checkpoint(dir)\n",
        "  try: \n",
        "    INIT_CHECKPOINT = tf.train.latest_checkpoint(INIT_CHECKPOINT_DIR)\n",
        "  except:\n",
        "    INIT_CHECKPOINT = latest_checkpoint(INIT_CHECKPOINT_DIR)\n",
        "  print(\"init checkpoint:\",INIT_CHECKPOINT,\"restore/save checkpont:\",RESTORE_CHECKPOINT)\n",
        "\n",
        "  config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "  config.hidden_dropout_prob = 0.1\n",
        "  config.attention_probs_dropout_prob = 0.1\n",
        "\n",
        "  model_fn = script.model_fn_builder(\n",
        "      bert_config=config,\n",
        "      logging_dir=GCS_LOGGING_DIR,\n",
        "      num_labels=len(label_list),\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      restore_checkpoint=RESTORE_CHECKPOINT,\n",
        "      init_learning_rate=INIT_LEARNING_RATE,\n",
        "      decay_per_step=DECAY_PER_STEP,\n",
        "      num_warmup_steps=10,\n",
        "      use_tpu=True,\n",
        "      use_one_hot_embeddings=True,\n",
        "      bert=MODEL,\n",
        "      weight_decay=0.01,\n",
        "      epsilon=1e-6,\n",
        "      clip_grads=False,\n",
        "      using_preds=USING_PREDS)\n",
        "\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      model_dir=BERT_GCS_DIR,\n",
        "      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "      keep_checkpoint_max=KEEP_N_CHECKPOINTS_AT_A_TIME,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "          num_shards=NUM_TPU_CORES,\n",
        "          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=True,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=BATCH_SIZE)\n",
        "  \n",
        "  train_file_name = \"train.tf_record\"\n",
        "  train_file = os.path.join(DATA_GCS_DIR, train_file_name)\n",
        "\n",
        "  if USING_SHARDS:\n",
        "    shards_folder = DATA_GCS_DIR\n",
        "    input_file = os.path.join(DATA_GCS_DIR, train_file_name)\n",
        "    import re\n",
        "    file_name = input_file.split(\"/\")[-1]\n",
        "    shards = [shards_folder + \"/\" + file for file in tf.io.gfile.listdir(shards_folder) if\n",
        "              re.match(file_name + \"_\\d+\", file)]\n",
        "    shards = sorted(shards,key=lambda shard:int(shard.split(\"_\")[-1]))[START_SHARD:]\n",
        "  else:\n",
        "    shards = [train_file]\n",
        "\n",
        "  if USING_SHARDS:\n",
        "    print(\"\\nUSING SHARDs:\")\n",
        "    for shard in shards:\n",
        "      print(shard)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  tf.logging.info(\"***** Running training *****\")\n",
        "  tf.logging.info(\"  Batch size = %d\", BATCH_SIZE)\n",
        "  for n,shard in enumerate(shards):\n",
        "      train_input_fn = script.file_based_input_fn_builder( ##if using external data with MRPC_w_preds, make sure to specify \"pred_num=xxx\"\n",
        "          input_file=shard,\n",
        "          seq_length=DATA_SEQ_LENGTH,\n",
        "          is_training=True,\n",
        "          drop_remainder=True,\n",
        "          pred_num=PRED_NUM if USING_PREDS else None)\n",
        "\n",
        "      ##writing data to drive so that the parallel eval script can know which model to evaluate\n",
        "      try:\n",
        "        tf.gfile.Open(COMS_PATH+\"/finetuning_run_paired_model.txt\",\"w+\").write(MODEL_NAME)\n",
        "        tf.gfile.Open(COMS_PATH+\"/finetuning_run_paired_seq_length.txt\",\"w+\").write(str(DATA_SEQ_LENGTH))\n",
        "        tf.gfile.Open(COMS_PATH+\"/finetuning_run_paired_batch_size.txt\",\"w+\").write(str(BATCH_SIZE))\n",
        "      except:\n",
        "        pass\n",
        "      estimator.train(input_fn=train_input_fn, max_steps=PLANNED_TOTAL_STEPS)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AjnVKSMlVXz"
      },
      "source": [
        "####Model/sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCuEbr6dv8U"
      },
      "source": [
        "#@markdown train batch size to use\n",
        "BATCH_SIZE=16 #@param\n",
        "#@markdown list of models to test\n",
        "models = [\"modified_medium\",\"modified_large\"] #@param\n",
        "#@markdown list of maximum sequence lengths to test\n",
        "lengths = [256,512,1024] #@param\n",
        "#@markdown whether or not to resume training from a previous finetuned checkpoint; if no, always train from pretrained model\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown whether or not external data is being used\n",
        "USING_PREDS = True #@param {type:\"boolean\"}\n",
        "#@markdown if using external data, how many datapoints are included in total\n",
        "PRED_NUM =   27#@param {type:\"integer\"}\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/TRAIN_BATCH_SIZE) \n",
        "\n",
        "for DATA_SEQ_LENGTH in lengths:\n",
        "  for MODEL_NAME in models:\n",
        "    print(\"\\n\\n\\nMODEL NAME:\",MODEL_NAME,\n",
        "          \"\\nINPUT MAX SEQ LENGTH:\",DATA_SEQ_LENGTH,\n",
        "          \"\\nTRAIN_BATCH_SIZE:\",BATCH_SIZE,\"\\n\\n\\n\")\n",
        "\n",
        "    MODEL = name2model[MODEL_NAME]\n",
        "    INIT_CHECKPOINT_DIR = \"{}/{}\".format(BUCKET_PATH, INIT_MODEL_DIR_format.replace(\"xxx\",MODEL_NAME))\n",
        "    BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR_format.replace(\"xxx\",MODEL_NAME+\"_\"+str(DATA_SEQ_LENGTH)))\n",
        "    DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, DATA_DIR_format.replace(\"xxx\",str(DATA_SEQ_LENGTH)))\n",
        "    \n",
        "    GCS_LOGGING_DIR = \"{}/{}\".format(BUCKET_PATH, LOGGING_DIR+\"/\"+RUN_NAME_format.replace(\"xxx\",MODEL_NAME+\"_\"+str(DATA_SEQ_LENGTH)))\n",
        "\n",
        "    CONFIG_FILE = \"{}/config.json\".format(BUCKET_PATH+\"/\"+INIT_MODEL_DIR_format.replace(\"xxx\",MODEL_NAME))\n",
        "\n",
        "    training_loop(BATCH_SIZE,\n",
        "                  RESUMING,\n",
        "                  PLANNED_TOTAL_STEPS,\n",
        "                  DECAY_PER_STEP,\n",
        "                  DATA_SEQ_LENGTH,\n",
        "                  MODEL_NAME,\n",
        "                  MODEL,\n",
        "                  INIT_CHECKPOINT_DIR,\n",
        "                  BERT_GCS_DIR,\n",
        "                  DATA_GCS_DIR,\n",
        "                  USING_SHARDS,\n",
        "                  START_SHARD,\n",
        "                  USING_PREDS,\n",
        "                  PRED_NUM,\n",
        "                  GCS_LOGGING_DIR,\n",
        "                  CONFIG_FILE)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ322RGr5ykF"
      },
      "source": [
        "####Batch size/sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IytLW0VbgOZz"
      },
      "source": [
        "#@markdown list of batch sizes to test\n",
        "batch_sizes = [64] #@param\n",
        "#@markdown list of maximum sequence lengths to test\n",
        "lengths = [1024] #@param\n",
        "#@markdown model to use\n",
        "MODEL_NAME=\"modified_large\" #@param {type:\"string\"}\n",
        "#@markdown whether or not to resume training from a previous finetuned checkpoint; if no, always train from pretrained model\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown whether or not external data is being used\n",
        "USING_PREDS = True #@param {type:\"boolean\"}\n",
        "#@markdown if using external data, how many datapoints are included in total\n",
        "PRED_NUM =   27#@param {type:\"integer\"}\n",
        "\n",
        "BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/TRAIN_BATCH_SIZE) \n",
        "\n",
        "for DATA_SEQ_LENGTH in lengths:\n",
        "    for BATCH_SIZE in batch_sizes:\n",
        "        print(\"\\n\\n\\nMODEL NAME:\",MODEL_NAME,\n",
        "              \"\\nINPUT MAX SEQ LENGTH:\",DATA_SEQ_LENGTH,\n",
        "              \"\\nTRAIN_BATCH_SIZE:\",BATCH_SIZE,\"\\n\\n\\n\")\n",
        "       \n",
        "        MODEL = name2model[MODEL_NAME]\n",
        "        INIT_CHECKPOINT_DIR = \"{}/{}\".format(BUCKET_PATH, INIT_MODEL_DIR_format.replace(\"xxx\",MODEL_NAME))\n",
        "        BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR_format.replace(\"xxx\",MODEL_NAME+\"_\"+str(DATA_SEQ_LENGTH)+\"_\"+str(BATCH_SIZE)))\n",
        "        DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, DATA_DIR_format.replace(\"xxx\",str(DATA_SEQ_LENGTH)))\n",
        "      \n",
        "        GCS_LOGGING_DIR = \"{}/{}\".format(BUCKET_PATH, LOGGING_DIR+\"/\"+RUN_NAME_format.replace(\"xxx\",MODEL_NAME+\"_\"+str(DATA_SEQ_LENGTH)+\"_\"+str(BATCH_SIZE)))\n",
        "        \n",
        "        CONFIG_FILE = \"{}/config.json\".format(BUCKET_PATH+\"/\"+INIT_MODEL_DIR_format.replace(\"xxx\",MODEL_NAME))\n",
        "\n",
        "        training_loop(BATCH_SIZE,\n",
        "                      RESUMING,\n",
        "                      PLANNED_TOTAL_STEPS,\n",
        "                      DECAY_PER_STEP,\n",
        "                      DATA_SEQ_LENGTH,\n",
        "                      MODEL_NAME,\n",
        "                      MODEL,\n",
        "                      INIT_CHECKPOINT_DIR,\n",
        "                      BERT_GCS_DIR,\n",
        "                      DATA_GCS_DIR,\n",
        "                      USING_SHARDS,\n",
        "                      START_SHARD,\n",
        "                      USING_PREDS,\n",
        "                      PRED_NUM,\n",
        "                      GCS_LOGGING_DIR,\n",
        "                      CONFIG_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tswiJYA_qCUq"
      },
      "source": [
        "###Train a single model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK3tf7aWqIiR",
        "outputId": "ade9bfce-913f-4d8e-c3de-06a830ce209b"
      },
      "source": [
        "#@markdown batch size to use\n",
        "BATCH_SIZE = 32 #@param\n",
        "#@markdown maximum sequence length to use\n",
        "DATA_SEQ_LENGTH = 512 #@param\n",
        "#@markdown model to use\n",
        "MODEL_NAME=\"modified_large\" #@param {type:\"string\"}\n",
        "#@markdown whether or not to resume training from a previous checkpoint; if no, always train from scratch\n",
        "RESUMING = True #@param {type:\"boolean\"}\n",
        "#@markdown ###### identifier for the model to use (replaces \"xxx\" from the variable \"MODEL_DIR_format\")\n",
        "model_name_extension = \"added_preds_512_32\" #@param {type:\"string\"}\n",
        "#@markdown whether or not training data was generated in shards (for really large databases)\n",
        "USING_SHARDS = True #@param {type:\"boolean\"}\n",
        "#@markdown if using shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD =   0#@param {type:\"integer\"}\n",
        "#@markdown whether or not external data is being used\n",
        "USING_PREDS = True #@param {type:\"boolean\"}\n",
        "#@markdown if using external data, how many datapoints are included in total\n",
        "PRED_NUM =   27#@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/TRAIN_BATCH_SIZE) \n",
        "\n",
        "\n",
        "print(\"\\n\\n\\nMODEL NAME:\",MODEL_NAME,\n",
        "      \"\\nINPUT MAX SEQ LENGTH:\",DATA_SEQ_LENGTH,\n",
        "      \"\\nTRAIN_BATCH_SIZE:\",BATCH_SIZE,\"\\n\\n\\n\")\n",
        "\n",
        "MODEL = name2model[MODEL_NAME]\n",
        "INIT_CHECKPOINT_DIR = \"{}/{}\".format(BUCKET_PATH, INIT_MODEL_DIR_format.replace(\"xxx\",MODEL_NAME))\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR_format.replace(\"xxx\",model_name_extension))\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, DATA_DIR_format.replace(\"xxx\",str(DATA_SEQ_LENGTH)))\n",
        "\n",
        "GCS_LOGGING_DIR = \"{}/{}\".format(BUCKET_PATH, LOGGING_DIR+\"/\"+RUN_NAME_format.replace(\"xxx\",MODEL_NAME+\"_\"+str(DATA_SEQ_LENGTH)+\"_\"+str(BATCH_SIZE)))\n",
        "\n",
        "CONFIG_FILE = \"{}/config.json\".format(BUCKET_PATH+\"/\"+INIT_MODEL_DIR_format.replace(\"xxx\",MODEL_NAME))\n",
        "\n",
        "\n",
        "training_loop(BATCH_SIZE,\n",
        "              RESUMING,\n",
        "              PLANNED_TOTAL_STEPS,\n",
        "              DECAY_PER_STEP,\n",
        "              DATA_SEQ_LENGTH,\n",
        "              MODEL_NAME,\n",
        "              MODEL,\n",
        "              INIT_CHECKPOINT_DIR,\n",
        "              BERT_GCS_DIR,\n",
        "              DATA_GCS_DIR,\n",
        "              USING_SHARDS,\n",
        "              START_SHARD,\n",
        "              USING_PREDS,\n",
        "              PRED_NUM,\n",
        "              GCS_LOGGING_DIR,\n",
        "              CONFIG_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "MODEL NAME: modified_large \n",
            "INPUT MAX SEQ LENGTH: 512 \n",
            "TRAIN_BATCH_SIZE: 32 \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-04 23:55:15,434 - tensorflow - WARNING - From /content/mutformer/modeling.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init checkpoint: gs://theodore_jiang/bert_model_modified_large/model.ckpt-2002192 restore/save checkpont: gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt-1200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-04 23:55:16,595 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd74aeb1320>) includes params argument, but params are not passed to Estimator.\n",
            "2021-12-04 23:55:16,597 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.117.234.18:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd8e0a1fc90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.117.234.18:8470', '_evaluation_master': 'grpc://10.117.234.18:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fd74aee5b50>}\n",
            "2021-12-04 23:55:16,598 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2021-12-04 23:55:16,749 - tensorflow - INFO - ***** Running training *****\n",
            "2021-12-04 23:55:16,750 - tensorflow - INFO -   Batch size = 32\n",
            "2021-12-04 23:55:16,751 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:353: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "USING SHARDs:\n",
            "gs://theodore_jiang/MRPC_adding_preds_512/train.tf_record_0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-04 23:55:17,662 - tensorflow - INFO - Querying Tensorflow master (grpc://10.117.234.18:8470) for TPU system metadata.\n",
            "2021-12-04 23:55:17,747 - tensorflow - INFO - Found TPU system:\n",
            "2021-12-04 23:55:17,748 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2021-12-04 23:55:17,749 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2021-12-04 23:55:17,749 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2021-12-04 23:55:17,750 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 306457937327901653)\n",
            "2021-12-04 23:55:17,751 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7390055950725494957)\n",
            "2021-12-04 23:55:17,752 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5531112587601217081)\n",
            "2021-12-04 23:55:17,753 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12595282466141110428)\n",
            "2021-12-04 23:55:17,754 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15545440572543926263)\n",
            "2021-12-04 23:55:17,757 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14409873313727157106)\n",
            "2021-12-04 23:55:17,758 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 14538866492185881342)\n",
            "2021-12-04 23:55:17,760 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 18365539494583660457)\n",
            "2021-12-04 23:55:17,761 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2390022716485407144)\n",
            "2021-12-04 23:55:17,761 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 16357026774115543205)\n",
            "2021-12-04 23:55:17,762 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1737732237185314194)\n",
            "2021-12-04 23:55:17,770 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2021-12-04 23:55:17,771 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2021-12-04 23:55:17,781 - tensorflow - INFO - Calling model_fn.\n",
            "2021-12-04 23:55:17,800 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:409: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2021-12-04 23:55:17,801 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2021-12-04 23:55:17,817 - tensorflow - WARNING - Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fd913c4a710> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2021-12-04 23:55:17,818 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:371: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2021-12-04 23:55:17,824 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:378: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-12-04 23:55:17,890 - tensorflow - INFO - *** Features ***\n",
            "2021-12-04 23:55:17,891 - tensorflow - INFO -   name = input_ids, shape = (4, 512)\n",
            "2021-12-04 23:55:17,892 - tensorflow - INFO -   name = input_mask, shape = (4, 512)\n",
            "2021-12-04 23:55:17,893 - tensorflow - INFO -   name = is_real_example, shape = (4,)\n",
            "2021-12-04 23:55:17,894 - tensorflow - INFO -   name = label_ids, shape = (4,)\n",
            "2021-12-04 23:55:17,894 - tensorflow - INFO -   name = preds, shape = (4, 27)\n",
            "2021-12-04 23:55:17,895 - tensorflow - INFO -   name = segment_ids, shape = (4, 512)\n",
            "2021-12-04 23:55:17,896 - tensorflow - WARNING - From /content/mutformer/modeling.py:336: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2021-12-04 23:55:17,902 - tensorflow - WARNING - From /content/mutformer/modeling.py:575: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2021-12-04 23:55:17,932 - tensorflow - WARNING - From /content/mutformer/modeling.py:656: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2021-12-04 23:55:17,974 - tensorflow - WARNING - From /content/mutformer/modeling.py:524: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fd913c4a710> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "step 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-04 23:55:18,174 - tensorflow - WARNING - From /content/mutformer/modeling.py:837: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2021-12-04 23:55:18,175 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2021-12-04 23:55:20,603 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:531: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape1 (4, 768)\n",
            "shape2 (4, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-04 23:55:21,088 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2021-12-04 23:55:21,090 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,092 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,094 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,095 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,097 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,098 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,102 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,103 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,105 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,106 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,107 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,109 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,110 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,111 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,112 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,113 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,114 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,115 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,116 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,117 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,118 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,119 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,120 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,121 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,122 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,123 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,124 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,125 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,126 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,127 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,128 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,129 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,130 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,131 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,132 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,133 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,134 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,135 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,136 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,137 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,138 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,139 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,140 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,141 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,146 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,147 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,148 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,149 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,154 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,155 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,156 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,157 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,158 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,159 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,162 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,163 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,164 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,165 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,166 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,167 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,168 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,169 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,170 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,170 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,171 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,172 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,173 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,174 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,175 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,176 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,177 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,178 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,179 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,180 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,181 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,182 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,183 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,185 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,186 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,188 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,191 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,192 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,193 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,194 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,195 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,196 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,197 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,199 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,200 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,201 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,202 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,205 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,206 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,206 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,207 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,208 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,209 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,210 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,211 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,214 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,215 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,216 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,217 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,218 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,219 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,220 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,221 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,222 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,223 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,224 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,225 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,226 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,226 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,227 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,228 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,231 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,232 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,233 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,233 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,234 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,235 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,236 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,237 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,239 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,240 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,241 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,243 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,243 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,244 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,245 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,246 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,247 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,248 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,249 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,250 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,251 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,252 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,253 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,254 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,255 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,256 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,257 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,258 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,263 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,264 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,266 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,267 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,268 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,273 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,274 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,275 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,276 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,279 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,280 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,281 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,282 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,283 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,284 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,285 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,287 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,288 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,289 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,290 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,291 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,292 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,294 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,295 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,296 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,297 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,299 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,302 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,304 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,304 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,305 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,306 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,307 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,308 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,309 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,310 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,311 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,312 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,313 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,314 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,315 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,320 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,322 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,324 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,324 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,327 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,330 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,333 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,333 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,334 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,335 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,338 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,341 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,343 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,344 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,344 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,347 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,348 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,349 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,350 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,351 - tensorflow - INFO -   name = extra_data_layers/pred_dense/kernel:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,352 - tensorflow - INFO -   name = extra_data_layers/pred_dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,353 - tensorflow - INFO -   name = extra_data_layers/combine_dense/kernel:0, shape = (1536, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,354 - tensorflow - INFO -   name = extra_data_layers/combine_dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,355 - tensorflow - INFO -   name = output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,356 - tensorflow - INFO -   name = output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "2021-12-04 23:55:21,356 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:577: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2021-12-04 23:55:21,600 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2021-12-04 23:55:30,296 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:550: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 2) (4, 2) (4, 1)\n",
            "acctot: Tensor(\"Sum_13:0\", shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-04 23:55:31,668 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:551: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "2021-12-04 23:55:32,727 - tensorflow - INFO - Create CheckpointSaverHook.\n",
            "2021-12-04 23:55:33,204 - tensorflow - INFO - Done calling model_fn.\n",
            "2021-12-04 23:55:35,361 - tensorflow - INFO - TPU job name worker\n",
            "2021-12-04 23:55:36,722 - tensorflow - INFO - Graph was finalized.\n",
            "2021-12-04 23:55:36,963 - tensorflow - INFO - Restoring parameters from gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt-1200\n",
            "2021-12-04 23:55:51,266 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "2021-12-04 23:55:52,730 - tensorflow - INFO - Running local_init_op.\n",
            "2021-12-04 23:55:53,249 - tensorflow - INFO - Done running local_init_op.\n",
            "2021-12-04 23:56:00,765 - tensorflow - INFO - Saving checkpoints for 1200 into gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt.\n",
            "2021-12-04 23:56:25,788 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2021-12-04 23:56:26,880 - tensorflow - INFO - Initialized dataset iterators in 0 seconds\n",
            "2021-12-04 23:56:26,882 - tensorflow - INFO - Installing graceful shutdown hook.\n",
            "2021-12-04 23:56:26,888 - tensorflow - INFO - Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2021-12-04 23:56:26,891 - tensorflow - INFO - Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2021-12-04 23:56:26,896 - tensorflow - INFO - Init TPU system\n",
            "2021-12-04 23:56:36,793 - tensorflow - INFO - Initialized TPU in 9 seconds\n",
            "2021-12-04 23:56:38,123 - tensorflow - INFO - Starting infeed thread controller.\n",
            "2021-12-04 23:56:38,124 - tensorflow - INFO - Starting outfeed thread controller.\n",
            "2021-12-04 23:56:38,660 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-04 23:56:38,661 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-04 23:57:13,354 - tensorflow - INFO - Outfeed finished for iteration (0, 0)\n",
            "2021-12-04 23:58:13,676 - tensorflow - INFO - Outfeed finished for iteration (0, 157)\n",
            "2021-12-04 23:59:14,207 - tensorflow - INFO - Outfeed finished for iteration (0, 311)\n",
            "2021-12-05 00:00:14,329 - tensorflow - INFO - Outfeed finished for iteration (0, 449)\n",
            "2021-12-05 00:01:14,486 - tensorflow - INFO - Outfeed finished for iteration (0, 582)\n",
            "2021-12-05 00:02:15,062 - tensorflow - INFO - Outfeed finished for iteration (0, 755)\n",
            "2021-12-05 00:03:10,496 - tensorflow - INFO - Saving checkpoints for 2200 into gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt.\n",
            "2021-12-05 00:03:15,560 - tensorflow - INFO - Outfeed finished for iteration (0, 885)\n",
            "2021-12-05 00:03:34,260 - tensorflow - INFO - loss = 0.09821024, step = 2200\n",
            "2021-12-05 00:03:34,264 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-05 00:03:34,265 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-05 00:04:15,642 - tensorflow - INFO - Outfeed finished for iteration (1, 44)\n",
            "2021-12-05 00:05:16,089 - tensorflow - INFO - Outfeed finished for iteration (1, 224)\n",
            "2021-12-05 00:06:16,332 - tensorflow - INFO - Outfeed finished for iteration (1, 391)\n",
            "2021-12-05 00:07:16,823 - tensorflow - INFO - Outfeed finished for iteration (1, 517)\n",
            "2021-12-05 00:08:20,531 - tensorflow - INFO - Outfeed finished for iteration (1, 629)\n",
            "2021-12-05 00:09:21,119 - tensorflow - INFO - Outfeed finished for iteration (1, 754)\n",
            "2021-12-05 00:10:16,069 - tensorflow - INFO - Saving checkpoints for 3200 into gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt.\n",
            "2021-12-05 00:10:21,957 - tensorflow - INFO - Outfeed finished for iteration (1, 877)\n",
            "2021-12-05 00:10:38,922 - tensorflow - INFO - loss = 0.44227907, step = 3200 (424.662 sec)\n",
            "2021-12-05 00:10:38,925 - tensorflow - INFO - global_step/sec: 2.35481\n",
            "2021-12-05 00:10:38,926 - tensorflow - INFO - examples/sec: 75.354\n",
            "2021-12-05 00:10:38,929 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-05 00:10:38,930 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-05 00:11:21,972 - tensorflow - INFO - Outfeed finished for iteration (1, 956)\n",
            "2021-12-05 00:12:22,112 - tensorflow - INFO - Outfeed finished for iteration (2, 78)\n",
            "2021-12-05 00:13:22,604 - tensorflow - INFO - Outfeed finished for iteration (2, 192)\n",
            "2021-12-05 00:14:23,019 - tensorflow - INFO - Outfeed finished for iteration (2, 309)\n",
            "2021-12-05 00:15:23,213 - tensorflow - INFO - Outfeed finished for iteration (2, 434)\n",
            "2021-12-05 00:16:23,433 - tensorflow - INFO - Outfeed finished for iteration (2, 562)\n",
            "2021-12-05 00:17:23,675 - tensorflow - INFO - Outfeed finished for iteration (2, 705)\n",
            "2021-12-05 00:18:23,950 - tensorflow - INFO - Outfeed finished for iteration (2, 825)\n",
            "2021-12-05 00:18:46,835 - tensorflow - INFO - Saving checkpoints for 4200 into gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt.\n",
            "2021-12-05 00:19:10,802 - tensorflow - INFO - loss = 0.50100493, step = 4200 (511.880 sec)\n",
            "2021-12-05 00:19:10,806 - tensorflow - INFO - global_step/sec: 1.95358\n",
            "2021-12-05 00:19:10,807 - tensorflow - INFO - examples/sec: 62.5146\n",
            "2021-12-05 00:19:10,809 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-05 00:19:10,810 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-05 00:19:24,231 - tensorflow - INFO - Outfeed finished for iteration (2, 957)\n",
            "2021-12-05 00:20:24,426 - tensorflow - INFO - Outfeed finished for iteration (3, 78)\n",
            "2021-12-05 00:21:24,507 - tensorflow - INFO - Outfeed finished for iteration (3, 200)\n",
            "2021-12-05 00:22:25,132 - tensorflow - INFO - Outfeed finished for iteration (3, 351)\n",
            "2021-12-05 00:23:25,266 - tensorflow - INFO - Outfeed finished for iteration (3, 474)\n",
            "2021-12-05 00:24:25,739 - tensorflow - INFO - Outfeed finished for iteration (3, 584)\n",
            "2021-12-05 00:25:31,225 - tensorflow - INFO - Outfeed finished for iteration (3, 695)\n",
            "2021-12-05 00:26:31,653 - tensorflow - INFO - Outfeed finished for iteration (3, 809)\n",
            "2021-12-05 00:27:03,463 - tensorflow - INFO - Saving checkpoints for 5200 into gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt.\n",
            "2021-12-05 00:27:26,078 - tensorflow - INFO - loss = 0.236013, step = 5200 (495.276 sec)\n",
            "2021-12-05 00:27:26,080 - tensorflow - INFO - global_step/sec: 2.01908\n",
            "2021-12-05 00:27:26,082 - tensorflow - INFO - examples/sec: 64.6106\n",
            "2021-12-05 00:27:26,084 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-05 00:27:26,085 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-05 00:27:32,159 - tensorflow - INFO - Outfeed finished for iteration (3, 947)\n",
            "2021-12-05 00:28:32,622 - tensorflow - INFO - Outfeed finished for iteration (4, 58)\n",
            "2021-12-05 00:29:32,872 - tensorflow - INFO - Outfeed finished for iteration (4, 163)\n",
            "2021-12-05 00:30:32,941 - tensorflow - INFO - Outfeed finished for iteration (4, 280)\n",
            "2021-12-05 00:31:32,970 - tensorflow - INFO - Outfeed finished for iteration (4, 392)\n",
            "2021-12-05 00:32:33,330 - tensorflow - INFO - Outfeed finished for iteration (4, 497)\n",
            "2021-12-05 00:33:33,521 - tensorflow - INFO - Outfeed finished for iteration (4, 619)\n",
            "2021-12-05 00:34:33,712 - tensorflow - INFO - Outfeed finished for iteration (4, 731)\n",
            "2021-12-05 00:35:33,900 - tensorflow - INFO - Outfeed finished for iteration (4, 836)\n",
            "2021-12-05 00:35:53,073 - tensorflow - INFO - Saving checkpoints for 6200 into gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt.\n",
            "2021-12-05 00:36:14,746 - tensorflow - INFO - loss = 1.1709654, step = 6200 (528.668 sec)\n",
            "2021-12-05 00:36:14,748 - tensorflow - INFO - global_step/sec: 1.89155\n",
            "2021-12-05 00:36:14,749 - tensorflow - INFO - examples/sec: 60.5295\n",
            "2021-12-05 00:36:14,752 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2021-12-05 00:36:14,753 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2021-12-05 00:36:33,903 - tensorflow - INFO - Outfeed finished for iteration (4, 951)\n",
            "2021-12-05 00:37:34,077 - tensorflow - INFO - Outfeed finished for iteration (5, 56)\n",
            "2021-12-05 00:38:34,109 - tensorflow - INFO - Outfeed finished for iteration (5, 182)\n",
            "2021-12-05 00:39:34,361 - tensorflow - INFO - Outfeed finished for iteration (5, 272)\n",
            "2021-12-05 00:40:34,475 - tensorflow - INFO - Outfeed finished for iteration (5, 389)\n",
            "2021-12-05 00:41:34,802 - tensorflow - INFO - Outfeed finished for iteration (5, 498)\n",
            "2021-12-05 00:42:35,348 - tensorflow - INFO - Outfeed finished for iteration (5, 606)\n",
            "2021-12-05 00:43:35,869 - tensorflow - INFO - Outfeed finished for iteration (5, 723)\n",
            "2021-12-05 00:44:36,145 - tensorflow - INFO - Outfeed finished for iteration (5, 844)\n",
            "2021-12-05 00:44:47,762 - tensorflow - INFO - Saving checkpoints for 7200 into gs://theodore_jiang/bert_model_mrpc_adding_preds_added_preds_512_32/model.ckpt.\n",
            "2021-12-05 00:45:08,635 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2021-12-05 00:45:11,409 - tensorflow - INFO - loss = 0.03621459, step = 7200 (536.663 sec)\n",
            "2021-12-05 00:45:11,412 - tensorflow - INFO - global_step/sec: 1.86336\n",
            "2021-12-05 00:45:11,413 - tensorflow - INFO - examples/sec: 59.6277\n",
            "2021-12-05 00:45:11,416 - tensorflow - INFO - Enqueue next (800) batch(es) of data to infeed.\n",
            "2021-12-05 00:45:11,417 - tensorflow - INFO - Dequeue next (800) batch(es) of data from outfeed.\n",
            "2021-12-05 00:45:36,202 - tensorflow - INFO - Outfeed finished for iteration (5, 978)\n",
            "2021-12-05 00:46:42,168 - tensorflow - INFO - Outfeed finished for iteration (6, 93)\n",
            "2021-12-05 00:47:42,401 - tensorflow - INFO - Outfeed finished for iteration (6, 200)\n",
            "2021-12-05 00:48:42,620 - tensorflow - INFO - Outfeed finished for iteration (6, 356)\n",
            "2021-12-05 00:49:43,156 - tensorflow - INFO - Outfeed finished for iteration (6, 480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAqZhhQ3_Joy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}