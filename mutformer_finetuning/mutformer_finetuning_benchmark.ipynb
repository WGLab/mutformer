{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VudE2umODMnI"
      },
      "source": [
        "#Finetuning Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHNq3MSTTea"
      },
      "source": [
        "This notebook performs finetuning with varying models, batch sizes, and sequence lengths in order to find the best model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_"
      },
      "source": [
        "# Configure settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozmx1LCLw3SQ"
      },
      "outputs": [],
      "source": [
        "#@markdown ## General Config\n",
        "#@markdown If preferred, a GCP TPU/runtime can be used to run this notebook (instructions below)\n",
        "GCP_RUNTIME = False #@param {type:\"boolean\"}\n",
        "#@markdown How many TPU scores the TPU has: if using colab, NUM_TPU_CORES is 8.\n",
        "NUM_TPU_CORES = 8 #@param {type:\"number\"}\n",
        "#@markdown Which mode to use (a different mode means a different finetuning task): options are:\n",
        "#@markdown * \"MRPC\" - paired sequence method\n",
        "#@markdown * \"MRPC_w_ex_data\" - paired sequence method with external data\n",
        "#@markdown * \"RE\" - single sequence method\n",
        "#@markdown * \"NER\" - single sequence per residue prediction \n",
        "#@markdown \n",
        "#@markdown You can add more modes by creating a new processor and/or a new model_fn inside of the \"mutformer_model_code\" folder downloaded from github, then changing the corresponding code snippets in the code segment named \"Authorize for GCS, Imports, and General Setup\" (also edit the dropdown below).\n",
        "MODE = \"MRPC_w_ex_data\" #@param   [\"MRPC_w_ex_data\", \"MRPC\", \"RE\", \"NER\"]   {type:\"string\"} \n",
        "             ####      ^^^^^ dropdown list for all modes ^^^^^\n",
        "#@markdown Name of the GCS bucket to use:\n",
        "BUCKET_NAME = \"theodore_jiang\" #@param {type:\"string\"}\n",
        "BUCKET_PATH = \"gs://\"+BUCKET_NAME\n",
        "#@markdown Where in GCS the data needs to be loaded from (should be the same as the OUTPUT_DATA_DIR variable in the data generation script):\n",
        "PROCESSED_DATA_DIR = \"compiled_finetune_data/MRPC_ex_data_all_finetune_update_loaded\" #@param {type:\"string\"}\n",
        "#@markdown Which folder to store the logs in (the LOGGING_DIR variable can be the same across all finetuning notebooks)\n",
        "LOGGING_DIR = \"MutFormer_finetuning_newbut_try3_logs\" #@param {type:\"string\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaNhPg7sG2DS"
      },
      "source": [
        "#If running on a GCP runtime, follow these instructions to set it up:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gicp021G3Xd"
      },
      "source": [
        "###1) Create a VM from the GCP website\n",
        "###2) Open a command prompt on your computer and perform the following steps\"\n",
        "To ssh into the VM, run:\n",
        "\n",
        "```\n",
        "gcloud beta compute ssh --zone <COMPUTE ZONE> <VM NAME> --project <PROJECT NAME> -- -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "Note: Make sure the port above matches the port below (in this case it's 8888)\n",
        "\\\n",
        "\\\n",
        "In the new command prompt that popped out, either run each of the commands below individually, or copy and paste the one liner below:\n",
        "```\n",
        "sudo apt-get update\n",
        "sudo apt-get -y install python3 python3-pip\n",
        "sudo apt-get install pkg-config\n",
        "sudo apt-get install libhdf5-serial-dev\n",
        "sudo apt-get install libffi6 libffi-dev\n",
        "sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm\n",
        "sudo -H pip3 install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "One command:\n",
        "```\n",
        "sudo apt-get update ; sudo apt-get -y install python3 python3-pip ; sudo apt-get install pkg-config ; sudo apt-get -y install libhdf5-serial-dev ; sudo apt-get install libffi6 libffi-dev; sudo -H pip3 install jupyter tensorflow==1.14 google-api-python-client tqdm ; sudo -H pip3 install jupyter_http_over_ws ; jupyter serverextension enable --py jupyter_http_over_ws ; jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0   --no-browser\n",
        "```\n",
        "###3) In this notebook, click the \"connect to local runtime\" option under the connect button, and copy and paste the link outputted by command prompt with \"locahost: ...\"\n",
        "###4) Finally, run this code segment, which creates a TPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbFX7QwQG67i"
      },
      "outputs": [],
      "source": [
        "GCE_PROJECT_NAME = \"genome-project-319100\" #@param {type:\"string\"}\n",
        "TPU_ZONE = \"us-central1-f\" #@param {type:\"string\"}\n",
        "TPU_NAME = \"mutformer-tpu\" #@param {type:\"string\"}\n",
        "\n",
        "!gcloud alpha compute tpus create $TPU_NAME --accelerator-type=tpu-v2 --version=1.15.5 --zone=$TPU_ZONE ##create new TPU\n",
        "\n",
        "!gsutil iam ch serviceAccount:`gcloud alpha compute tpus describe $TPU_NAME | grep serviceAccount | cut -d' ' -f2`:admin gs://theodore_jiang && echo 'Successfully set permissions!' ##give TPU access to GCS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXZaQIt1SXQv"
      },
      "source": [
        "#Clone the MutFormer repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L470I2VGCLTe",
        "outputId": "0c27f5b3-aa00-46ee-f329-89a451aaec60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mutformer'...\n",
            "remote: Enumerating objects: 1217, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 1217 (delta 78), reused 56 (delta 46), pack-reused 1120\u001b[K\n",
            "Receiving objects: 100% (1217/1217), 2.30 MiB | 13.87 MiB/s, done.\n",
            "Resolving deltas: 100% (867/867), done.\n"
          ]
        }
      ],
      "source": [
        "if GCP_RUNTIME:\n",
        "  !sudo apt-get -y install git\n",
        "#@markdown Where to clone the repo into:\n",
        "REPO_DESTINATION_PATH = \"mutformer\" #@param {type:\"string\"}\n",
        "import os,shutil\n",
        "if not os.path.exists(REPO_DESTINATION_PATH):\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "else:\n",
        "  shutil.rmtree(REPO_DESTINATION_PATH)\n",
        "  os.makedirs(REPO_DESTINATION_PATH)\n",
        "cmd = \"git clone https://github.com/WGLab/mutformer.git \\\"\" + REPO_DESTINATION_PATH + \"\\\"\"\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj1mClhQQE_n"
      },
      "source": [
        "#Authorize for GCS, Imports, and General Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S4CiOh3RzFW",
        "outputId": "88a2e2c4-7998-4d29-add9-3631cc9403c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Authorize for runtime GCS:\n",
            "\u001b[1;33mWARNING:\u001b[0m The --[no-]launch-browser flags are deprecated and will be removed on June 7th 2022 (Release 389.0.0). Use --no-browser to replace --no-launch-browser.\n",
            "\n",
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=sDexGzyMkAKKKrKmWf5690ds3bCK85&prompt=consent&access_type=offline&code_challenge=jJmx5NYlPt3H0DYCJ5WGe1eIU2iK8-7_t4HUVmq_-wo&code_challenge_method=S256\n",
            "\n",
            "Enter verification code: 4/1AX4XfWhBug0C3usQ-hBTX1_YTiLhCICG9HJLi6e6g1_1gPTVO3QVQxRpL_k\n",
            "\n",
            "You are now logged in as [tianqitheodorejiang@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "Authorize for TPU GCS:\n",
            "\u001b[1;33mWARNING:\u001b[0m The --[no-]launch-browser flags are deprecated and will be removed on June 7th 2022 (Release 389.0.0). Use --no-browser to replace --no-launch-browser.\n",
            "\n",
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=SqLARAuT7TaU5rf13BDGK75iXm84pF&prompt=consent&access_type=offline&code_challenge=TCLfKVDa87n5CmDUN122ufcK-R12HF0fGljn58qDmtA&code_challenge_method=S256\n",
            "\n",
            "Enter verification code: 4/1AX4XfWgjVrYu3MHaxzEQuLgFrir0g8NxWQuAT8sf6UXI3l3zOZLA-rtWFjc\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n",
            "WARNING:tensorflow:From /content/mutformer/optimization.py:85: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:35:42,240 - tensorflow - INFO - Using TPU runtime\n",
            "2022-05-18 23:35:42,373 - tensorflow - INFO - TPU address is grpc://10.112.135.146:8470\n",
            "2022-05-18 23:35:42,378 - tensorflow - WARNING - \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not GCP_RUNTIME:\n",
        "  %tensorflow_version 1.x\n",
        "  def authenticate_user(): ##authentication function that uses link authentication instead of popup\n",
        "    if os.path.exists(\"/content/.config/application_default_credentials.json\"): \n",
        "      return\n",
        "    print(\"Authorize for runtime GCS:\")\n",
        "    !gcloud auth login --no-launch-browser\n",
        "    print(\"Authorize for TPU GCS:\")\n",
        "    !gcloud auth application-default login  --no-launch-browser\n",
        "  authenticate_user()\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import importlib\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if REPO_DESTINATION_PATH == \"mutformer\":\n",
        "  if os.path.exists(\"mutformer_code\"):\n",
        "    shutil.rmtree(\"mutformer_code\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH,\"mutformer_code\")\n",
        "  REPO_DESTINATION_PATH = \"mutformer_code\"\n",
        "if not os.path.exists(\"mutformer\"):\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "else:\n",
        "  shutil.rmtree(\"mutformer\")\n",
        "  shutil.copytree(REPO_DESTINATION_PATH+\"/mutformer_model_code\",\"mutformer\")\n",
        "if \"mutformer\" in sys.path:\n",
        "  sys.path.remove(\"mutformer\")\n",
        "sys.path.append(\"mutformer\")\n",
        "\n",
        "from mutformer import modeling, optimization, tokenization,run_classifier,run_ner_for_pathogenic  #### <<<<< if you added more modes, change these imports to import the correct processors, \n",
        "from mutformer.modeling import BertModel,BertModelModified                                        #### <<<<< correct training scripts (i.e. run_classifier and run_ner_for_pathogenic), and\n",
        "from mutformer.run_classifier import MrpcProcessor,REProcessor,MrpcWithExDataProcessor            #### <<<<< correct model classes\n",
        "from mutformer.run_ner_for_pathogenic import NERProcessor  \n",
        "\n",
        "##reload modules in case that's needed\n",
        "modules2reload = [modeling, \n",
        "                  optimization, \n",
        "                  tokenization,\n",
        "                  run_classifier,\n",
        "                  run_ner_for_pathogenic]\n",
        "for module in modules2reload:\n",
        "    importlib.reload(module)\n",
        "\n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "log.handlers = []\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "#@markdown Whether or not to write logs to a file\n",
        "DO_FILE_LOGGING = True #@param {type:\"boolean\"}\n",
        "if DO_FILE_LOGGING:\n",
        "  #@markdown * If using file logging, what path to write logs to\n",
        "  FILE_LOGGING_PATH = 'file_logging/spam.log' #@param {type:\"string\"}\n",
        "  if not os.path.exists(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1])):\n",
        "    os.makedirs(\"/\".join(FILE_LOGGING_PATH.split(\"/\")[:-1]))\n",
        "  fh = logging.FileHandler(FILE_LOGGING_PATH)\n",
        "  fh.setLevel(logging.INFO)\n",
        "  fh.setFormatter(formatter)\n",
        "  log.addHandler(fh)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "ch.setFormatter(formatter)\n",
        "log.addHandler(ch)\n",
        "\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    ##upload credentials to TPU.\n",
        "    with open(\"/content/.config/application_default_credentials.json\", 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "\n",
        "\n",
        "if MODE==\"MRPC\":      ####       vvvvv if you added more modes, change this part to set the processors and training scripts correctly vvvvv\n",
        "  processor = MrpcProcessor()\n",
        "  script = run_classifier\n",
        "  USING_EX_DATA = False\n",
        "elif MODE==\"MRPC_w_ex_data\":\n",
        "  processor = MrpcWithExDataProcessor()\n",
        "  script = run_classifier\n",
        "  USING_EX_DATA = True\n",
        "elif MODE==\"RE\":\n",
        "  processor = REProcessor()\n",
        "  script = run_classifier\n",
        "  USING_EX_DATA = False\n",
        "elif MODE==\"NER\":\n",
        "  processor = NERProcessor()\n",
        "  script = run_ner_for_pathogenic\n",
        "  USING_EX_DATA = False\n",
        "else:\n",
        "  raise Exception(\"The mode specified was not one of the available modes: [\\\"MRPC\\\",\\\"MRPC_w_ex_data\\\" \\\"RE\\\",\\\"NER\\\"].\")\n",
        "label_list = processor.get_labels()\n",
        "                      ####       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkFC96e0cK6n"
      },
      "source": [
        "# Run Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdWEQQ0vWBKU"
      },
      "source": [
        "This following section will perform finetuning tests for testing different models' performance with different parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ_lmHSa7ct_"
      },
      "source": [
        "###General definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bpaa3Eo7h8W"
      },
      "outputs": [],
      "source": [
        "def latest_checkpoint(dir):\n",
        "  cmd = \"gsutil ls \"+dir\n",
        "  files = !{cmd}\n",
        "  for file in files:\n",
        "    if \"model.ckpt\" in file:\n",
        "      return file.replace(\".\"+file.split(\".\")[-1],\"\")\n",
        "\n",
        "def training_loop(BATCH_SIZE,\n",
        "                  RESUMING,\n",
        "                  PLANNED_TOTAL_STEPS,\n",
        "                  DECAY_PER_STEP,\n",
        "                  MAX_SEQ_LENGTH,\n",
        "                  MODEL_NAME,\n",
        "                  MODEL,\n",
        "                  INIT_CHECKPOINT_DIR,\n",
        "                  GCS_OUTPUT_MODEL_DIR,\n",
        "                  DATA_GCS_DIR,\n",
        "                  USING_SHARDS,\n",
        "                  START_SHARD,\n",
        "                  USING_EX_DATA,\n",
        "                  EX_DATA_NUM,\n",
        "                  GCS_LOGGING_DIR,\n",
        "                  CONFIG_FILE,\n",
        "                  FREEZING=None):\n",
        "  \n",
        "  tf.logging.info(\"Using data from: \"+DATA_GCS_DIR)\n",
        "  tf.logging.info(\"Loading model from: \"+INIT_CHECKPOINT_DIR)\n",
        "\n",
        "\n",
        "  RESTORE_CHECKPOINT = None if not RESUMING else tf.train.latest_checkpoint(GCS_OUTPUT_MODEL_DIR)\n",
        "  if not RESUMING:\n",
        "    cmd = \"gsutil -m rm -r \"+GCS_OUTPUT_MODEL_DIR\n",
        "    !{cmd}\n",
        "\n",
        "  try: \n",
        "    INIT_CHECKPOINT = tf.train.latest_checkpoint(INIT_CHECKPOINT_DIR)\n",
        "  except:\n",
        "    INIT_CHECKPOINT = latest_checkpoint(INIT_CHECKPOINT_DIR)\n",
        "  print(\"init checkpoint:\",INIT_CHECKPOINT,\"restore/save checkpont:\",RESTORE_CHECKPOINT)\n",
        "\n",
        "  config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "  if not tf.io.gfile.exists(GCS_OUTPUT_MODEL_DIR+\"/config.json\"):\n",
        "    tf.io.gfile.copy(CONFIG_FILE,GCS_OUTPUT_MODEL_DIR+\"/config.json\")\n",
        "\n",
        "  model_fn = script.model_fn_builder(\n",
        "      bert_config=config,\n",
        "      logging_dir=GCS_LOGGING_DIR,\n",
        "      num_labels=len(label_list),\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      restore_checkpoint=RESTORE_CHECKPOINT,\n",
        "      init_learning_rate=INIT_LEARNING_RATE,\n",
        "      decay_per_step=DECAY_PER_STEP,\n",
        "      num_warmup_steps=NUM_WARMUP_STEPS,\n",
        "      use_tpu=True,\n",
        "      use_one_hot_embeddings=True,\n",
        "      bert=MODEL,\n",
        "      weight_decay=WEIGHT_DECAY,\n",
        "      epsilon=1e-6, ##epsilon is used to prevent dividing by zero\n",
        "      clip_grads=False,\n",
        "      freezing_x_layers=FREEZING,\n",
        "      using_ex_data=USING_EX_DATA)\n",
        "\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      model_dir=GCS_OUTPUT_MODEL_DIR,\n",
        "      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "      keep_checkpoint_max=KEEP_N_CHECKPOINTS_AT_A_TIME,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "          num_shards=NUM_TPU_CORES,\n",
        "          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=True,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=BATCH_SIZE)\n",
        "  \n",
        "  train_file_name = \"train.tf_record\"\n",
        "  train_file = os.path.join(DATA_GCS_DIR, train_file_name)\n",
        "\n",
        "  if USING_SHARDS:\n",
        "    shards_folder = DATA_GCS_DIR\n",
        "    input_file = os.path.join(DATA_GCS_DIR, train_file_name)\n",
        "    import re\n",
        "    file_name = input_file.split(\"/\")[-1]\n",
        "    shards = [shards_folder + \"/\" + file for file in tf.io.gfile.listdir(shards_folder) if\n",
        "              re.match(file_name + \"_\\d+\", file)]\n",
        "    shards = sorted(shards,key=lambda shard:int(shard.split(\"_\")[-1]))[START_SHARD:]\n",
        "  else:\n",
        "    shards = [train_file]\n",
        "\n",
        "  if USING_SHARDS:\n",
        "    print(\"\\nUSING SHARDs:\")\n",
        "    for shard in shards:\n",
        "      print(shard)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  tf.logging.info(\"***** Running training *****\")\n",
        "  tf.logging.info(\"  Batch size = %d\", BATCH_SIZE)\n",
        "  for n,shard in enumerate(shards):\n",
        "      train_input_fn = script.file_based_input_fn_builder(\n",
        "          input_file=shard,\n",
        "          seq_length=MAX_SEQ_LENGTH,\n",
        "          is_training=True,\n",
        "          drop_remainder=True,\n",
        "          pred_num=EX_DATA_NUM if USING_EX_DATA else None)\n",
        "      estimator.train(input_fn=train_input_fn, max_steps=PLANNED_TOTAL_STEPS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrgQPrH4kZV7"
      },
      "source": [
        "###Training Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqe2NOckb6OR"
      },
      "source": [
        "Following are three code segments to run. These options are:\n",
        "1. Model/sequence length: different model architectures will be tested using a fixed batch size on data of varying sequence lengths \\\n",
        "2. Sequence length/batch size: one model architecture will be tested using varying batch sizes on data of varying sequence lengths\\\n",
        "3. One model: one model architecture will be tested using a fixed batch size on a fixed set of data of a given sequence length\n",
        "\n",
        "Note: During training, evaluation results on the training dataset will be written into GCS. To view these results, use the colab notebook titled \"mutformer processing and viewing finetuning results.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AjnVKSMlVXz"
      },
      "source": [
        "####Model/sequence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrCuEbr6dv8U"
      },
      "outputs": [],
      "source": [
        "#@markdown ### IO config\n",
        "#@markdown Folder in GCS where the pretrained models needs to be loaded from:\n",
        "INIT_MODEL_DIR = \"pretrained_models\" #@param {type:\"string\"}\n",
        "#@markdown Folder for where to save the finetuned models:\n",
        "OUTPUT_MODEL_DIR = \"bert_model_mrpc_ex_data_all3_22_3\" #@param {type:\"string\"}\n",
        "#@markdown Which folder inside of LOGGING_DIR to store the logs in\n",
        "RUN_NAME = \"MRPC_ex_data_all3_22_3\" #@param {type:\"string\"}\n",
        "#@markdown \\\n",
        "#@markdown \n",
        "#@markdown \n",
        "#@markdown ### Training procedure config\n",
        "#@markdown Batch size to use\n",
        "BATCH_SIZE =  16#@param {type:\"integer\"}\n",
        "#@markdown The training loop will loop through a list of pretrained models and a list of sequence lengths, training a model for each combination of pretrained model and sequence length\n",
        "#@markdown * List of pretrained models to load (should indicate the names of the model folders inside the specified INIT_MODEL_DIR\n",
        "MODELS =  [\"MutFormer_em_adap8L\"]#,\"MutFormer10L\",\"MutFormer12L\"]#@param\n",
        "#@markdown * List of model architectures for each model in the \"MODELS\" list defined in the entry above: each position in this list must correctly indicate the model architecture of its corresponding model folder in the list \"MODELS\" (BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture).\n",
        "MODEL_ARCHITECTURES = [\"MutFormer_embedded_convs\"]#,\"BertModelModified\",\"BertModelModified\"] #@param\n",
        "#@markdown * List of sequence lengths to test\n",
        "MAX_SEQ_LENGTHS = [1024]#,512] #@param\n",
        "#@markdown Whether or not to resume training from a previous checkpoint; if no, always train from scratch\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown Whether or not data was generated in shards (for really large databases)\n",
        "USING_SHARDS = False #@param {type:\"boolean\"}\n",
        "#@markdown If training data was generated in shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD = 0 #@param {type:\"integer\"}\n",
        "#@markdown Training uses a linear learning rate.\n",
        "#@markdown * Start learning rate: training will start with this learning rate on the step that learning rate warmup is complete\n",
        "INIT_LEARNING_RATE =  2e-6 #@param {type:\"number\"}\n",
        "#@markdown * End learning rate: training will alter the learning rate every step linearly so that it finishes with this learning rate on the last step.\n",
        "END_LEARNING_RATE = 3e-8 #@param {type:\"number\"}\n",
        "#@markdown How many steps during training to perform learning rate warmup for (start from learning rate 0 and increase to INIT_LEARNING_RATE): Set to 0 for no warmup.\n",
        "NUM_WARMUP_STEPS =  0#@param {type:\"integer\"}\n",
        "#@markdown What weight decay value to use (MutFormer uses 0.01; a higher weight decay is more resistant to exploding gradients, but also limits the model's ability to learn)\n",
        "WEIGHT_DECAY = 0.01 #@param {type:\"number\"}\n",
        "#@markdown Save a checkpoint every this amount of steps:\n",
        "SAVE_CHECKPOINTS_STEPS =   1000#@param {type:\"integer\"}\n",
        "#@markdown TPUEstimator will keep this number of checkpoints at a time; older checkpoints will all be deleted:\n",
        "KEEP_N_CHECKPOINTS_AT_A_TIME =  100#@param {type:\"integer\"}\n",
        "#@markdown How many sequences should the model train on before stopping:\n",
        "PLANNED_TOTAL_SEQUENCES_SEEN =  2e5 #@param {type:\"number\"}\n",
        "#@markdown How many steps should the model train for before stopping (number of total sequences trained on will depend on the batch size used). NOTE: PLANNED_TOTAL_STEPS will override PLANNED_TOTAL_SEQUENCES_SEEN; if using PLANNED_TOTAL_SEQUENCES_SEEN, set PLANNED_TOTAL_STEPS to -1 (PLANNED TOTAL STEPS will be based on the train batch size used, which can be specified later)\n",
        "PLANNED_TOTAL_STEPS =  10000#@param {type:\"number\"}\n",
        "\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/BATCH_SIZE) \n",
        "\n",
        "DATA_INFOS = [[\"N/A\" for MODEL_NAME in MODELS]            ##create an empty 2D list to store all\n",
        "              for MAX_SEQ_LENGTH in MAX_SEQ_LENGTHS]      ##the data info dictionaries\n",
        "                                                                                   \n",
        "for M,MAX_SEQ_LENGTH in enumerate(MAX_SEQ_LENGTHS):\n",
        "  for m,MODEL_NAME in enumerate(MODELS):\n",
        "    print(\"\\n\\n\\nMODEL NAME:\",MODEL_NAME,\n",
        "          \"\\nINPUT MAX SEQ LENGTH:\",MAX_SEQ_LENGTH)\n",
        "\n",
        "\n",
        "    MODEL = getattr(modeling, MODEL_ARCHITECTURES[m])\n",
        "    INIT_CHECKPOINT_DIR = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME\n",
        "    GCS_OUTPUT_MODEL_DIR = BUCKET_PATH+\"/\"+OUTPUT_MODEL_DIR+\"/mn_\"+MODEL_NAME+\"_sl_\"+str(MAX_SEQ_LENGTH)\n",
        "    DATA_GCS_DIR = BUCKET_PATH+\"/\"+PROCESSED_DATA_DIR+\"/\"+str(MAX_SEQ_LENGTH)\n",
        "    \n",
        "    GCS_LOGGING_DIR = BUCKET_PATH+\"/\"+LOGGING_DIR+\"/\"+RUN_NAME+\"/mn_\"+MODEL_NAME+\"_sl_\"+str(MAX_SEQ_LENGTH)\n",
        "\n",
        "    CONFIG_FILE = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME+\"/config.json\"\n",
        "    \n",
        "    if DATA_INFOS[M][m] == \"N/A\":\n",
        "      DATA_INFOS[M][m] = json.load(tf.gfile.Open(DATA_GCS_DIR+\"/info.json\"))\n",
        "    \n",
        "    EX_DATA_NUM = DATA_INFOS[M][m][\"ex_data_num\"] if USING_EX_DATA else 0\n",
        "    \n",
        "    training_loop(BATCH_SIZE,\n",
        "                  RESUMING,\n",
        "                  PLANNED_TOTAL_STEPS,\n",
        "                  DECAY_PER_STEP,\n",
        "                  MAX_SEQ_LENGTH,\n",
        "                  MODEL_NAME,\n",
        "                  MODEL,\n",
        "                  INIT_CHECKPOINT_DIR,\n",
        "                  GCS_OUTPUT_MODEL_DIR,\n",
        "                  DATA_GCS_DIR,\n",
        "                  USING_SHARDS,\n",
        "                  START_SHARD,\n",
        "                  USING_EX_DATA,\n",
        "                  EX_DATA_NUM,\n",
        "                  GCS_LOGGING_DIR,\n",
        "                  CONFIG_FILE)\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP6CPmRoIWOm"
      },
      "source": [
        "####Freezing/Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYXyCw2kVO9k",
        "outputId": "916fc3db-9b3b-449a-c955-9b082d6f7864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000000\n"
          ]
        }
      ],
      "source": [
        "asdf = 0\n",
        "for i in range(0,10000000):\n",
        "    asdf+=1**2\n",
        "print(asdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOuxQ5NeGM4v",
        "outputId": "5560844c-bb5c-464f-e168-59dd1915478f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Freezing layers: 8 \n",
            "BATCH SIZE: 16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:37:15,952 - tensorflow - INFO - Using data from: gs://theodore_jiang/compiled_finetune_data/MRPC_ex_data_all_finetune_update_loaded/512\n",
            "2022-05-18 23:37:15,954 - tensorflow - INFO - Loading model from: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L\n",
            "2022-05-18 23:37:17,518 - tensorflow - WARNING - From /content/mutformer/modeling.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "init checkpoint: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056 restore/save checkpont: gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_8_bs_16/model.ckpt-14000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:37:18,345 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1829d95830>) includes params argument, but params are not passed to Estimator.\n",
            "2022-05-18 23:37:18,348 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_8_bs_16', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.112.135.146:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f181e4d0ed0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.112.135.146:8470', '_evaluation_master': 'grpc://10.112.135.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f181e4db7d0>}\n",
            "2022-05-18 23:37:18,352 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2022-05-18 23:37:18,354 - tensorflow - INFO - ***** Running training *****\n",
            "2022-05-18 23:37:18,357 - tensorflow - INFO -   Batch size = 16\n",
            "2022-05-18 23:37:18,359 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:378: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2022-05-18 23:37:20,478 - tensorflow - INFO - Skipping training since max_steps has already saved.\n",
            "2022-05-18 23:37:20,480 - tensorflow - INFO - training_loop marked as finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Freezing layers: 8 \n",
            "BATCH SIZE: 64\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:37:20,881 - tensorflow - INFO - Using data from: gs://theodore_jiang/compiled_finetune_data/MRPC_ex_data_all_finetune_update_loaded/512\n",
            "2022-05-18 23:37:20,883 - tensorflow - INFO - Loading model from: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "init checkpoint: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056 restore/save checkpont: gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_8_bs_64/model.ckpt-14000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:37:22,736 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f181e4c5b00>) includes params argument, but params are not passed to Estimator.\n",
            "2022-05-18 23:37:22,738 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_8_bs_64', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.112.135.146:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f181e52c550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.112.135.146:8470', '_evaluation_master': 'grpc://10.112.135.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f187e73d350>}\n",
            "2022-05-18 23:37:22,740 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2022-05-18 23:37:22,741 - tensorflow - INFO - ***** Running training *****\n",
            "2022-05-18 23:37:22,742 - tensorflow - INFO -   Batch size = 64\n",
            "2022-05-18 23:37:25,038 - tensorflow - INFO - Skipping training since max_steps has already saved.\n",
            "2022-05-18 23:37:25,040 - tensorflow - INFO - training_loop marked as finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Freezing layers: 6 \n",
            "BATCH SIZE: 16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:37:25,486 - tensorflow - INFO - Using data from: gs://theodore_jiang/compiled_finetune_data/MRPC_ex_data_all_finetune_update_loaded/512\n",
            "2022-05-18 23:37:25,488 - tensorflow - INFO - Loading model from: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "init checkpoint: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056 restore/save checkpont: gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt-3000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:37:27,617 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f181e4ffdd0>) includes params argument, but params are not passed to Estimator.\n",
            "2022-05-18 23:37:27,620 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.112.135.146:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f181e52cad0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.112.135.146:8470', '_evaluation_master': 'grpc://10.112.135.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f181e52cc50>}\n",
            "2022-05-18 23:37:27,623 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2022-05-18 23:37:27,626 - tensorflow - INFO - ***** Running training *****\n",
            "2022-05-18 23:37:27,629 - tensorflow - INFO -   Batch size = 16\n",
            "2022-05-18 23:37:30,008 - tensorflow - INFO - Querying Tensorflow master (grpc://10.112.135.146:8470) for TPU system metadata.\n",
            "2022-05-18 23:37:30,028 - tensorflow - INFO - Found TPU system:\n",
            "2022-05-18 23:37:30,031 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2022-05-18 23:37:30,035 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2022-05-18 23:37:30,037 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2022-05-18 23:37:30,039 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7744513791632944376)\n",
            "2022-05-18 23:37:30,041 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7897525396200153615)\n",
            "2022-05-18 23:37:30,042 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18203121091228161108)\n",
            "2022-05-18 23:37:30,044 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7643529171897127319)\n",
            "2022-05-18 23:37:30,046 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5098989032771748931)\n",
            "2022-05-18 23:37:30,048 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17355166448020794620)\n",
            "2022-05-18 23:37:30,049 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10263619074854522981)\n",
            "2022-05-18 23:37:30,053 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6177495284628076268)\n",
            "2022-05-18 23:37:30,054 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13200199635073852883)\n",
            "2022-05-18 23:37:30,056 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11839754200800065391)\n",
            "2022-05-18 23:37:30,057 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15915597681490588600)\n",
            "2022-05-18 23:37:30,068 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2022-05-18 23:37:30,078 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2022-05-18 23:37:30,105 - tensorflow - INFO - Calling model_fn.\n",
            "2022-05-18 23:37:30,141 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:434: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2022-05-18 23:37:30,143 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2022-05-18 23:37:30,163 - tensorflow - WARNING - Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f181f7bd050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2022-05-18 23:37:30,165 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:396: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2022-05-18 23:37:30,182 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:403: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2022-05-18 23:37:30,288 - tensorflow - INFO - *** Features ***\n",
            "2022-05-18 23:37:30,289 - tensorflow - INFO -   name = ex_data, shape = (2, 27)\n",
            "2022-05-18 23:37:30,294 - tensorflow - INFO -   name = input_ids, shape = (2, 512)\n",
            "2022-05-18 23:37:30,297 - tensorflow - INFO -   name = input_mask, shape = (2, 512)\n",
            "2022-05-18 23:37:30,300 - tensorflow - INFO -   name = is_real_example, shape = (2,)\n",
            "2022-05-18 23:37:30,313 - tensorflow - INFO -   name = label_ids, shape = (2,)\n",
            "2022-05-18 23:37:30,315 - tensorflow - INFO -   name = segment_ids, shape = (2, 512)\n",
            "2022-05-18 23:37:30,316 - tensorflow - WARNING - From /content/mutformer/modeling.py:425: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2022-05-18 23:37:30,327 - tensorflow - WARNING - From /content/mutformer/modeling.py:920: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f181f7bd050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-18 23:37:30,381 - tensorflow - WARNING - From /content/mutformer/modeling.py:1003: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2022-05-18 23:37:30,441 - tensorflow - WARNING - From /content/mutformer/modeling.py:869: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2022-05-18 23:37:30,794 - tensorflow - WARNING - From /content/mutformer/modeling.py:1184: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2022-05-18 23:37:30,797 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2022-05-18 23:37:32,909 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:557: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "2022-05-18 23:37:34,393 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2022-05-18 23:37:34,396 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,403 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,408 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,412 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,415 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,417 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,421 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,425 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,428 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,433 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,435 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,436 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,439 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,444 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,456 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,459 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,461 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,465 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,468 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,472 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,474 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,479 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,480 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,486 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,491 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,492 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,496 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,498 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,500 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,503 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,506 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,508 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,512 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,514 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,516 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,518 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,520 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,524 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,526 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,529 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,530 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,532 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,535 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,536 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,538 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,539 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,544 - tensorflow - INFO -   name = extra_data_layers/pred_dense/kernel:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,546 - tensorflow - INFO -   name = extra_data_layers/pred_dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,552 - tensorflow - INFO -   name = extra_data_layers/combine_dense/kernel:0, shape = (1536, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,554 - tensorflow - INFO -   name = extra_data_layers/combine_dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,555 - tensorflow - INFO -   name = output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,557 - tensorflow - INFO -   name = output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "2022-05-18 23:37:34,558 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:620: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2022-05-18 23:37:34,965 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2022-05-18 23:37:43,121 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:576: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "2022-05-18 23:37:45,758 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:577: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "2022-05-18 23:37:45,793 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:679: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
            "\n",
            "2022-05-18 23:37:45,878 - tensorflow - INFO - Create CheckpointSaverHook.\n",
            "2022-05-18 23:37:46,162 - tensorflow - INFO - Done calling model_fn.\n",
            "2022-05-18 23:37:49,281 - tensorflow - INFO - TPU job name worker\n",
            "2022-05-18 23:37:50,456 - tensorflow - INFO - Graph was finalized.\n",
            "2022-05-18 23:37:51,155 - tensorflow - INFO - Restoring parameters from gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt-3000\n",
            "2022-05-18 23:38:03,405 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "2022-05-18 23:38:05,634 - tensorflow - INFO - Running local_init_op.\n",
            "2022-05-18 23:38:06,012 - tensorflow - INFO - Done running local_init_op.\n",
            "2022-05-18 23:38:14,117 - tensorflow - INFO - Saving checkpoints for 3000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-18 23:38:35,661 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2022-05-18 23:38:36,428 - tensorflow - INFO - Initialized dataset iterators in 0 seconds\n",
            "2022-05-18 23:38:36,430 - tensorflow - INFO - Installing graceful shutdown hook.\n",
            "2022-05-18 23:38:36,438 - tensorflow - INFO - Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2022-05-18 23:38:36,445 - tensorflow - INFO - Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2022-05-18 23:38:36,453 - tensorflow - INFO - Init TPU system\n",
            "2022-05-18 23:38:42,330 - tensorflow - INFO - Initialized TPU in 5 seconds\n",
            "2022-05-18 23:38:43,544 - tensorflow - INFO - Starting infeed thread controller.\n",
            "2022-05-18 23:38:43,544 - tensorflow - INFO - Starting outfeed thread controller.\n",
            "2022-05-18 23:38:43,916 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-18 23:38:43,918 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-18 23:39:03,699 - tensorflow - INFO - Outfeed finished for iteration (0, 0)\n",
            "2022-05-18 23:40:04,276 - tensorflow - INFO - Outfeed finished for iteration (0, 146)\n",
            "2022-05-18 23:41:05,027 - tensorflow - INFO - Outfeed finished for iteration (0, 289)\n",
            "2022-05-18 23:42:05,040 - tensorflow - INFO - Outfeed finished for iteration (0, 432)\n",
            "2022-05-18 23:43:05,074 - tensorflow - INFO - Outfeed finished for iteration (0, 571)\n",
            "2022-05-18 23:44:05,267 - tensorflow - INFO - Outfeed finished for iteration (0, 711)\n",
            "2022-05-18 23:45:05,333 - tensorflow - INFO - Outfeed finished for iteration (0, 852)\n",
            "2022-05-18 23:45:13,028 - tensorflow - INFO - Saving checkpoints for 4000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-18 23:45:34,428 - tensorflow - INFO - loss = 2.6700975e-05, step = 4000\n",
            "2022-05-18 23:45:34,435 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-18 23:45:34,437 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-18 23:46:05,924 - tensorflow - INFO - Outfeed finished for iteration (0, 977)\n",
            "2022-05-18 23:47:06,611 - tensorflow - INFO - Outfeed finished for iteration (1, 116)\n",
            "2022-05-18 23:48:06,955 - tensorflow - INFO - Outfeed finished for iteration (1, 257)\n",
            "2022-05-18 23:49:06,958 - tensorflow - INFO - Outfeed finished for iteration (1, 393)\n",
            "2022-05-18 23:50:07,627 - tensorflow - INFO - Outfeed finished for iteration (1, 532)\n",
            "2022-05-18 23:51:08,128 - tensorflow - INFO - Outfeed finished for iteration (1, 655)\n",
            "2022-05-18 23:52:08,838 - tensorflow - INFO - Outfeed finished for iteration (1, 783)\n",
            "2022-05-18 23:52:46,579 - tensorflow - INFO - Saving checkpoints for 5000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-18 23:53:07,962 - tensorflow - INFO - loss = 1.5377194e-05, step = 5000 (453.534 sec)\n",
            "2022-05-18 23:53:07,970 - tensorflow - INFO - global_step/sec: 2.2049\n",
            "2022-05-18 23:53:07,976 - tensorflow - INFO - examples/sec: 35.2785\n",
            "2022-05-18 23:53:07,982 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-18 23:53:07,986 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-18 23:53:09,667 - tensorflow - INFO - Outfeed finished for iteration (1, 919)\n",
            "2022-05-18 23:54:10,185 - tensorflow - INFO - Outfeed finished for iteration (2, 49)\n",
            "2022-05-18 23:55:10,385 - tensorflow - INFO - Outfeed finished for iteration (2, 185)\n",
            "2022-05-18 23:56:10,782 - tensorflow - INFO - Outfeed finished for iteration (2, 319)\n",
            "2022-05-18 23:57:11,345 - tensorflow - INFO - Outfeed finished for iteration (2, 454)\n",
            "2022-05-18 23:58:12,188 - tensorflow - INFO - Outfeed finished for iteration (2, 577)\n",
            "2022-05-18 23:59:13,063 - tensorflow - INFO - Outfeed finished for iteration (2, 709)\n",
            "2022-05-19 00:00:13,533 - tensorflow - INFO - Outfeed finished for iteration (2, 841)\n",
            "2022-05-19 00:00:25,866 - tensorflow - INFO - Saving checkpoints for 6000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:00:46,753 - tensorflow - INFO - loss = 1.5257838e-05, step = 6000 (458.791 sec)\n",
            "2022-05-19 00:00:46,759 - tensorflow - INFO - global_step/sec: 2.17964\n",
            "2022-05-19 00:00:46,761 - tensorflow - INFO - examples/sec: 34.8743\n",
            "2022-05-19 00:00:46,767 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:00:46,769 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:01:14,412 - tensorflow - INFO - Outfeed finished for iteration (2, 964)\n",
            "2022-05-19 00:02:14,962 - tensorflow - INFO - Outfeed finished for iteration (3, 85)\n",
            "2022-05-19 00:03:15,649 - tensorflow - INFO - Outfeed finished for iteration (3, 217)\n",
            "2022-05-19 00:04:15,844 - tensorflow - INFO - Outfeed finished for iteration (3, 340)\n",
            "2022-05-19 00:05:16,655 - tensorflow - INFO - Outfeed finished for iteration (3, 463)\n",
            "2022-05-19 00:06:16,785 - tensorflow - INFO - Outfeed finished for iteration (3, 595)\n",
            "2022-05-19 00:07:17,135 - tensorflow - INFO - Outfeed finished for iteration (3, 730)\n",
            "2022-05-19 00:08:17,887 - tensorflow - INFO - Outfeed finished for iteration (3, 868)\n",
            "2022-05-19 00:08:18,372 - tensorflow - INFO - Saving checkpoints for 7000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:08:39,624 - tensorflow - INFO - loss = 7.1525683e-06, step = 7000 (472.871 sec)\n",
            "2022-05-19 00:08:39,631 - tensorflow - INFO - global_step/sec: 2.11474\n",
            "2022-05-19 00:08:39,636 - tensorflow - INFO - examples/sec: 33.8358\n",
            "2022-05-19 00:08:39,642 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:08:39,646 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:09:18,541 - tensorflow - INFO - Outfeed finished for iteration (3, 996)\n",
            "2022-05-19 00:10:18,588 - tensorflow - INFO - Outfeed finished for iteration (4, 128)\n",
            "2022-05-19 00:11:18,730 - tensorflow - INFO - Outfeed finished for iteration (4, 258)\n",
            "2022-05-19 00:12:19,484 - tensorflow - INFO - Outfeed finished for iteration (4, 392)\n",
            "2022-05-19 00:13:19,956 - tensorflow - INFO - Outfeed finished for iteration (4, 524)\n",
            "2022-05-19 00:14:20,700 - tensorflow - INFO - Outfeed finished for iteration (4, 643)\n",
            "2022-05-19 00:15:21,112 - tensorflow - INFO - Outfeed finished for iteration (4, 755)\n",
            "2022-05-19 00:16:15,925 - tensorflow - INFO - Saving checkpoints for 8000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:16:21,818 - tensorflow - INFO - Outfeed finished for iteration (4, 882)\n",
            "2022-05-19 00:16:36,868 - tensorflow - INFO - loss = 4.410527e-06, step = 8000 (477.243 sec)\n",
            "2022-05-19 00:16:36,878 - tensorflow - INFO - global_step/sec: 2.09535\n",
            "2022-05-19 00:16:36,882 - tensorflow - INFO - examples/sec: 33.5256\n",
            "2022-05-19 00:16:36,888 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:16:36,890 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:17:22,386 - tensorflow - INFO - Outfeed finished for iteration (5, 6)\n",
            "2022-05-19 00:18:22,767 - tensorflow - INFO - Outfeed finished for iteration (5, 133)\n",
            "2022-05-19 00:19:23,311 - tensorflow - INFO - Outfeed finished for iteration (5, 252)\n",
            "2022-05-19 00:20:23,560 - tensorflow - INFO - Outfeed finished for iteration (5, 382)\n",
            "2022-05-19 00:21:23,587 - tensorflow - INFO - Outfeed finished for iteration (5, 512)\n",
            "2022-05-19 00:22:24,956 - tensorflow - INFO - Outfeed finished for iteration (5, 633)\n",
            "2022-05-19 00:23:25,028 - tensorflow - INFO - Outfeed finished for iteration (5, 751)\n",
            "2022-05-19 00:24:19,171 - tensorflow - INFO - Saving checkpoints for 9000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:24:25,914 - tensorflow - INFO - Outfeed finished for iteration (5, 883)\n",
            "2022-05-19 00:24:40,370 - tensorflow - INFO - loss = 2.1458147e-06, step = 9000 (483.502 sec)\n",
            "2022-05-19 00:24:40,380 - tensorflow - INFO - global_step/sec: 2.06824\n",
            "2022-05-19 00:24:40,385 - tensorflow - INFO - examples/sec: 33.0919\n",
            "2022-05-19 00:24:40,391 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:24:40,392 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:25:26,168 - tensorflow - INFO - Outfeed finished for iteration (6, 0)\n",
            "2022-05-19 00:26:26,252 - tensorflow - INFO - Outfeed finished for iteration (6, 132)\n",
            "2022-05-19 00:27:26,751 - tensorflow - INFO - Outfeed finished for iteration (6, 251)\n",
            "2022-05-19 00:28:26,784 - tensorflow - INFO - Outfeed finished for iteration (6, 374)\n",
            "2022-05-19 00:29:26,798 - tensorflow - INFO - Outfeed finished for iteration (6, 497)\n",
            "2022-05-19 00:30:27,120 - tensorflow - INFO - Outfeed finished for iteration (6, 625)\n",
            "2022-05-19 00:31:27,743 - tensorflow - INFO - Outfeed finished for iteration (6, 750)\n",
            "2022-05-19 00:32:20,178 - tensorflow - INFO - Saving checkpoints for 10000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:32:28,347 - tensorflow - INFO - Outfeed finished for iteration (6, 887)\n",
            "2022-05-19 00:32:40,867 - tensorflow - INFO - loss = 2.1458147e-06, step = 10000 (480.498 sec)\n",
            "2022-05-19 00:32:40,876 - tensorflow - INFO - global_step/sec: 2.08119\n",
            "2022-05-19 00:32:40,877 - tensorflow - INFO - examples/sec: 33.299\n",
            "2022-05-19 00:32:40,884 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:32:40,888 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:33:28,775 - tensorflow - INFO - Outfeed finished for iteration (7, 10)\n",
            "2022-05-19 00:34:28,790 - tensorflow - INFO - Outfeed finished for iteration (7, 138)\n",
            "2022-05-19 00:35:29,048 - tensorflow - INFO - Outfeed finished for iteration (7, 259)\n",
            "2022-05-19 00:36:29,332 - tensorflow - INFO - Outfeed finished for iteration (7, 390)\n",
            "2022-05-19 00:37:29,584 - tensorflow - INFO - Outfeed finished for iteration (7, 518)\n",
            "2022-05-19 00:38:29,805 - tensorflow - INFO - Outfeed finished for iteration (7, 646)\n",
            "2022-05-19 00:39:30,546 - tensorflow - INFO - Outfeed finished for iteration (7, 773)\n",
            "2022-05-19 00:40:20,768 - tensorflow - INFO - Saving checkpoints for 11000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:40:30,995 - tensorflow - INFO - Outfeed finished for iteration (7, 890)\n",
            "2022-05-19 00:40:42,895 - tensorflow - INFO - loss = 1.3113488e-06, step = 11000 (482.028 sec)\n",
            "2022-05-19 00:40:42,902 - tensorflow - INFO - global_step/sec: 2.07457\n",
            "2022-05-19 00:40:42,905 - tensorflow - INFO - examples/sec: 33.1932\n",
            "2022-05-19 00:40:42,913 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:40:42,920 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:41:31,257 - tensorflow - INFO - Outfeed finished for iteration (8, 15)\n",
            "2022-05-19 00:42:31,837 - tensorflow - INFO - Outfeed finished for iteration (8, 149)\n",
            "2022-05-19 00:43:32,297 - tensorflow - INFO - Outfeed finished for iteration (8, 275)\n",
            "2022-05-19 00:44:32,665 - tensorflow - INFO - Outfeed finished for iteration (8, 407)\n",
            "2022-05-19 00:45:32,834 - tensorflow - INFO - Outfeed finished for iteration (8, 537)\n",
            "2022-05-19 00:46:33,158 - tensorflow - INFO - Outfeed finished for iteration (8, 677)\n",
            "2022-05-19 00:47:33,731 - tensorflow - INFO - Outfeed finished for iteration (8, 810)\n",
            "2022-05-19 00:48:00,831 - tensorflow - INFO - Saving checkpoints for 12000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:48:22,686 - tensorflow - INFO - loss = 1.3112378e-06, step = 12000 (459.791 sec)\n",
            "2022-05-19 00:48:22,693 - tensorflow - INFO - global_step/sec: 2.1749\n",
            "2022-05-19 00:48:22,695 - tensorflow - INFO - examples/sec: 34.7984\n",
            "2022-05-19 00:48:22,704 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:48:22,706 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:48:34,576 - tensorflow - INFO - Outfeed finished for iteration (8, 941)\n",
            "2022-05-19 00:49:35,465 - tensorflow - INFO - Outfeed finished for iteration (9, 56)\n",
            "2022-05-19 00:50:35,581 - tensorflow - INFO - Outfeed finished for iteration (9, 168)\n",
            "2022-05-19 00:51:35,849 - tensorflow - INFO - Outfeed finished for iteration (9, 293)\n",
            "2022-05-19 00:52:36,642 - tensorflow - INFO - Outfeed finished for iteration (9, 423)\n",
            "2022-05-19 00:53:36,965 - tensorflow - INFO - Outfeed finished for iteration (9, 544)\n",
            "2022-05-19 00:54:37,245 - tensorflow - INFO - Outfeed finished for iteration (9, 670)\n",
            "2022-05-19 00:55:38,186 - tensorflow - INFO - Outfeed finished for iteration (9, 797)\n",
            "2022-05-19 00:56:14,018 - tensorflow - INFO - Saving checkpoints for 13000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 00:56:34,524 - tensorflow - INFO - loss = 8.3447355e-07, step = 13000 (491.838 sec)\n",
            "2022-05-19 00:56:34,529 - tensorflow - INFO - global_step/sec: 2.0332\n",
            "2022-05-19 00:56:34,532 - tensorflow - INFO - examples/sec: 32.5312\n",
            "2022-05-19 00:56:34,539 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 00:56:34,542 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 00:56:38,781 - tensorflow - INFO - Outfeed finished for iteration (9, 918)\n",
            "2022-05-19 00:57:39,241 - tensorflow - INFO - Outfeed finished for iteration (10, 52)\n",
            "2022-05-19 00:58:39,460 - tensorflow - INFO - Outfeed finished for iteration (10, 171)\n",
            "2022-05-19 00:59:40,338 - tensorflow - INFO - Outfeed finished for iteration (10, 290)\n",
            "2022-05-19 01:00:40,827 - tensorflow - INFO - Outfeed finished for iteration (10, 415)\n",
            "2022-05-19 01:01:41,667 - tensorflow - INFO - Outfeed finished for iteration (10, 537)\n",
            "2022-05-19 01:02:42,057 - tensorflow - INFO - Outfeed finished for iteration (10, 666)\n",
            "2022-05-19 01:03:42,261 - tensorflow - INFO - Outfeed finished for iteration (10, 794)\n",
            "2022-05-19 01:04:19,347 - tensorflow - INFO - Saving checkpoints for 14000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_16/model.ckpt.\n",
            "2022-05-19 01:04:38,156 - tensorflow - INFO - loss = 1.1921072e-06, step = 14000 (483.632 sec)\n",
            "2022-05-19 01:04:38,163 - tensorflow - INFO - global_step/sec: 2.06768\n",
            "2022-05-19 01:04:38,168 - tensorflow - INFO - examples/sec: 33.0828\n",
            "2022-05-19 01:04:39,045 - tensorflow - INFO - Stop infeed thread controller\n",
            "2022-05-19 01:04:39,047 - tensorflow - INFO - Shutting down InfeedController thread.\n",
            "2022-05-19 01:04:39,050 - tensorflow - INFO - InfeedController received shutdown signal, stopping.\n",
            "2022-05-19 01:04:39,054 - tensorflow - INFO - Infeed thread finished, shutting down.\n",
            "2022-05-19 01:04:39,058 - tensorflow - INFO - infeed marked as finished\n",
            "2022-05-19 01:04:39,060 - tensorflow - INFO - Stop output thread controller\n",
            "2022-05-19 01:04:39,061 - tensorflow - INFO - Shutting down OutfeedController thread.\n",
            "2022-05-19 01:04:42,921 - tensorflow - INFO - Outfeed finished for iteration (10, 921)\n",
            "2022-05-19 01:05:20,127 - tensorflow - INFO - OutfeedController received shutdown signal, stopping.\n",
            "2022-05-19 01:05:20,129 - tensorflow - INFO - Outfeed thread finished, shutting down.\n",
            "2022-05-19 01:05:20,131 - tensorflow - INFO - outfeed marked as finished\n",
            "2022-05-19 01:05:20,133 - tensorflow - INFO - Shutdown TPU system.\n",
            "2022-05-19 01:05:20,973 - tensorflow - INFO - Loss for final step: 1.1921072e-06.\n",
            "2022-05-19 01:05:20,975 - tensorflow - INFO - training_loop marked as finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Freezing layers: 6 \n",
            "BATCH SIZE: 64\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 01:05:21,464 - tensorflow - INFO - Using data from: gs://theodore_jiang/compiled_finetune_data/MRPC_ex_data_all_finetune_update_loaded/512\n",
            "2022-05-19 01:05:21,466 - tensorflow - INFO - Loading model from: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "init checkpoint: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056 restore/save checkpont: None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 01:05:24,545 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1818399c20>) includes params argument, but params are not passed to Estimator.\n",
            "2022-05-19 01:05:24,547 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.112.135.146:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1816a73e50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.112.135.146:8470', '_evaluation_master': 'grpc://10.112.135.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f1816a04810>}\n",
            "2022-05-19 01:05:24,555 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2022-05-19 01:05:24,560 - tensorflow - INFO - ***** Running training *****\n",
            "2022-05-19 01:05:24,565 - tensorflow - INFO -   Batch size = 64\n",
            "2022-05-19 01:05:25,008 - tensorflow - INFO - Querying Tensorflow master (grpc://10.112.135.146:8470) for TPU system metadata.\n",
            "2022-05-19 01:05:25,026 - tensorflow - INFO - Found TPU system:\n",
            "2022-05-19 01:05:25,028 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2022-05-19 01:05:25,030 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2022-05-19 01:05:25,032 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2022-05-19 01:05:25,036 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7744513791632944376)\n",
            "2022-05-19 01:05:25,038 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7897525396200153615)\n",
            "2022-05-19 01:05:25,041 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18203121091228161108)\n",
            "2022-05-19 01:05:25,043 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7643529171897127319)\n",
            "2022-05-19 01:05:25,046 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5098989032771748931)\n",
            "2022-05-19 01:05:25,048 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17355166448020794620)\n",
            "2022-05-19 01:05:25,050 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10263619074854522981)\n",
            "2022-05-19 01:05:25,052 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6177495284628076268)\n",
            "2022-05-19 01:05:25,053 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13200199635073852883)\n",
            "2022-05-19 01:05:25,056 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11839754200800065391)\n",
            "2022-05-19 01:05:25,064 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15915597681490588600)\n",
            "2022-05-19 01:05:25,102 - tensorflow - INFO - Calling model_fn.\n",
            "2022-05-19 01:05:25,131 - tensorflow - WARNING - Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f18169f3170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2022-05-19 01:05:25,226 - tensorflow - INFO - *** Features ***\n",
            "2022-05-19 01:05:25,227 - tensorflow - INFO -   name = ex_data, shape = (8, 27)\n",
            "2022-05-19 01:05:25,231 - tensorflow - INFO -   name = input_ids, shape = (8, 512)\n",
            "2022-05-19 01:05:25,236 - tensorflow - INFO -   name = input_mask, shape = (8, 512)\n",
            "2022-05-19 01:05:25,242 - tensorflow - INFO -   name = is_real_example, shape = (8,)\n",
            "2022-05-19 01:05:25,247 - tensorflow - INFO -   name = label_ids, shape = (8,)\n",
            "2022-05-19 01:05:25,251 - tensorflow - INFO -   name = segment_ids, shape = (8, 512)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f18169f3170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 01:05:30,042 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2022-05-19 01:05:30,048 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,055 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,057 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,066 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,068 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,071 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,073 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,077 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,079 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,081 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,083 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,085 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,087 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,090 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,093 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,095 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,096 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,099 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,101 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,102 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,104 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,106 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,108 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,110 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,112 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,114 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,116 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,117 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,119 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,121 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,122 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,124 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,126 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,128 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,130 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,132 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,134 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,136 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,138 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,140 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,143 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,145 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,146 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,148 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,150 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,152 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 01:05:30,158 - tensorflow - INFO -   name = extra_data_layers/pred_dense/kernel:0, shape = (27, 768), *INIT_NEW*\n",
            "2022-05-19 01:05:30,159 - tensorflow - INFO -   name = extra_data_layers/pred_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2022-05-19 01:05:30,161 - tensorflow - INFO -   name = extra_data_layers/combine_dense/kernel:0, shape = (1536, 768), *INIT_NEW*\n",
            "2022-05-19 01:05:30,163 - tensorflow - INFO -   name = extra_data_layers/combine_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2022-05-19 01:05:30,165 - tensorflow - INFO -   name = output_weights:0, shape = (2, 768), *INIT_NEW*\n",
            "2022-05-19 01:05:30,167 - tensorflow - INFO -   name = output_bias:0, shape = (2,), *INIT_NEW*\n",
            "2022-05-19 01:05:38,949 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:566: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2022-05-19 01:05:39,255 - tensorflow - INFO - Create CheckpointSaverHook.\n",
            "2022-05-19 01:05:39,534 - tensorflow - INFO - Done calling model_fn.\n",
            "2022-05-19 01:05:42,556 - tensorflow - INFO - TPU job name worker\n",
            "2022-05-19 01:05:43,777 - tensorflow - INFO - Graph was finalized.\n",
            "2022-05-19 01:05:50,476 - tensorflow - INFO - Restoring parameters from gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056\n",
            "2022-05-19 01:05:59,985 - tensorflow - INFO - Running local_init_op.\n",
            "2022-05-19 01:06:00,437 - tensorflow - INFO - Done running local_init_op.\n",
            "2022-05-19 01:06:08,537 - tensorflow - INFO - Saving checkpoints for 0 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:06:28,021 - tensorflow - INFO - Initialized dataset iterators in 0 seconds\n",
            "2022-05-19 01:06:28,023 - tensorflow - INFO - Installing graceful shutdown hook.\n",
            "2022-05-19 01:06:28,032 - tensorflow - INFO - Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2022-05-19 01:06:28,037 - tensorflow - INFO - Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2022-05-19 01:06:28,045 - tensorflow - INFO - Init TPU system\n",
            "2022-05-19 01:06:39,301 - tensorflow - INFO - Initialized TPU in 11 seconds\n",
            "2022-05-19 01:06:42,282 - tensorflow - INFO - Starting infeed thread controller.\n",
            "2022-05-19 01:06:42,282 - tensorflow - INFO - Starting outfeed thread controller.\n",
            "2022-05-19 01:06:42,771 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:06:42,772 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:07:01,032 - tensorflow - INFO - Outfeed finished for iteration (0, 0)\n",
            "2022-05-19 01:08:01,718 - tensorflow - INFO - Outfeed finished for iteration (0, 152)\n",
            "2022-05-19 01:09:02,391 - tensorflow - INFO - Outfeed finished for iteration (0, 304)\n",
            "2022-05-19 01:10:05,656 - tensorflow - INFO - Outfeed finished for iteration (0, 370)\n",
            "2022-05-19 01:11:05,892 - tensorflow - INFO - Outfeed finished for iteration (0, 522)\n",
            "2022-05-19 01:12:06,171 - tensorflow - INFO - Outfeed finished for iteration (0, 659)\n",
            "2022-05-19 01:13:06,444 - tensorflow - INFO - Outfeed finished for iteration (0, 799)\n",
            "2022-05-19 01:13:37,277 - tensorflow - INFO - Saving checkpoints for 1000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:13:58,069 - tensorflow - INFO - loss = 0.000392866, step = 1000\n",
            "2022-05-19 01:13:58,075 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:13:58,080 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:14:06,620 - tensorflow - INFO - Outfeed finished for iteration (0, 934)\n",
            "2022-05-19 01:15:07,337 - tensorflow - INFO - Outfeed finished for iteration (1, 83)\n",
            "2022-05-19 01:16:07,662 - tensorflow - INFO - Outfeed finished for iteration (1, 226)\n",
            "2022-05-19 01:17:07,946 - tensorflow - INFO - Outfeed finished for iteration (1, 371)\n",
            "2022-05-19 01:18:08,084 - tensorflow - INFO - Outfeed finished for iteration (1, 514)\n",
            "2022-05-19 01:19:08,568 - tensorflow - INFO - Outfeed finished for iteration (1, 662)\n",
            "2022-05-19 01:20:08,777 - tensorflow - INFO - Outfeed finished for iteration (1, 803)\n",
            "2022-05-19 01:20:43,821 - tensorflow - INFO - Saving checkpoints for 2000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:21:03,628 - tensorflow - INFO - loss = 0.0001455489, step = 2000 (425.559 sec)\n",
            "2022-05-19 01:21:03,635 - tensorflow - INFO - global_step/sec: 2.34984\n",
            "2022-05-19 01:21:03,640 - tensorflow - INFO - examples/sec: 150.39\n",
            "2022-05-19 01:21:03,644 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:21:03,646 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:21:09,469 - tensorflow - INFO - Outfeed finished for iteration (1, 928)\n",
            "2022-05-19 01:22:09,890 - tensorflow - INFO - Outfeed finished for iteration (2, 77)\n",
            "2022-05-19 01:23:10,010 - tensorflow - INFO - Outfeed finished for iteration (2, 225)\n",
            "2022-05-19 01:24:10,641 - tensorflow - INFO - Outfeed finished for iteration (2, 363)\n",
            "2022-05-19 01:25:11,106 - tensorflow - INFO - Outfeed finished for iteration (2, 507)\n",
            "2022-05-19 01:26:11,394 - tensorflow - INFO - Outfeed finished for iteration (2, 652)\n",
            "2022-05-19 01:27:11,993 - tensorflow - INFO - Outfeed finished for iteration (2, 790)\n",
            "2022-05-19 01:27:47,624 - tensorflow - INFO - Saving checkpoints for 3000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:28:09,294 - tensorflow - INFO - loss = 9.202831e-05, step = 3000 (425.666 sec)\n",
            "2022-05-19 01:28:09,305 - tensorflow - INFO - global_step/sec: 2.34923\n",
            "2022-05-19 01:28:09,309 - tensorflow - INFO - examples/sec: 150.351\n",
            "2022-05-19 01:28:09,314 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:28:09,317 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:28:13,497 - tensorflow - INFO - Outfeed finished for iteration (2, 918)\n",
            "2022-05-19 01:29:14,106 - tensorflow - INFO - Outfeed finished for iteration (3, 57)\n",
            "2022-05-19 01:30:14,615 - tensorflow - INFO - Outfeed finished for iteration (3, 177)\n",
            "2022-05-19 01:31:14,984 - tensorflow - INFO - Outfeed finished for iteration (3, 316)\n",
            "2022-05-19 01:32:15,250 - tensorflow - INFO - Outfeed finished for iteration (3, 463)\n",
            "2022-05-19 01:33:15,628 - tensorflow - INFO - Outfeed finished for iteration (3, 591)\n",
            "2022-05-19 01:34:15,990 - tensorflow - INFO - Outfeed finished for iteration (3, 683)\n",
            "2022-05-19 01:35:16,593 - tensorflow - INFO - Outfeed finished for iteration (3, 816)\n",
            "2022-05-19 01:35:39,151 - tensorflow - INFO - Saving checkpoints for 4000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:36:00,021 - tensorflow - INFO - loss = 4.112661e-05, step = 4000 (470.726 sec)\n",
            "2022-05-19 01:36:00,025 - tensorflow - INFO - global_step/sec: 2.12441\n",
            "2022-05-19 01:36:00,028 - tensorflow - INFO - examples/sec: 135.962\n",
            "2022-05-19 01:36:00,037 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:36:00,041 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:36:16,714 - tensorflow - INFO - Outfeed finished for iteration (3, 954)\n",
            "2022-05-19 01:37:17,027 - tensorflow - INFO - Outfeed finished for iteration (4, 93)\n",
            "2022-05-19 01:38:17,080 - tensorflow - INFO - Outfeed finished for iteration (4, 207)\n",
            "2022-05-19 01:39:17,172 - tensorflow - INFO - Outfeed finished for iteration (4, 321)\n",
            "2022-05-19 01:40:17,895 - tensorflow - INFO - Outfeed finished for iteration (4, 447)\n",
            "2022-05-19 01:41:18,846 - tensorflow - INFO - Outfeed finished for iteration (4, 568)\n",
            "2022-05-19 01:42:18,964 - tensorflow - INFO - Outfeed finished for iteration (4, 702)\n",
            "2022-05-19 01:43:18,966 - tensorflow - INFO - Outfeed finished for iteration (4, 842)\n",
            "2022-05-19 01:43:31,375 - tensorflow - INFO - Saving checkpoints for 5000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:43:51,794 - tensorflow - INFO - loss = 3.2066786e-05, step = 5000 (471.774 sec)\n",
            "2022-05-19 01:43:51,802 - tensorflow - INFO - global_step/sec: 2.11966\n",
            "2022-05-19 01:43:51,804 - tensorflow - INFO - examples/sec: 135.658\n",
            "2022-05-19 01:43:51,811 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:43:51,812 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:44:19,513 - tensorflow - INFO - Outfeed finished for iteration (4, 982)\n",
            "2022-05-19 01:45:19,749 - tensorflow - INFO - Outfeed finished for iteration (5, 124)\n",
            "2022-05-19 01:46:19,806 - tensorflow - INFO - Outfeed finished for iteration (5, 270)\n",
            "2022-05-19 01:47:19,866 - tensorflow - INFO - Outfeed finished for iteration (5, 413)\n",
            "2022-05-19 01:48:20,320 - tensorflow - INFO - Outfeed finished for iteration (5, 554)\n",
            "2022-05-19 01:49:20,948 - tensorflow - INFO - Outfeed finished for iteration (5, 686)\n",
            "2022-05-19 01:50:22,152 - tensorflow - INFO - Outfeed finished for iteration (5, 831)\n",
            "2022-05-19 01:50:39,107 - tensorflow - INFO - Saving checkpoints for 6000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:50:57,935 - tensorflow - INFO - loss = 2.3126315e-05, step = 6000 (426.141 sec)\n",
            "2022-05-19 01:50:57,940 - tensorflow - INFO - global_step/sec: 2.34664\n",
            "2022-05-19 01:50:57,944 - tensorflow - INFO - examples/sec: 150.185\n",
            "2022-05-19 01:50:57,949 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:50:57,951 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:51:22,811 - tensorflow - INFO - Outfeed finished for iteration (5, 967)\n",
            "2022-05-19 01:52:25,598 - tensorflow - INFO - Outfeed finished for iteration (6, 95)\n",
            "2022-05-19 01:53:26,193 - tensorflow - INFO - Outfeed finished for iteration (6, 216)\n",
            "2022-05-19 01:54:26,816 - tensorflow - INFO - Outfeed finished for iteration (6, 363)\n",
            "2022-05-19 01:55:27,349 - tensorflow - INFO - Outfeed finished for iteration (6, 521)\n",
            "2022-05-19 01:56:27,787 - tensorflow - INFO - Outfeed finished for iteration (6, 667)\n",
            "2022-05-19 01:57:27,976 - tensorflow - INFO - Outfeed finished for iteration (6, 808)\n",
            "2022-05-19 01:57:53,553 - tensorflow - INFO - Saving checkpoints for 7000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 01:58:12,166 - tensorflow - INFO - loss = 1.3351806e-05, step = 7000 (434.231 sec)\n",
            "2022-05-19 01:58:12,169 - tensorflow - INFO - global_step/sec: 2.30293\n",
            "2022-05-19 01:58:12,175 - tensorflow - INFO - examples/sec: 147.388\n",
            "2022-05-19 01:58:12,181 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 01:58:12,185 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 01:58:28,469 - tensorflow - INFO - Outfeed finished for iteration (6, 951)\n",
            "2022-05-19 01:59:28,823 - tensorflow - INFO - Outfeed finished for iteration (7, 109)\n",
            "2022-05-19 02:00:29,180 - tensorflow - INFO - Outfeed finished for iteration (7, 258)\n",
            "2022-05-19 02:01:30,009 - tensorflow - INFO - Outfeed finished for iteration (7, 408)\n",
            "2022-05-19 02:02:30,235 - tensorflow - INFO - Outfeed finished for iteration (7, 556)\n",
            "2022-05-19 02:03:30,431 - tensorflow - INFO - Outfeed finished for iteration (7, 699)\n",
            "2022-05-19 02:04:31,381 - tensorflow - INFO - Outfeed finished for iteration (7, 846)\n",
            "2022-05-19 02:04:40,443 - tensorflow - INFO - Saving checkpoints for 8000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 02:05:20,715 - tensorflow - INFO - loss = 1.04899445e-05, step = 8000 (428.548 sec)\n",
            "2022-05-19 02:05:20,719 - tensorflow - INFO - global_step/sec: 2.33345\n",
            "2022-05-19 02:05:20,722 - tensorflow - INFO - examples/sec: 149.341\n",
            "2022-05-19 02:05:20,726 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:05:20,728 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:05:31,852 - tensorflow - INFO - Outfeed finished for iteration (7, 991)\n",
            "2022-05-19 02:06:31,955 - tensorflow - INFO - Outfeed finished for iteration (8, 138)\n",
            "2022-05-19 02:07:32,067 - tensorflow - INFO - Outfeed finished for iteration (8, 281)\n",
            "2022-05-19 02:08:32,284 - tensorflow - INFO - Outfeed finished for iteration (8, 416)\n",
            "2022-05-19 02:09:32,399 - tensorflow - INFO - Outfeed finished for iteration (8, 550)\n",
            "2022-05-19 02:10:32,707 - tensorflow - INFO - Outfeed finished for iteration (8, 688)\n",
            "2022-05-19 02:11:32,823 - tensorflow - INFO - Outfeed finished for iteration (8, 832)\n",
            "2022-05-19 02:11:47,993 - tensorflow - INFO - Saving checkpoints for 9000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 02:12:07,192 - tensorflow - INFO - loss = 4.5301463e-06, step = 9000 (406.478 sec)\n",
            "2022-05-19 02:12:07,198 - tensorflow - INFO - global_step/sec: 2.46015\n",
            "2022-05-19 02:12:07,205 - tensorflow - INFO - examples/sec: 157.45\n",
            "2022-05-19 02:12:07,209 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:12:07,212 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:12:33,109 - tensorflow - INFO - Outfeed finished for iteration (8, 972)\n",
            "2022-05-19 02:13:33,462 - tensorflow - INFO - Outfeed finished for iteration (9, 98)\n",
            "2022-05-19 02:14:33,691 - tensorflow - INFO - Outfeed finished for iteration (9, 236)\n",
            "2022-05-19 02:15:34,282 - tensorflow - INFO - Outfeed finished for iteration (9, 371)\n",
            "2022-05-19 02:16:34,622 - tensorflow - INFO - Outfeed finished for iteration (9, 502)\n",
            "2022-05-19 02:17:34,717 - tensorflow - INFO - Outfeed finished for iteration (9, 632)\n",
            "2022-05-19 02:18:35,310 - tensorflow - INFO - Outfeed finished for iteration (9, 775)\n",
            "2022-05-19 02:19:25,181 - tensorflow - INFO - Saving checkpoints for 10000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 02:19:36,226 - tensorflow - INFO - Outfeed finished for iteration (9, 892)\n",
            "2022-05-19 02:19:46,549 - tensorflow - INFO - loss = 3.814873e-06, step = 10000 (459.357 sec)\n",
            "2022-05-19 02:19:46,555 - tensorflow - INFO - global_step/sec: 2.17696\n",
            "2022-05-19 02:19:46,556 - tensorflow - INFO - examples/sec: 139.325\n",
            "2022-05-19 02:19:46,562 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:19:46,565 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:20:36,954 - tensorflow - INFO - Outfeed finished for iteration (10, 22)\n",
            "2022-05-19 02:21:37,398 - tensorflow - INFO - Outfeed finished for iteration (10, 154)\n",
            "2022-05-19 02:22:38,071 - tensorflow - INFO - Outfeed finished for iteration (10, 283)\n",
            "2022-05-19 02:23:38,668 - tensorflow - INFO - Outfeed finished for iteration (10, 411)\n",
            "2022-05-19 02:24:38,855 - tensorflow - INFO - Outfeed finished for iteration (10, 541)\n",
            "2022-05-19 02:25:39,602 - tensorflow - INFO - Outfeed finished for iteration (10, 686)\n",
            "2022-05-19 02:26:39,727 - tensorflow - INFO - Outfeed finished for iteration (10, 816)\n",
            "2022-05-19 02:27:03,440 - tensorflow - INFO - Saving checkpoints for 11000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 02:27:23,945 - tensorflow - INFO - loss = 2.2649906e-06, step = 11000 (457.396 sec)\n",
            "2022-05-19 02:27:23,950 - tensorflow - INFO - global_step/sec: 2.18629\n",
            "2022-05-19 02:27:23,952 - tensorflow - INFO - examples/sec: 139.923\n",
            "2022-05-19 02:27:23,956 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:27:23,958 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:27:40,349 - tensorflow - INFO - Outfeed finished for iteration (10, 955)\n",
            "2022-05-19 02:28:40,895 - tensorflow - INFO - Outfeed finished for iteration (11, 89)\n",
            "2022-05-19 02:29:40,923 - tensorflow - INFO - Outfeed finished for iteration (11, 229)\n",
            "2022-05-19 02:30:41,159 - tensorflow - INFO - Outfeed finished for iteration (11, 372)\n",
            "2022-05-19 02:31:42,290 - tensorflow - INFO - Outfeed finished for iteration (11, 476)\n",
            "2022-05-19 02:32:42,504 - tensorflow - INFO - Outfeed finished for iteration (11, 595)\n",
            "2022-05-19 02:33:43,247 - tensorflow - INFO - Outfeed finished for iteration (11, 724)\n",
            "2022-05-19 02:34:43,567 - tensorflow - INFO - Outfeed finished for iteration (11, 857)\n",
            "2022-05-19 02:34:49,468 - tensorflow - INFO - Saving checkpoints for 12000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 02:35:09,634 - tensorflow - INFO - loss = 9.537907e-07, step = 12000 (465.689 sec)\n",
            "2022-05-19 02:35:09,638 - tensorflow - INFO - global_step/sec: 2.14736\n",
            "2022-05-19 02:35:09,644 - tensorflow - INFO - examples/sec: 137.431\n",
            "2022-05-19 02:35:09,647 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:35:09,649 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:35:43,797 - tensorflow - INFO - Outfeed finished for iteration (11, 988)\n",
            "2022-05-19 02:36:44,525 - tensorflow - INFO - Outfeed finished for iteration (12, 125)\n",
            "2022-05-19 02:37:45,030 - tensorflow - INFO - Outfeed finished for iteration (12, 259)\n",
            "2022-05-19 02:38:46,026 - tensorflow - INFO - Outfeed finished for iteration (12, 395)\n",
            "2022-05-19 02:39:46,523 - tensorflow - INFO - Outfeed finished for iteration (12, 528)\n",
            "2022-05-19 02:40:47,320 - tensorflow - INFO - Outfeed finished for iteration (12, 666)\n",
            "2022-05-19 02:41:47,476 - tensorflow - INFO - Outfeed finished for iteration (12, 805)\n",
            "2022-05-19 02:42:17,897 - tensorflow - INFO - Saving checkpoints for 13000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 02:42:39,039 - tensorflow - INFO - loss = 7.1534305e-07, step = 13000 (449.404 sec)\n",
            "2022-05-19 02:42:39,042 - tensorflow - INFO - global_step/sec: 2.22517\n",
            "2022-05-19 02:42:39,045 - tensorflow - INFO - examples/sec: 142.411\n",
            "2022-05-19 02:42:39,050 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:42:39,051 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:42:47,552 - tensorflow - INFO - Outfeed finished for iteration (12, 932)\n",
            "2022-05-19 02:43:47,764 - tensorflow - INFO - Outfeed finished for iteration (13, 66)\n",
            "2022-05-19 02:44:47,993 - tensorflow - INFO - Outfeed finished for iteration (13, 199)\n",
            "2022-05-19 02:45:48,223 - tensorflow - INFO - Outfeed finished for iteration (13, 330)\n",
            "2022-05-19 02:46:48,512 - tensorflow - INFO - Outfeed finished for iteration (13, 463)\n",
            "2022-05-19 02:47:49,153 - tensorflow - INFO - Outfeed finished for iteration (13, 592)\n",
            "2022-05-19 02:48:49,160 - tensorflow - INFO - Outfeed finished for iteration (13, 720)\n",
            "2022-05-19 02:49:49,821 - tensorflow - INFO - Outfeed finished for iteration (13, 852)\n",
            "2022-05-19 02:49:57,419 - tensorflow - INFO - Saving checkpoints for 14000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_6_bs_64/model.ckpt.\n",
            "2022-05-19 02:50:18,515 - tensorflow - INFO - loss = 1.0730146e-06, step = 14000 (459.477 sec)\n",
            "2022-05-19 02:50:18,521 - tensorflow - INFO - global_step/sec: 2.17638\n",
            "2022-05-19 02:50:18,523 - tensorflow - INFO - examples/sec: 139.288\n",
            "2022-05-19 02:50:19,449 - tensorflow - INFO - Stop infeed thread controller\n",
            "2022-05-19 02:50:19,454 - tensorflow - INFO - Shutting down InfeedController thread.\n",
            "2022-05-19 02:50:19,456 - tensorflow - INFO - InfeedController received shutdown signal, stopping.\n",
            "2022-05-19 02:50:19,458 - tensorflow - INFO - Infeed thread finished, shutting down.\n",
            "2022-05-19 02:50:19,461 - tensorflow - INFO - infeed marked as finished\n",
            "2022-05-19 02:50:19,464 - tensorflow - INFO - Stop output thread controller\n",
            "2022-05-19 02:50:19,465 - tensorflow - INFO - Shutting down OutfeedController thread.\n",
            "2022-05-19 02:50:49,958 - tensorflow - INFO - Outfeed finished for iteration (13, 984)\n",
            "2022-05-19 02:50:56,283 - tensorflow - INFO - OutfeedController received shutdown signal, stopping.\n",
            "2022-05-19 02:50:56,285 - tensorflow - INFO - Outfeed thread finished, shutting down.\n",
            "2022-05-19 02:50:56,286 - tensorflow - INFO - outfeed marked as finished\n",
            "2022-05-19 02:50:56,287 - tensorflow - INFO - Shutdown TPU system.\n",
            "2022-05-19 02:50:58,186 - tensorflow - INFO - Loss for final step: 1.0730146e-06.\n",
            "2022-05-19 02:50:58,187 - tensorflow - INFO - training_loop marked as finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Freezing layers: 5 \n",
            "BATCH SIZE: 16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 02:50:58,860 - tensorflow - INFO - Using data from: gs://theodore_jiang/compiled_finetune_data/MRPC_ex_data_all_finetune_update_loaded/512\n",
            "2022-05-19 02:50:58,862 - tensorflow - INFO - Loading model from: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "init checkpoint: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056 restore/save checkpont: None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 02:51:01,922 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f181e4ff4d0>) includes params argument, but params are not passed to Estimator.\n",
            "2022-05-19 02:51:01,924 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.112.135.146:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1813b037d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.112.135.146:8470', '_evaluation_master': 'grpc://10.112.135.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f1816a736d0>}\n",
            "2022-05-19 02:51:01,926 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2022-05-19 02:51:01,932 - tensorflow - INFO - ***** Running training *****\n",
            "2022-05-19 02:51:01,934 - tensorflow - INFO -   Batch size = 16\n",
            "2022-05-19 02:51:02,374 - tensorflow - INFO - Querying Tensorflow master (grpc://10.112.135.146:8470) for TPU system metadata.\n",
            "2022-05-19 02:51:02,390 - tensorflow - INFO - Found TPU system:\n",
            "2022-05-19 02:51:02,392 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2022-05-19 02:51:02,395 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2022-05-19 02:51:02,397 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2022-05-19 02:51:02,402 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7744513791632944376)\n",
            "2022-05-19 02:51:02,403 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7897525396200153615)\n",
            "2022-05-19 02:51:02,404 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18203121091228161108)\n",
            "2022-05-19 02:51:02,406 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7643529171897127319)\n",
            "2022-05-19 02:51:02,407 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5098989032771748931)\n",
            "2022-05-19 02:51:02,409 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17355166448020794620)\n",
            "2022-05-19 02:51:02,410 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10263619074854522981)\n",
            "2022-05-19 02:51:02,411 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6177495284628076268)\n",
            "2022-05-19 02:51:02,412 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13200199635073852883)\n",
            "2022-05-19 02:51:02,414 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11839754200800065391)\n",
            "2022-05-19 02:51:02,415 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15915597681490588600)\n",
            "2022-05-19 02:51:02,451 - tensorflow - INFO - Calling model_fn.\n",
            "2022-05-19 02:51:02,486 - tensorflow - WARNING - Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f1812ace9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2022-05-19 02:51:02,574 - tensorflow - INFO - *** Features ***\n",
            "2022-05-19 02:51:02,580 - tensorflow - INFO -   name = ex_data, shape = (2, 27)\n",
            "2022-05-19 02:51:02,581 - tensorflow - INFO -   name = input_ids, shape = (2, 512)\n",
            "2022-05-19 02:51:02,587 - tensorflow - INFO -   name = input_mask, shape = (2, 512)\n",
            "2022-05-19 02:51:02,591 - tensorflow - INFO -   name = is_real_example, shape = (2,)\n",
            "2022-05-19 02:51:02,595 - tensorflow - INFO -   name = label_ids, shape = (2,)\n",
            "2022-05-19 02:51:02,599 - tensorflow - INFO -   name = segment_ids, shape = (2, 512)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f1812ace9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 02:51:06,202 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2022-05-19 02:51:06,208 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,210 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,213 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,215 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,216 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,218 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,220 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,222 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,223 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,225 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,226 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,228 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,230 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,233 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,234 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,236 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,238 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,239 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,241 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,242 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,244 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,246 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,247 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,248 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,250 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,251 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,253 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,255 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,256 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,257 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,259 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,260 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,262 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,263 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,264 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,266 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,268 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,269 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,271 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,272 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,274 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,276 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,277 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,279 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,281 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,282 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,284 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,286 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,287 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,289 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,290 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,292 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,294 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,295 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,296 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,298 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,300 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,301 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,307 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,309 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,310 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,311 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 02:51:06,314 - tensorflow - INFO -   name = extra_data_layers/pred_dense/kernel:0, shape = (27, 768), *INIT_NEW*\n",
            "2022-05-19 02:51:06,315 - tensorflow - INFO -   name = extra_data_layers/pred_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2022-05-19 02:51:06,316 - tensorflow - INFO -   name = extra_data_layers/combine_dense/kernel:0, shape = (1536, 768), *INIT_NEW*\n",
            "2022-05-19 02:51:06,318 - tensorflow - INFO -   name = extra_data_layers/combine_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2022-05-19 02:51:06,320 - tensorflow - INFO -   name = output_weights:0, shape = (2, 768), *INIT_NEW*\n",
            "2022-05-19 02:51:06,321 - tensorflow - INFO -   name = output_bias:0, shape = (2,), *INIT_NEW*\n",
            "2022-05-19 02:51:14,800 - tensorflow - INFO - Create CheckpointSaverHook.\n",
            "2022-05-19 02:51:15,068 - tensorflow - INFO - Done calling model_fn.\n",
            "2022-05-19 02:51:18,204 - tensorflow - INFO - TPU job name worker\n",
            "2022-05-19 02:51:19,339 - tensorflow - INFO - Graph was finalized.\n",
            "2022-05-19 02:51:26,336 - tensorflow - INFO - Restoring parameters from gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056\n",
            "2022-05-19 02:51:28,267 - tensorflow - INFO - Running local_init_op.\n",
            "2022-05-19 02:51:28,809 - tensorflow - INFO - Done running local_init_op.\n",
            "2022-05-19 02:51:36,863 - tensorflow - INFO - Saving checkpoints for 0 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 02:51:55,706 - tensorflow - INFO - Initialized dataset iterators in 0 seconds\n",
            "2022-05-19 02:51:55,709 - tensorflow - INFO - Installing graceful shutdown hook.\n",
            "2022-05-19 02:51:55,716 - tensorflow - INFO - Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2022-05-19 02:51:55,722 - tensorflow - INFO - Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2022-05-19 02:51:55,728 - tensorflow - INFO - Init TPU system\n",
            "2022-05-19 02:52:15,760 - tensorflow - INFO - Initialized TPU in 20 seconds\n",
            "2022-05-19 02:52:18,491 - tensorflow - INFO - Starting infeed thread controller.\n",
            "2022-05-19 02:52:18,491 - tensorflow - INFO - Starting outfeed thread controller.\n",
            "2022-05-19 02:52:18,973 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:52:18,975 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:52:40,285 - tensorflow - INFO - Outfeed finished for iteration (0, 0)\n",
            "2022-05-19 02:53:40,368 - tensorflow - INFO - Outfeed finished for iteration (0, 161)\n",
            "2022-05-19 02:54:40,670 - tensorflow - INFO - Outfeed finished for iteration (0, 309)\n",
            "2022-05-19 02:55:41,050 - tensorflow - INFO - Outfeed finished for iteration (0, 467)\n",
            "2022-05-19 02:56:41,367 - tensorflow - INFO - Outfeed finished for iteration (0, 625)\n",
            "2022-05-19 02:57:41,561 - tensorflow - INFO - Outfeed finished for iteration (0, 777)\n",
            "2022-05-19 02:58:16,580 - tensorflow - INFO - Saving checkpoints for 1000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 02:58:35,460 - tensorflow - INFO - loss = 0.00037948703, step = 1000\n",
            "2022-05-19 02:58:35,466 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 02:58:35,469 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 02:58:41,679 - tensorflow - INFO - Outfeed finished for iteration (0, 927)\n",
            "2022-05-19 02:59:41,887 - tensorflow - INFO - Outfeed finished for iteration (1, 83)\n",
            "2022-05-19 03:00:42,569 - tensorflow - INFO - Outfeed finished for iteration (1, 235)\n",
            "2022-05-19 03:01:43,272 - tensorflow - INFO - Outfeed finished for iteration (1, 382)\n",
            "2022-05-19 03:02:44,015 - tensorflow - INFO - Outfeed finished for iteration (1, 525)\n",
            "2022-05-19 03:03:44,708 - tensorflow - INFO - Outfeed finished for iteration (1, 673)\n",
            "2022-05-19 03:04:44,758 - tensorflow - INFO - Outfeed finished for iteration (1, 822)\n",
            "2022-05-19 03:05:05,736 - tensorflow - INFO - Saving checkpoints for 2000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 03:05:27,185 - tensorflow - INFO - loss = 9.023779e-05, step = 2000 (411.726 sec)\n",
            "2022-05-19 03:05:27,192 - tensorflow - INFO - global_step/sec: 2.42878\n",
            "2022-05-19 03:05:27,196 - tensorflow - INFO - examples/sec: 38.8605\n",
            "2022-05-19 03:05:27,199 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 03:05:27,202 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 03:05:45,272 - tensorflow - INFO - Outfeed finished for iteration (1, 957)\n",
            "2022-05-19 03:06:45,542 - tensorflow - INFO - Outfeed finished for iteration (2, 102)\n",
            "2022-05-19 03:07:45,963 - tensorflow - INFO - Outfeed finished for iteration (2, 242)\n",
            "2022-05-19 03:08:46,722 - tensorflow - INFO - Outfeed finished for iteration (2, 375)\n",
            "2022-05-19 03:09:47,562 - tensorflow - INFO - Outfeed finished for iteration (2, 513)\n",
            "2022-05-19 03:10:48,746 - tensorflow - INFO - Outfeed finished for iteration (2, 643)\n",
            "2022-05-19 03:11:48,780 - tensorflow - INFO - Outfeed finished for iteration (2, 773)\n",
            "2022-05-19 03:12:30,975 - tensorflow - INFO - Saving checkpoints for 3000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 03:12:49,646 - tensorflow - INFO - Outfeed finished for iteration (2, 905)\n",
            "2022-05-19 03:12:52,290 - tensorflow - INFO - loss = 6.2344465e-05, step = 3000 (445.104 sec)\n",
            "2022-05-19 03:12:52,296 - tensorflow - INFO - global_step/sec: 2.24667\n",
            "2022-05-19 03:12:52,298 - tensorflow - INFO - examples/sec: 35.9467\n",
            "2022-05-19 03:12:52,303 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 03:12:52,307 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 03:13:49,959 - tensorflow - INFO - Outfeed finished for iteration (3, 37)\n",
            "2022-05-19 03:14:50,217 - tensorflow - INFO - Outfeed finished for iteration (3, 173)\n",
            "2022-05-19 03:16:03,793 - tensorflow - INFO - Outfeed finished for iteration (3, 309)\n",
            "2022-05-19 03:17:04,297 - tensorflow - INFO - Outfeed finished for iteration (3, 448)\n",
            "2022-05-19 03:18:05,071 - tensorflow - INFO - Outfeed finished for iteration (3, 576)\n",
            "2022-05-19 03:19:05,911 - tensorflow - INFO - Outfeed finished for iteration (3, 708)\n",
            "2022-05-19 03:20:06,641 - tensorflow - INFO - Outfeed finished for iteration (3, 827)\n",
            "2022-05-19 03:20:24,151 - tensorflow - INFO - Saving checkpoints for 4000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 03:20:43,774 - tensorflow - INFO - loss = 3.3260876e-05, step = 4000 (471.484 sec)\n",
            "2022-05-19 03:20:43,778 - tensorflow - INFO - global_step/sec: 2.12097\n",
            "2022-05-19 03:20:43,780 - tensorflow - INFO - examples/sec: 33.9355\n",
            "2022-05-19 03:20:43,785 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 03:20:43,789 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 03:21:07,195 - tensorflow - INFO - Outfeed finished for iteration (3, 965)\n",
            "2022-05-19 03:22:07,910 - tensorflow - INFO - Outfeed finished for iteration (4, 102)\n",
            "2022-05-19 03:23:08,569 - tensorflow - INFO - Outfeed finished for iteration (4, 238)\n",
            "2022-05-19 03:24:08,885 - tensorflow - INFO - Outfeed finished for iteration (4, 368)\n",
            "2022-05-19 03:25:08,977 - tensorflow - INFO - Outfeed finished for iteration (4, 504)\n",
            "2022-05-19 03:26:09,504 - tensorflow - INFO - Outfeed finished for iteration (4, 640)\n",
            "2022-05-19 03:27:10,371 - tensorflow - INFO - Outfeed finished for iteration (4, 783)\n",
            "2022-05-19 03:27:50,231 - tensorflow - INFO - Saving checkpoints for 5000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 03:28:10,282 - tensorflow - INFO - loss = 2.9326791e-05, step = 5000 (446.508 sec)\n",
            "2022-05-19 03:28:10,287 - tensorflow - INFO - global_step/sec: 2.2396\n",
            "2022-05-19 03:28:10,289 - tensorflow - INFO - examples/sec: 35.8336\n",
            "2022-05-19 03:28:10,298 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 03:28:10,299 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 03:28:11,079 - tensorflow - INFO - Outfeed finished for iteration (4, 915)\n",
            "2022-05-19 03:29:11,423 - tensorflow - INFO - Outfeed finished for iteration (5, 48)\n",
            "2022-05-19 03:30:11,800 - tensorflow - INFO - Outfeed finished for iteration (5, 166)\n",
            "2022-05-19 03:31:11,981 - tensorflow - INFO - Outfeed finished for iteration (5, 290)\n",
            "2022-05-19 03:32:12,331 - tensorflow - INFO - Outfeed finished for iteration (5, 426)\n",
            "2022-05-19 03:33:12,649 - tensorflow - INFO - Outfeed finished for iteration (5, 549)\n",
            "2022-05-19 03:34:13,451 - tensorflow - INFO - Outfeed finished for iteration (5, 670)\n",
            "2022-05-19 03:35:13,768 - tensorflow - INFO - Outfeed finished for iteration (5, 807)\n",
            "2022-05-19 03:35:39,708 - tensorflow - INFO - Saving checkpoints for 6000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 03:36:00,232 - tensorflow - INFO - loss = 1.2398466e-05, step = 6000 (469.950 sec)\n",
            "2022-05-19 03:36:00,242 - tensorflow - INFO - global_step/sec: 2.12787\n",
            "2022-05-19 03:36:00,244 - tensorflow - INFO - examples/sec: 34.0459\n",
            "2022-05-19 03:36:00,253 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 03:36:00,256 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 03:36:13,862 - tensorflow - INFO - Outfeed finished for iteration (5, 938)\n",
            "2022-05-19 03:37:14,576 - tensorflow - INFO - Outfeed finished for iteration (6, 64)\n",
            "2022-05-19 03:38:14,667 - tensorflow - INFO - Outfeed finished for iteration (6, 152)\n",
            "2022-05-19 03:39:14,846 - tensorflow - INFO - Outfeed finished for iteration (6, 277)\n",
            "2022-05-19 03:40:15,062 - tensorflow - INFO - Outfeed finished for iteration (6, 400)\n",
            "2022-05-19 03:41:15,449 - tensorflow - INFO - Outfeed finished for iteration (6, 513)\n",
            "2022-05-19 03:42:15,488 - tensorflow - INFO - Outfeed finished for iteration (6, 642)\n",
            "2022-05-19 03:43:15,992 - tensorflow - INFO - Outfeed finished for iteration (6, 761)\n",
            "2022-05-19 03:44:04,975 - tensorflow - INFO - Saving checkpoints for 7000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 03:44:16,469 - tensorflow - INFO - Outfeed finished for iteration (6, 895)\n",
            "2022-05-19 03:44:25,554 - tensorflow - INFO - loss = 8.34472e-06, step = 7000 (505.322 sec)\n",
            "2022-05-19 03:44:25,566 - tensorflow - INFO - global_step/sec: 1.97892\n",
            "2022-05-19 03:44:25,569 - tensorflow - INFO - examples/sec: 31.6627\n",
            "2022-05-19 03:44:25,576 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 03:44:25,578 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 03:45:16,684 - tensorflow - INFO - Outfeed finished for iteration (7, 25)\n",
            "2022-05-19 03:46:17,072 - tensorflow - INFO - Outfeed finished for iteration (7, 159)\n",
            "2022-05-19 03:47:17,306 - tensorflow - INFO - Outfeed finished for iteration (7, 292)\n",
            "2022-05-19 03:48:17,616 - tensorflow - INFO - Outfeed finished for iteration (7, 415)\n",
            "2022-05-19 03:49:18,538 - tensorflow - INFO - Outfeed finished for iteration (7, 553)\n",
            "2022-05-19 03:50:19,093 - tensorflow - INFO - Outfeed finished for iteration (7, 687)\n",
            "2022-05-19 03:51:19,224 - tensorflow - INFO - Outfeed finished for iteration (7, 815)\n",
            "2022-05-19 03:51:45,798 - tensorflow - INFO - Saving checkpoints for 8000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 03:52:07,899 - tensorflow - INFO - loss = 7.2714847e-06, step = 8000 (462.345 sec)\n",
            "2022-05-19 03:52:07,904 - tensorflow - INFO - global_step/sec: 2.16292\n",
            "2022-05-19 03:52:07,914 - tensorflow - INFO - examples/sec: 34.6068\n",
            "2022-05-19 03:52:07,925 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 03:52:07,931 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 03:52:19,545 - tensorflow - INFO - Outfeed finished for iteration (7, 940)\n",
            "2022-05-19 03:53:20,091 - tensorflow - INFO - Outfeed finished for iteration (8, 68)\n",
            "2022-05-19 03:54:20,135 - tensorflow - INFO - Outfeed finished for iteration (8, 202)\n",
            "2022-05-19 03:55:20,373 - tensorflow - INFO - Outfeed finished for iteration (8, 330)\n",
            "2022-05-19 03:56:20,411 - tensorflow - INFO - Outfeed finished for iteration (8, 447)\n",
            "2022-05-19 03:57:21,050 - tensorflow - INFO - Outfeed finished for iteration (8, 572)\n",
            "2022-05-19 03:58:21,835 - tensorflow - INFO - Outfeed finished for iteration (8, 699)\n",
            "2022-05-19 03:59:22,216 - tensorflow - INFO - Outfeed finished for iteration (8, 821)\n",
            "2022-05-19 03:59:49,221 - tensorflow - INFO - Saving checkpoints for 9000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 04:00:08,841 - tensorflow - INFO - loss = 5.48392e-06, step = 9000 (480.941 sec)\n",
            "2022-05-19 04:00:08,851 - tensorflow - INFO - global_step/sec: 2.07923\n",
            "2022-05-19 04:00:08,853 - tensorflow - INFO - examples/sec: 33.2677\n",
            "2022-05-19 04:00:08,864 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:00:08,866 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:00:22,727 - tensorflow - INFO - Outfeed finished for iteration (8, 937)\n",
            "2022-05-19 04:01:22,859 - tensorflow - INFO - Outfeed finished for iteration (9, 58)\n",
            "2022-05-19 04:02:23,405 - tensorflow - INFO - Outfeed finished for iteration (9, 188)\n",
            "2022-05-19 04:03:24,008 - tensorflow - INFO - Outfeed finished for iteration (9, 326)\n",
            "2022-05-19 04:04:24,596 - tensorflow - INFO - Outfeed finished for iteration (9, 445)\n",
            "2022-05-19 04:05:25,165 - tensorflow - INFO - Outfeed finished for iteration (9, 569)\n",
            "2022-05-19 04:06:25,911 - tensorflow - INFO - Outfeed finished for iteration (9, 698)\n",
            "2022-05-19 04:07:26,139 - tensorflow - INFO - Outfeed finished for iteration (9, 826)\n",
            "2022-05-19 04:07:46,354 - tensorflow - INFO - Saving checkpoints for 10000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 04:08:06,680 - tensorflow - INFO - loss = 2.7416477e-06, step = 10000 (477.839 sec)\n",
            "2022-05-19 04:08:06,683 - tensorflow - INFO - global_step/sec: 2.09279\n",
            "2022-05-19 04:08:06,686 - tensorflow - INFO - examples/sec: 33.4846\n",
            "2022-05-19 04:08:06,693 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:08:06,698 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:08:28,124 - tensorflow - INFO - Outfeed finished for iteration (9, 953)\n",
            "2022-05-19 04:09:28,521 - tensorflow - INFO - Outfeed finished for iteration (10, 70)\n",
            "2022-05-19 04:10:28,808 - tensorflow - INFO - Outfeed finished for iteration (10, 200)\n",
            "2022-05-19 04:11:29,155 - tensorflow - INFO - Outfeed finished for iteration (10, 328)\n",
            "2022-05-19 04:12:29,206 - tensorflow - INFO - Outfeed finished for iteration (10, 449)\n",
            "2022-05-19 04:13:29,207 - tensorflow - INFO - Outfeed finished for iteration (10, 588)\n",
            "2022-05-19 04:14:29,544 - tensorflow - INFO - Outfeed finished for iteration (10, 715)\n",
            "2022-05-19 04:15:29,831 - tensorflow - INFO - Outfeed finished for iteration (10, 840)\n",
            "2022-05-19 04:15:45,293 - tensorflow - INFO - Saving checkpoints for 11000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 04:16:03,907 - tensorflow - INFO - loss = 1.4306861e-06, step = 11000 (477.228 sec)\n",
            "2022-05-19 04:16:03,915 - tensorflow - INFO - global_step/sec: 2.09542\n",
            "2022-05-19 04:16:03,918 - tensorflow - INFO - examples/sec: 33.5267\n",
            "2022-05-19 04:16:03,931 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:16:03,932 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:16:30,148 - tensorflow - INFO - Outfeed finished for iteration (10, 950)\n",
            "2022-05-19 04:17:30,552 - tensorflow - INFO - Outfeed finished for iteration (11, 86)\n",
            "2022-05-19 04:18:31,912 - tensorflow - INFO - Outfeed finished for iteration (11, 205)\n",
            "2022-05-19 04:19:32,207 - tensorflow - INFO - Outfeed finished for iteration (11, 333)\n",
            "2022-05-19 04:20:32,616 - tensorflow - INFO - Outfeed finished for iteration (11, 463)\n",
            "2022-05-19 04:21:33,396 - tensorflow - INFO - Outfeed finished for iteration (11, 584)\n",
            "2022-05-19 04:22:33,991 - tensorflow - INFO - Outfeed finished for iteration (11, 724)\n",
            "2022-05-19 04:23:34,584 - tensorflow - INFO - Outfeed finished for iteration (11, 868)\n",
            "2022-05-19 04:23:35,052 - tensorflow - INFO - Saving checkpoints for 12000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 04:23:56,229 - tensorflow - INFO - loss = 2.6226976e-06, step = 12000 (472.322 sec)\n",
            "2022-05-19 04:23:56,234 - tensorflow - INFO - global_step/sec: 2.11721\n",
            "2022-05-19 04:23:56,241 - tensorflow - INFO - examples/sec: 33.8754\n",
            "2022-05-19 04:23:56,245 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:23:56,248 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:24:35,098 - tensorflow - INFO - Outfeed finished for iteration (11, 999)\n",
            "2022-05-19 04:25:35,725 - tensorflow - INFO - Outfeed finished for iteration (12, 131)\n",
            "2022-05-19 04:26:35,744 - tensorflow - INFO - Outfeed finished for iteration (12, 253)\n",
            "2022-05-19 04:27:36,097 - tensorflow - INFO - Outfeed finished for iteration (12, 389)\n",
            "2022-05-19 04:28:36,908 - tensorflow - INFO - Outfeed finished for iteration (12, 516)\n",
            "2022-05-19 04:29:37,530 - tensorflow - INFO - Outfeed finished for iteration (12, 638)\n",
            "2022-05-19 04:30:38,402 - tensorflow - INFO - Outfeed finished for iteration (12, 787)\n",
            "2022-05-19 04:31:21,182 - tensorflow - INFO - Saving checkpoints for 13000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 04:31:38,737 - tensorflow - INFO - Outfeed finished for iteration (12, 908)\n",
            "2022-05-19 04:31:42,017 - tensorflow - INFO - loss = 1.3112378e-06, step = 13000 (465.788 sec)\n",
            "2022-05-19 04:31:42,022 - tensorflow - INFO - global_step/sec: 2.1469\n",
            "2022-05-19 04:31:42,027 - tensorflow - INFO - examples/sec: 34.3504\n",
            "2022-05-19 04:31:42,035 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:31:42,038 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:32:39,428 - tensorflow - INFO - Outfeed finished for iteration (13, 36)\n",
            "2022-05-19 04:33:40,188 - tensorflow - INFO - Outfeed finished for iteration (13, 170)\n",
            "2022-05-19 04:34:40,208 - tensorflow - INFO - Outfeed finished for iteration (13, 286)\n",
            "2022-05-19 04:35:40,550 - tensorflow - INFO - Outfeed finished for iteration (13, 416)\n",
            "2022-05-19 04:36:41,544 - tensorflow - INFO - Outfeed finished for iteration (13, 537)\n",
            "2022-05-19 04:37:41,929 - tensorflow - INFO - Outfeed finished for iteration (13, 669)\n",
            "2022-05-19 04:38:42,630 - tensorflow - INFO - Outfeed finished for iteration (13, 803)\n",
            "2022-05-19 04:39:13,084 - tensorflow - INFO - Saving checkpoints for 14000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_16/model.ckpt.\n",
            "2022-05-19 04:39:32,311 - tensorflow - INFO - loss = 1.6689471e-06, step = 14000 (470.294 sec)\n",
            "2022-05-19 04:39:32,317 - tensorflow - INFO - global_step/sec: 2.12633\n",
            "2022-05-19 04:39:32,323 - tensorflow - INFO - examples/sec: 34.0212\n",
            "2022-05-19 04:39:33,044 - tensorflow - INFO - Stop infeed thread controller\n",
            "2022-05-19 04:39:33,047 - tensorflow - INFO - Shutting down InfeedController thread.\n",
            "2022-05-19 04:39:33,051 - tensorflow - INFO - InfeedController received shutdown signal, stopping.\n",
            "2022-05-19 04:39:33,054 - tensorflow - INFO - Infeed thread finished, shutting down.\n",
            "2022-05-19 04:39:33,062 - tensorflow - INFO - infeed marked as finished\n",
            "2022-05-19 04:39:33,067 - tensorflow - INFO - Stop output thread controller\n",
            "2022-05-19 04:39:33,069 - tensorflow - INFO - Shutting down OutfeedController thread.\n",
            "2022-05-19 04:39:43,177 - tensorflow - INFO - Outfeed finished for iteration (13, 914)\n",
            "2022-05-19 04:40:28,420 - tensorflow - INFO - OutfeedController received shutdown signal, stopping.\n",
            "2022-05-19 04:40:28,422 - tensorflow - INFO - Outfeed thread finished, shutting down.\n",
            "2022-05-19 04:40:28,425 - tensorflow - INFO - outfeed marked as finished\n",
            "2022-05-19 04:40:28,426 - tensorflow - INFO - Shutdown TPU system.\n",
            "2022-05-19 04:40:29,957 - tensorflow - INFO - Loss for final step: 1.6689471e-06.\n",
            "2022-05-19 04:40:29,958 - tensorflow - INFO - training_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Freezing layers: 5 \n",
            "BATCH SIZE: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 04:40:32,031 - tensorflow - INFO - Using data from: gs://theodore_jiang/compiled_finetune_data/MRPC_ex_data_all_finetune_update_loaded/512\n",
            "2022-05-19 04:40:32,034 - tensorflow - INFO - Loading model from: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init checkpoint: gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056 restore/save checkpont: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 04:40:34,898 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1812af4050>) includes params argument, but params are not passed to Estimator.\n",
            "2022-05-19 04:40:34,900 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.112.135.146:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f180f2a0b50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.112.135.146:8470', '_evaluation_master': 'grpc://10.112.135.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f180f2a0a10>}\n",
            "2022-05-19 04:40:34,907 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2022-05-19 04:40:34,911 - tensorflow - INFO - ***** Running training *****\n",
            "2022-05-19 04:40:34,917 - tensorflow - INFO -   Batch size = 64\n",
            "2022-05-19 04:40:35,379 - tensorflow - INFO - Querying Tensorflow master (grpc://10.112.135.146:8470) for TPU system metadata.\n",
            "2022-05-19 04:40:35,396 - tensorflow - INFO - Found TPU system:\n",
            "2022-05-19 04:40:35,398 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2022-05-19 04:40:35,400 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2022-05-19 04:40:35,401 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2022-05-19 04:40:35,406 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7744513791632944376)\n",
            "2022-05-19 04:40:35,407 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7897525396200153615)\n",
            "2022-05-19 04:40:35,409 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18203121091228161108)\n",
            "2022-05-19 04:40:35,410 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7643529171897127319)\n",
            "2022-05-19 04:40:35,412 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5098989032771748931)\n",
            "2022-05-19 04:40:35,413 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17355166448020794620)\n",
            "2022-05-19 04:40:35,415 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10263619074854522981)\n",
            "2022-05-19 04:40:35,416 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6177495284628076268)\n",
            "2022-05-19 04:40:35,417 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13200199635073852883)\n",
            "2022-05-19 04:40:35,418 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11839754200800065391)\n",
            "2022-05-19 04:40:35,420 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15915597681490588600)\n",
            "2022-05-19 04:40:35,460 - tensorflow - INFO - Calling model_fn.\n",
            "2022-05-19 04:40:35,523 - tensorflow - WARNING - Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f180f2a3290> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2022-05-19 04:40:35,668 - tensorflow - INFO - *** Features ***\n",
            "2022-05-19 04:40:35,670 - tensorflow - INFO -   name = ex_data, shape = (8, 27)\n",
            "2022-05-19 04:40:35,672 - tensorflow - INFO -   name = input_ids, shape = (8, 512)\n",
            "2022-05-19 04:40:35,673 - tensorflow - INFO -   name = input_mask, shape = (8, 512)\n",
            "2022-05-19 04:40:35,679 - tensorflow - INFO -   name = is_real_example, shape = (8,)\n",
            "2022-05-19 04:40:35,680 - tensorflow - INFO -   name = label_ids, shape = (8,)\n",
            "2022-05-19 04:40:35,683 - tensorflow - INFO -   name = segment_ids, shape = (8, 512)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f180f2a3290> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 04:40:39,915 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2022-05-19 04:40:39,917 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,921 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,926 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,934 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,939 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,941 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,942 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,944 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,946 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,948 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,950 - tensorflow - INFO -   name = bert/embeddings/conv1d_2/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,952 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,954 - tensorflow - INFO -   name = bert/embeddings/conv1d_3/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,956 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,957 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,959 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,960 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,963 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,965 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,971 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,976 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,977 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,981 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,982 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,985 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,988 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,989 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,994 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,995 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,997 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:39,998 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,002 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,005 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,007 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,010 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,012 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,013 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,017 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,019 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,020 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,025 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,027 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,028 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,030 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,034 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,036 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,037 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,039 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,042 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,043 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,045 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,046 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,047 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,049 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,050 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,052 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,053 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,054 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,056 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,057 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,058 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,059 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2022-05-19 04:40:40,061 - tensorflow - INFO -   name = extra_data_layers/pred_dense/kernel:0, shape = (27, 768), *INIT_NEW*\n",
            "2022-05-19 04:40:40,062 - tensorflow - INFO -   name = extra_data_layers/pred_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2022-05-19 04:40:40,063 - tensorflow - INFO -   name = extra_data_layers/combine_dense/kernel:0, shape = (1536, 768), *INIT_NEW*\n",
            "2022-05-19 04:40:40,064 - tensorflow - INFO -   name = extra_data_layers/combine_dense/bias:0, shape = (768,), *INIT_NEW*\n",
            "2022-05-19 04:40:40,065 - tensorflow - INFO -   name = output_weights:0, shape = (2, 768), *INIT_NEW*\n",
            "2022-05-19 04:40:40,067 - tensorflow - INFO -   name = output_bias:0, shape = (2,), *INIT_NEW*\n",
            "2022-05-19 04:40:48,012 - tensorflow - INFO - Create CheckpointSaverHook.\n",
            "2022-05-19 04:40:48,273 - tensorflow - INFO - Done calling model_fn.\n",
            "2022-05-19 04:40:50,844 - tensorflow - INFO - TPU job name worker\n",
            "2022-05-19 04:40:51,978 - tensorflow - INFO - Graph was finalized.\n",
            "2022-05-19 04:40:58,659 - tensorflow - INFO - Restoring parameters from gs://theodore_jiang/pretrained_models/MutFormer_em_adap8L/model.ckpt-1501056\n",
            "2022-05-19 04:41:00,819 - tensorflow - INFO - Running local_init_op.\n",
            "2022-05-19 04:41:01,354 - tensorflow - INFO - Done running local_init_op.\n",
            "2022-05-19 04:41:09,358 - tensorflow - INFO - Saving checkpoints for 0 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 04:41:27,272 - tensorflow - INFO - Initialized dataset iterators in 0 seconds\n",
            "2022-05-19 04:41:27,275 - tensorflow - INFO - Installing graceful shutdown hook.\n",
            "2022-05-19 04:41:27,283 - tensorflow - INFO - Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2022-05-19 04:41:27,291 - tensorflow - INFO - Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2022-05-19 04:41:27,304 - tensorflow - INFO - Init TPU system\n",
            "2022-05-19 04:41:38,557 - tensorflow - INFO - Initialized TPU in 11 seconds\n",
            "2022-05-19 04:41:41,421 - tensorflow - INFO - Starting infeed thread controller.\n",
            "2022-05-19 04:41:41,421 - tensorflow - INFO - Starting outfeed thread controller.\n",
            "2022-05-19 04:41:41,965 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:41:41,967 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:42:01,592 - tensorflow - INFO - Outfeed finished for iteration (0, 0)\n",
            "2022-05-19 04:43:02,183 - tensorflow - INFO - Outfeed finished for iteration (0, 157)\n",
            "2022-05-19 04:44:02,405 - tensorflow - INFO - Outfeed finished for iteration (0, 317)\n",
            "2022-05-19 04:45:02,901 - tensorflow - INFO - Outfeed finished for iteration (0, 469)\n",
            "2022-05-19 04:46:03,911 - tensorflow - INFO - Outfeed finished for iteration (0, 599)\n",
            "2022-05-19 04:47:04,246 - tensorflow - INFO - Outfeed finished for iteration (0, 722)\n",
            "2022-05-19 04:48:01,775 - tensorflow - INFO - Saving checkpoints for 1000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 04:48:04,489 - tensorflow - INFO - Outfeed finished for iteration (0, 878)\n",
            "2022-05-19 04:48:22,706 - tensorflow - INFO - loss = 0.00032841114, step = 1000\n",
            "2022-05-19 04:48:22,712 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:48:22,717 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:49:05,258 - tensorflow - INFO - Outfeed finished for iteration (1, 17)\n",
            "2022-05-19 04:50:05,300 - tensorflow - INFO - Outfeed finished for iteration (1, 134)\n",
            "2022-05-19 04:51:05,326 - tensorflow - INFO - Outfeed finished for iteration (1, 252)\n",
            "2022-05-19 04:52:05,558 - tensorflow - INFO - Outfeed finished for iteration (1, 396)\n",
            "2022-05-19 04:53:05,960 - tensorflow - INFO - Outfeed finished for iteration (1, 534)\n",
            "2022-05-19 04:54:06,816 - tensorflow - INFO - Outfeed finished for iteration (1, 664)\n",
            "2022-05-19 04:55:07,103 - tensorflow - INFO - Outfeed finished for iteration (1, 818)\n",
            "2022-05-19 04:55:27,071 - tensorflow - INFO - Saving checkpoints for 2000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 04:55:47,259 - tensorflow - INFO - loss = 0.0001714212, step = 2000 (444.553 sec)\n",
            "2022-05-19 04:55:47,264 - tensorflow - INFO - global_step/sec: 2.24945\n",
            "2022-05-19 04:55:47,270 - tensorflow - INFO - examples/sec: 143.965\n",
            "2022-05-19 04:55:47,273 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 04:55:47,276 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 04:56:07,598 - tensorflow - INFO - Outfeed finished for iteration (1, 972)\n",
            "2022-05-19 04:57:08,217 - tensorflow - INFO - Outfeed finished for iteration (2, 115)\n",
            "2022-05-19 04:58:08,326 - tensorflow - INFO - Outfeed finished for iteration (2, 265)\n",
            "2022-05-19 04:59:08,620 - tensorflow - INFO - Outfeed finished for iteration (2, 403)\n",
            "2022-05-19 05:00:08,935 - tensorflow - INFO - Outfeed finished for iteration (2, 570)\n",
            "2022-05-19 05:01:09,349 - tensorflow - INFO - Outfeed finished for iteration (2, 704)\n",
            "2022-05-19 05:02:09,803 - tensorflow - INFO - Outfeed finished for iteration (2, 836)\n",
            "2022-05-19 05:02:24,639 - tensorflow - INFO - Saving checkpoints for 3000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:02:44,205 - tensorflow - INFO - loss = 0.000105615414, step = 3000 (416.946 sec)\n",
            "2022-05-19 05:02:44,211 - tensorflow - INFO - global_step/sec: 2.39838\n",
            "2022-05-19 05:02:44,215 - tensorflow - INFO - examples/sec: 153.497\n",
            "2022-05-19 05:02:44,225 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:02:44,227 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:03:12,794 - tensorflow - INFO - Outfeed finished for iteration (2, 971)\n",
            "2022-05-19 05:04:13,099 - tensorflow - INFO - Outfeed finished for iteration (3, 120)\n",
            "2022-05-19 05:05:13,449 - tensorflow - INFO - Outfeed finished for iteration (3, 266)\n",
            "2022-05-19 05:06:14,165 - tensorflow - INFO - Outfeed finished for iteration (3, 404)\n",
            "2022-05-19 05:07:14,381 - tensorflow - INFO - Outfeed finished for iteration (3, 530)\n",
            "2022-05-19 05:08:14,643 - tensorflow - INFO - Outfeed finished for iteration (3, 655)\n",
            "2022-05-19 05:09:15,385 - tensorflow - INFO - Outfeed finished for iteration (3, 776)\n",
            "2022-05-19 05:09:59,298 - tensorflow - INFO - Saving checkpoints for 4000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:10:15,504 - tensorflow - INFO - Outfeed finished for iteration (3, 897)\n",
            "2022-05-19 05:10:18,109 - tensorflow - INFO - loss = 6.282239e-05, step = 4000 (453.903 sec)\n",
            "2022-05-19 05:10:18,114 - tensorflow - INFO - global_step/sec: 2.20312\n",
            "2022-05-19 05:10:18,116 - tensorflow - INFO - examples/sec: 140.999\n",
            "2022-05-19 05:10:18,125 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:10:18,127 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:11:15,720 - tensorflow - INFO - Outfeed finished for iteration (4, 27)\n",
            "2022-05-19 05:12:16,259 - tensorflow - INFO - Outfeed finished for iteration (4, 178)\n",
            "2022-05-19 05:13:16,669 - tensorflow - INFO - Outfeed finished for iteration (4, 306)\n",
            "2022-05-19 05:14:17,270 - tensorflow - INFO - Outfeed finished for iteration (4, 447)\n",
            "2022-05-19 05:15:17,528 - tensorflow - INFO - Outfeed finished for iteration (4, 586)\n",
            "2022-05-19 05:16:17,538 - tensorflow - INFO - Outfeed finished for iteration (4, 720)\n",
            "2022-05-19 05:17:17,552 - tensorflow - INFO - Outfeed finished for iteration (4, 845)\n",
            "2022-05-19 05:17:30,191 - tensorflow - INFO - Saving checkpoints for 5000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:17:51,230 - tensorflow - INFO - loss = 3.4332435e-05, step = 5000 (453.121 sec)\n",
            "2022-05-19 05:17:51,236 - tensorflow - INFO - global_step/sec: 2.20691\n",
            "2022-05-19 05:17:51,238 - tensorflow - INFO - examples/sec: 141.242\n",
            "2022-05-19 05:17:51,243 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:17:51,244 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:18:17,552 - tensorflow - INFO - Outfeed finished for iteration (4, 968)\n",
            "2022-05-19 05:19:17,986 - tensorflow - INFO - Outfeed finished for iteration (5, 96)\n",
            "2022-05-19 05:20:18,359 - tensorflow - INFO - Outfeed finished for iteration (5, 215)\n",
            "2022-05-19 05:21:18,529 - tensorflow - INFO - Outfeed finished for iteration (5, 356)\n",
            "2022-05-19 05:22:18,607 - tensorflow - INFO - Outfeed finished for iteration (5, 496)\n",
            "2022-05-19 05:23:18,830 - tensorflow - INFO - Outfeed finished for iteration (5, 635)\n",
            "2022-05-19 05:24:19,536 - tensorflow - INFO - Outfeed finished for iteration (5, 776)\n",
            "2022-05-19 05:24:58,060 - tensorflow - INFO - Saving checkpoints for 6000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:25:18,378 - tensorflow - INFO - loss = 2.5748812e-05, step = 6000 (447.148 sec)\n",
            "2022-05-19 05:25:18,382 - tensorflow - INFO - global_step/sec: 2.23641\n",
            "2022-05-19 05:25:18,389 - tensorflow - INFO - examples/sec: 143.13\n",
            "2022-05-19 05:25:18,394 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:25:18,396 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:25:20,033 - tensorflow - INFO - Outfeed finished for iteration (5, 917)\n",
            "2022-05-19 05:26:20,454 - tensorflow - INFO - Outfeed finished for iteration (6, 46)\n",
            "2022-05-19 05:27:21,007 - tensorflow - INFO - Outfeed finished for iteration (6, 178)\n",
            "2022-05-19 05:28:21,251 - tensorflow - INFO - Outfeed finished for iteration (6, 315)\n",
            "2022-05-19 05:29:21,587 - tensorflow - INFO - Outfeed finished for iteration (6, 455)\n",
            "2022-05-19 05:30:23,882 - tensorflow - INFO - Outfeed finished for iteration (6, 592)\n",
            "2022-05-19 05:31:24,590 - tensorflow - INFO - Outfeed finished for iteration (6, 730)\n",
            "2022-05-19 05:32:25,493 - tensorflow - INFO - Outfeed finished for iteration (6, 856)\n",
            "2022-05-19 05:32:34,447 - tensorflow - INFO - Saving checkpoints for 7000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:32:54,636 - tensorflow - INFO - loss = 1.9311577e-05, step = 7000 (456.258 sec)\n",
            "2022-05-19 05:32:54,640 - tensorflow - INFO - global_step/sec: 2.19174\n",
            "2022-05-19 05:32:54,649 - tensorflow - INFO - examples/sec: 140.271\n",
            "2022-05-19 05:32:54,654 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:32:54,659 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:33:26,834 - tensorflow - INFO - Outfeed finished for iteration (6, 977)\n",
            "2022-05-19 05:34:26,967 - tensorflow - INFO - Outfeed finished for iteration (7, 109)\n",
            "2022-05-19 05:35:30,126 - tensorflow - INFO - Outfeed finished for iteration (7, 226)\n",
            "2022-05-19 05:36:33,587 - tensorflow - INFO - Outfeed finished for iteration (7, 357)\n",
            "2022-05-19 05:37:33,911 - tensorflow - INFO - Outfeed finished for iteration (7, 483)\n",
            "2022-05-19 05:38:34,085 - tensorflow - INFO - Outfeed finished for iteration (7, 613)\n",
            "2022-05-19 05:39:34,686 - tensorflow - INFO - Outfeed finished for iteration (7, 743)\n",
            "2022-05-19 05:40:26,545 - tensorflow - INFO - Saving checkpoints for 8000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:40:35,354 - tensorflow - INFO - Outfeed finished for iteration (7, 890)\n",
            "2022-05-19 05:40:47,218 - tensorflow - INFO - loss = 8.940569e-06, step = 8000 (472.582 sec)\n",
            "2022-05-19 05:40:47,228 - tensorflow - INFO - global_step/sec: 2.11601\n",
            "2022-05-19 05:40:47,230 - tensorflow - INFO - examples/sec: 135.425\n",
            "2022-05-19 05:40:47,236 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:40:47,237 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:41:35,928 - tensorflow - INFO - Outfeed finished for iteration (8, 22)\n",
            "2022-05-19 05:42:36,434 - tensorflow - INFO - Outfeed finished for iteration (8, 161)\n",
            "2022-05-19 05:43:36,628 - tensorflow - INFO - Outfeed finished for iteration (8, 288)\n",
            "2022-05-19 05:44:37,440 - tensorflow - INFO - Outfeed finished for iteration (8, 402)\n",
            "2022-05-19 05:45:37,933 - tensorflow - INFO - Outfeed finished for iteration (8, 526)\n",
            "2022-05-19 05:46:38,113 - tensorflow - INFO - Outfeed finished for iteration (8, 662)\n",
            "2022-05-19 05:47:38,315 - tensorflow - INFO - Outfeed finished for iteration (8, 799)\n",
            "2022-05-19 05:48:09,711 - tensorflow - INFO - Saving checkpoints for 9000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:48:29,529 - tensorflow - INFO - loss = 5.8415167e-06, step = 9000 (462.311 sec)\n",
            "2022-05-19 05:48:29,533 - tensorflow - INFO - global_step/sec: 2.16307\n",
            "2022-05-19 05:48:29,539 - tensorflow - INFO - examples/sec: 138.437\n",
            "2022-05-19 05:48:29,547 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:48:29,549 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:48:38,651 - tensorflow - INFO - Outfeed finished for iteration (8, 924)\n",
            "2022-05-19 05:49:39,081 - tensorflow - INFO - Outfeed finished for iteration (9, 43)\n",
            "2022-05-19 05:50:39,604 - tensorflow - INFO - Outfeed finished for iteration (9, 186)\n",
            "2022-05-19 05:51:39,714 - tensorflow - INFO - Outfeed finished for iteration (9, 322)\n",
            "2022-05-19 05:52:40,154 - tensorflow - INFO - Outfeed finished for iteration (9, 463)\n",
            "2022-05-19 05:53:40,684 - tensorflow - INFO - Outfeed finished for iteration (9, 608)\n",
            "2022-05-19 05:54:41,598 - tensorflow - INFO - Outfeed finished for iteration (9, 725)\n",
            "2022-05-19 05:55:42,167 - tensorflow - INFO - Outfeed finished for iteration (9, 865)\n",
            "2022-05-19 05:55:44,361 - tensorflow - INFO - Saving checkpoints for 10000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 05:56:05,586 - tensorflow - INFO - loss = 3.0994265e-06, step = 10000 (456.057 sec)\n",
            "2022-05-19 05:56:05,590 - tensorflow - INFO - global_step/sec: 2.19271\n",
            "2022-05-19 05:56:05,594 - tensorflow - INFO - examples/sec: 140.334\n",
            "2022-05-19 05:56:05,598 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 05:56:05,600 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 05:56:42,194 - tensorflow - INFO - Outfeed finished for iteration (10, 0)\n",
            "2022-05-19 05:57:42,324 - tensorflow - INFO - Outfeed finished for iteration (10, 140)\n",
            "2022-05-19 05:58:42,416 - tensorflow - INFO - Outfeed finished for iteration (10, 277)\n",
            "2022-05-19 05:59:44,389 - tensorflow - INFO - Outfeed finished for iteration (10, 415)\n",
            "2022-05-19 06:00:44,984 - tensorflow - INFO - Outfeed finished for iteration (10, 543)\n",
            "2022-05-19 06:01:45,138 - tensorflow - INFO - Outfeed finished for iteration (10, 680)\n",
            "2022-05-19 06:02:45,427 - tensorflow - INFO - Outfeed finished for iteration (10, 814)\n",
            "2022-05-19 06:03:09,790 - tensorflow - INFO - Saving checkpoints for 11000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 06:03:28,379 - tensorflow - INFO - loss = 2.026674e-06, step = 11000 (442.793 sec)\n",
            "2022-05-19 06:03:28,385 - tensorflow - INFO - global_step/sec: 2.25838\n",
            "2022-05-19 06:03:28,390 - tensorflow - INFO - examples/sec: 144.536\n",
            "2022-05-19 06:03:28,401 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 06:03:28,402 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 06:03:46,160 - tensorflow - INFO - Outfeed finished for iteration (10, 955)\n",
            "2022-05-19 06:04:46,385 - tensorflow - INFO - Outfeed finished for iteration (11, 97)\n",
            "2022-05-19 06:05:46,433 - tensorflow - INFO - Outfeed finished for iteration (11, 218)\n",
            "2022-05-19 06:06:46,702 - tensorflow - INFO - Outfeed finished for iteration (11, 350)\n",
            "2022-05-19 06:07:47,207 - tensorflow - INFO - Outfeed finished for iteration (11, 498)\n",
            "2022-05-19 06:08:47,384 - tensorflow - INFO - Outfeed finished for iteration (11, 634)\n",
            "2022-05-19 06:09:48,011 - tensorflow - INFO - Outfeed finished for iteration (11, 786)\n",
            "2022-05-19 06:10:32,582 - tensorflow - INFO - Saving checkpoints for 12000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 06:10:48,777 - tensorflow - INFO - Outfeed finished for iteration (11, 905)\n",
            "2022-05-19 06:10:51,729 - tensorflow - INFO - loss = 1.1922384e-06, step = 12000 (443.350 sec)\n",
            "2022-05-19 06:10:51,737 - tensorflow - INFO - global_step/sec: 2.25554\n",
            "2022-05-19 06:10:51,740 - tensorflow - INFO - examples/sec: 144.355\n",
            "2022-05-19 06:10:51,749 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 06:10:51,752 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 06:11:49,006 - tensorflow - INFO - Outfeed finished for iteration (12, 52)\n",
            "2022-05-19 06:12:49,592 - tensorflow - INFO - Outfeed finished for iteration (12, 187)\n",
            "2022-05-19 06:13:49,969 - tensorflow - INFO - Outfeed finished for iteration (12, 323)\n",
            "2022-05-19 06:14:50,600 - tensorflow - INFO - Outfeed finished for iteration (12, 453)\n",
            "2022-05-19 06:15:54,562 - tensorflow - INFO - Outfeed finished for iteration (12, 589)\n",
            "2022-05-19 06:16:55,585 - tensorflow - INFO - Outfeed finished for iteration (12, 712)\n",
            "2022-05-19 06:17:55,627 - tensorflow - INFO - Outfeed finished for iteration (12, 849)\n",
            "2022-05-19 06:18:06,349 - tensorflow - INFO - Saving checkpoints for 13000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 06:18:28,661 - tensorflow - INFO - loss = 9.537907e-07, step = 13000 (456.931 sec)\n",
            "2022-05-19 06:18:28,665 - tensorflow - INFO - global_step/sec: 2.18853\n",
            "2022-05-19 06:18:28,672 - tensorflow - INFO - examples/sec: 140.066\n",
            "2022-05-19 06:18:28,677 - tensorflow - INFO - Enqueue next (1000) batch(es) of data to infeed.\n",
            "2022-05-19 06:18:28,678 - tensorflow - INFO - Dequeue next (1000) batch(es) of data from outfeed.\n",
            "2022-05-19 06:18:56,408 - tensorflow - INFO - Outfeed finished for iteration (12, 981)\n",
            "2022-05-19 06:19:56,772 - tensorflow - INFO - Outfeed finished for iteration (13, 111)\n",
            "2022-05-19 06:20:57,331 - tensorflow - INFO - Outfeed finished for iteration (13, 240)\n",
            "2022-05-19 06:21:57,670 - tensorflow - INFO - Outfeed finished for iteration (13, 374)\n",
            "2022-05-19 06:22:58,412 - tensorflow - INFO - Outfeed finished for iteration (13, 509)\n",
            "2022-05-19 06:23:58,993 - tensorflow - INFO - Outfeed finished for iteration (13, 652)\n",
            "2022-05-19 06:24:59,148 - tensorflow - INFO - Outfeed finished for iteration (13, 790)\n",
            "2022-05-19 06:25:32,204 - tensorflow - INFO - Saving checkpoints for 14000 into gs://theodore_jiang/bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl/fl_5_bs_64/model.ckpt.\n",
            "2022-05-19 06:25:53,174 - tensorflow - INFO - loss = 8.345669e-07, step = 14000 (444.513 sec)\n",
            "2022-05-19 06:25:53,178 - tensorflow - INFO - global_step/sec: 2.24966\n",
            "2022-05-19 06:25:53,180 - tensorflow - INFO - examples/sec: 143.978\n",
            "2022-05-19 06:25:54,091 - tensorflow - INFO - Stop infeed thread controller\n",
            "2022-05-19 06:25:54,093 - tensorflow - INFO - Shutting down InfeedController thread.\n",
            "2022-05-19 06:25:54,095 - tensorflow - INFO - InfeedController received shutdown signal, stopping.\n",
            "2022-05-19 06:25:54,096 - tensorflow - INFO - Infeed thread finished, shutting down.\n",
            "2022-05-19 06:25:54,100 - tensorflow - INFO - infeed marked as finished\n",
            "2022-05-19 06:25:54,101 - tensorflow - INFO - Stop output thread controller\n",
            "2022-05-19 06:25:54,103 - tensorflow - INFO - Shutting down OutfeedController thread.\n",
            "2022-05-19 06:26:00,033 - tensorflow - INFO - Outfeed finished for iteration (13, 925)\n",
            "2022-05-19 06:26:33,646 - tensorflow - INFO - OutfeedController received shutdown signal, stopping.\n",
            "2022-05-19 06:26:33,649 - tensorflow - INFO - Outfeed thread finished, shutting down.\n",
            "2022-05-19 06:26:33,651 - tensorflow - INFO - outfeed marked as finished\n",
            "2022-05-19 06:26:33,652 - tensorflow - INFO - Shutdown TPU system.\n",
            "2022-05-19 06:26:35,443 - tensorflow - INFO - Loss for final step: 8.345669e-07.\n",
            "2022-05-19 06:26:35,446 - tensorflow - INFO - training_loop marked as finished\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### IO config\n",
        "#@markdown Folder in GCS where the pretrained models needs to be loaded from:\n",
        "INIT_MODEL_DIR = \"pretrained_models\" #@param {type:\"string\"}\n",
        "#@markdown Folder for where to save the finetuned models:\n",
        "OUTPUT_MODEL_DIR = \"bert_model_mrpc_ex_data_all_flbs5_6_2022_512sl\" #@param {type:\"string\"}\n",
        "#@markdown Which folder inside of LOGGING_DIR to store the logs in\n",
        "RUN_NAME = \"MRPC_ex_data_allflbs5_6_2022_512sl\" #@param {type:\"string\"}\n",
        "#@markdown \\\n",
        "#@markdown \n",
        "#@markdown \n",
        "#@markdown ### Training procedure config\n",
        "FREEZINGS = [8,6,5] #@param\n",
        "#@markdown Batch size to use\n",
        "BATCH_SIZES =  [16,64] #@param\n",
        "#@markdown The training loop will loop through a list of pretrained models and a list of sequence lengths, training a model for each combination of pretrained model and sequence length\n",
        "#@markdown * List of pretrained models to load (should indicate the names of the model folders inside the specified INIT_MODEL_DIR\n",
        "MODEL_NAME =  \"MutFormer_em_adap8L\"#,\"MutFormer10L\",\"MutFormer12L\"]#@param\n",
        "#@markdown * List of model architectures for each model in the \"MODELS\" list defined in the entry above: each position in this list must correctly indicate the model architecture of its corresponding model folder in the list \"MODELS\" (BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture).\n",
        "MODEL_ARCHITECTURE = \"MutFormer_embedded_convs\"#,\"BertModelModified\",\"BertModelModified\"] #@param\n",
        "#@markdown * List of sequence lengths to test\n",
        "MAX_SEQ_LENGTH = 512 #@param\n",
        "#@markdown Whether or not to resume training from a previous checkpoint; if no, always train from scratch\n",
        "RESUMING = True #@param {type:\"boolean\"}\n",
        "#@markdown Whether or not data was generated in shards (for really large databases)\n",
        "USING_SHARDS = False #@param {type:\"boolean\"}\n",
        "#@markdown If training data was generated in shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD = 0 #@param {type:\"integer\"}\n",
        "#@markdown Training uses a linear learning rate.\n",
        "#@markdown * Start learning rate: training will start with this learning rate on the step that learning rate warmup is complete\n",
        "INIT_LEARNING_RATE =  1e-5 #@param {type:\"number\"}\n",
        "#@markdown * End learning rate: training will alter the learning rate every step linearly so that it finishes with this learning rate on the last step.\n",
        "END_LEARNING_RATE = 3e-9 #@param {type:\"number\"}\n",
        "#@markdown How many steps during training to perform learning rate warmup for (start from learning rate 0 and increase to INIT_LEARNING_RATE): Set to 0 for no warmup.\n",
        "NUM_WARMUP_STEPS =  0#@param {type:\"integer\"}\n",
        "#@markdown What weight decay value to use (MutFormer uses 0.01; a higher weight decay is more resistant to exploding gradients, but also limits the model's ability to learn)\n",
        "WEIGHT_DECAY = 0.01 #@param {type:\"number\"}\n",
        "#@markdown Save a checkpoint every this amount of steps:\n",
        "SAVE_CHECKPOINTS_STEPS =   1000#@param {type:\"integer\"}\n",
        "#@markdown TPUEstimator will keep this number of checkpoints at a time; older checkpoints will all be deleted:\n",
        "KEEP_N_CHECKPOINTS_AT_A_TIME =  100#@param {type:\"integer\"}\n",
        "#@markdown How many sequences should the model train on before stopping:\n",
        "PLANNED_TOTAL_SEQUENCES_SEEN =  2e5 #@param {type:\"number\"}\n",
        "#@markdown How many steps should the model train for before stopping (number of total sequences trained on will depend on the batch size used). NOTE: PLANNED_TOTAL_STEPS will override PLANNED_TOTAL_SEQUENCES_SEEN; if using PLANNED_TOTAL_SEQUENCES_SEEN, set PLANNED_TOTAL_STEPS to -1 (PLANNED TOTAL STEPS will be based on the train batch size used, which can be specified later)\n",
        "PLANNED_TOTAL_STEPS =  14000#@param {type:\"number\"}\n",
        "\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/BATCH_SIZE) \n",
        "\n",
        "DATA_INFOS = [[\"N/A\" for BATCH_SIZE in BATCH_SIZES]            ##create an empty 2D list to store all\n",
        "              for FREEZING in FREEZINGS]      ##the data info dictionaries\n",
        "                                                                                   \n",
        "for M,FREEZING in enumerate(FREEZINGS):\n",
        "  for m,BATCH_SIZE in enumerate(BATCH_SIZES):\n",
        "    print(\"\\n\\n\\nFreezing layers:\",FREEZING,\n",
        "          \"\\nBATCH SIZE:\",BATCH_SIZE)\n",
        "\n",
        "\n",
        "    MODEL = getattr(modeling, MODEL_ARCHITECTURE)\n",
        "    INIT_CHECKPOINT_DIR = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME\n",
        "    GCS_OUTPUT_MODEL_DIR = BUCKET_PATH+\"/\"+OUTPUT_MODEL_DIR+\"/fl_\"+str(FREEZING)+\"_bs_\"+str(BATCH_SIZE)\n",
        "    DATA_GCS_DIR = BUCKET_PATH+\"/\"+PROCESSED_DATA_DIR+\"/\"+str(MAX_SEQ_LENGTH)\n",
        "    \n",
        "    GCS_LOGGING_DIR = BUCKET_PATH+\"/\"+LOGGING_DIR+\"/\"+RUN_NAME+\"/fl_\"+str(FREEZING)+\"_bs_\"+str(BATCH_SIZE)\n",
        "\n",
        "    CONFIG_FILE = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME+\"/config.json\"\n",
        "    \n",
        "    if DATA_INFOS[M][m] == \"N/A\":\n",
        "      DATA_INFOS[M][m] = json.load(tf.gfile.Open(DATA_GCS_DIR+\"/info.json\"))\n",
        "    \n",
        "    EX_DATA_NUM = DATA_INFOS[M][m][\"ex_data_num\"] if USING_EX_DATA else 0\n",
        "    \n",
        "    training_loop(BATCH_SIZE,\n",
        "                  RESUMING,\n",
        "                  PLANNED_TOTAL_STEPS,\n",
        "                  DECAY_PER_STEP,\n",
        "                  MAX_SEQ_LENGTH,\n",
        "                  MODEL_NAME,\n",
        "                  MODEL,\n",
        "                  INIT_CHECKPOINT_DIR,\n",
        "                  GCS_OUTPUT_MODEL_DIR,\n",
        "                  DATA_GCS_DIR,\n",
        "                  USING_SHARDS,\n",
        "                  START_SHARD,\n",
        "                  USING_EX_DATA,\n",
        "                  EX_DATA_NUM,\n",
        "                  GCS_LOGGING_DIR,\n",
        "                  CONFIG_FILE,\n",
        "                  FREEZING=FREEZING,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQNkVKkFip91"
      },
      "outputs": [],
      "source": [
        "#imvwgytpviqrlfrva#jjrc#ujdfbbxy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ322RGr5ykF"
      },
      "source": [
        "####Batch size/sequence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IytLW0VbgOZz"
      },
      "outputs": [],
      "source": [
        "#@markdown ### IO config\n",
        "#@markdown Folder in GCS where the pretrained models needs to be loaded from:\n",
        "INIT_MODEL_DIR = \"\" #@param {type:\"string\"}\n",
        "#@markdown Name of the folder to the pretrained model to load from inside INIT_MODEL_DIR\n",
        "MODEL_NAME=\"bert_model_modified_large\" #@param {type:\"string\"}\n",
        "#@markdown Model architecture to use BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture\n",
        "MODEL_ARCHITECTURE = BertModelModified #@param\n",
        "#@markdown Folder for where to save the finetuned model\n",
        "OUTPUT_MODEL_DIR = \"bert_model_mrpc_adding_preds\" #@param {type:\"string\"}\n",
        "#@markdown Which folder inside of LOGGING_DIR to store the logs in\n",
        "RUN_NAME = \"MRPC_adding_preds_w_mutformer12L\" #@param {type:\"string\"}\n",
        "#@markdown \\\n",
        "#@markdown \n",
        "#@markdown \n",
        "#@markdown ### Training procedure config\n",
        "#@markdown The training loop will loop through a list of batch sizes and a list of sequence lengths, training a model for each combination of batch size and sequence length\n",
        "#@markdown * List of batch sizes to test\n",
        "BATCH_SIZES = [64] #@param\n",
        "#@markdown * List of sequence lengths to test\n",
        "MAX_SEQ_LENGTHS = [1024] #@param\n",
        "#@markdown Whether or not to resume training from a previous checkpoint; if no, always train from scratch\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown Whether or not data was generated in shards (for really large databases)\n",
        "USING_SHARDS = False #@param {type:\"boolean\"}\n",
        "#@markdown If training data was generated in shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD = 0 #@param {type:\"integer\"}\n",
        "#@markdown Training uses a linear learning rate.\n",
        "#@markdown * Start learning rate: training will start with this learning rate on the step that learning rate warmup is complete\n",
        "INIT_LEARNING_RATE =  1e-5 #@param {type:\"number\"}\n",
        "#@markdown * End learning rate: training will alter the learning rate every step linearly so that it finishes with this learning rate on the last step.\n",
        "END_LEARNING_RATE = 5e-7 #@param {type:\"number\"}\n",
        "#@markdown How many steps during training to perform learning rate warmup for (start from learning rate 0 and increase to INIT_LEARNING_RATE): Set to 0 for no warmup.\n",
        "NUM_WARMUP_STEPS = 10 #@param {type:\"integer\"}\n",
        "#@markdown What weight decay value to use (MutFormer uses 0.01; a higher weight decay is more resistant to exploding gradients, but also limits the model's ability to learn)\n",
        "WEIGHT_DECAY = 0.01 #@param {type:\"number\"}\n",
        "#@markdown Save a checkpoint every this amount of steps:\n",
        "SAVE_CHECKPOINTS_STEPS =  1000 #@param {type:\"integer\"}\n",
        "#@markdown TPUEstimator will keep this number of checkpoints at a time; older checkpoints will all be deleted:\n",
        "KEEP_N_CHECKPOINTS_AT_A_TIME =  10#@param {type:\"integer\"}\n",
        "#@markdown How many sequences should the model train on before stopping:\n",
        "PLANNED_TOTAL_SEQUENCES_SEEN =  2e5 #@param {type:\"number\"}\n",
        "#@markdown How many steps should the model train for before stopping (number of total sequences trained on will depend on the batch size used). NOTE: PLANNED_TOTAL_STEPS will override PLANNED_TOTAL_SEQUENCES_SEEN; if using PLANNED_TOTAL_SEQUENCES_SEEN, set PLANNED_TOTAL_STEPS to -1 (PLANNED TOTAL STEPS will be based on the train batch size used, which can be specified later)\n",
        "PLANNED_TOTAL_STEPS = 8000 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/BATCH_SIZE) \n",
        "\n",
        "DATA_INFOS = [[\"N/A\" for BATCH_SIZE in BATCH_SIZES]            ##create an empty 2D list to store all\n",
        "              for MAX_SEQ_LENGTH in MAX_SEQ_LENGTHS]           ##the data info dictionaries\n",
        "\n",
        "for M,MAX_SEQ_LENGTH in enumerate(MAX_SEQ_LENGTHS):\n",
        "    for B,BATCH_SIZE in enumerate(BATCH_SIZES):\n",
        "        print(\"\\nINPUT MAX SEQ LENGTH:\",MAX_SEQ_LENGTH,\n",
        "              \"\\nTRAIN_BATCH_SIZE:\",BATCH_SIZE,\"\\n\\n\\n\")\n",
        "       \n",
        "        MODEL = MODEL_ARCHITECTURE\n",
        "        INIT_CHECKPOINT_DIR = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME\n",
        "        GCS_OUTPUT_MODEL_DIR = BUCKET_PATH+\"/\"+OUTPUT_MODEL_DIR+\"/bs_\"+str(BATCH_SIZE)+\"_sl_\"+str(MAX_SEQ_LENGTH)\n",
        "        DATA_GCS_DIR = BUCKET_PATH+\"/\"+PROCESSED_DATA_DIR+\"/\"+str(MAX_SEQ_LENGTH)\n",
        "      \n",
        "        GCS_LOGGING_DIR = BUCKET_PATH+\"/\"+LOGGING_DIR+\"/\"+RUN_NAME+\"/bs_\"+str(BATCH_SIZE)+_\"sl_\"+str(MAX_SEQ_LENGTH)\n",
        "        \n",
        "        CONFIG_FILE = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME+\"/config.json\"\n",
        "        \n",
        "        if DATA_INFOS[M][B] == \"N/A\":\n",
        "          DATA_INFOS[M][B] = json.load(tf.gfile.Open(DATA_GCS_DIR+\"/info.json\"))\n",
        "        \n",
        "        EX_DATA_NUM = DATA_INFOS[M][B][\"ex_data_num\"] if USING_EX_DATA else 0\n",
        "\n",
        "        training_loop(BATCH_SIZE,\n",
        "                      RESUMING,\n",
        "                      PLANNED_TOTAL_STEPS,\n",
        "                      DECAY_PER_STEP,\n",
        "                      MAX_SEQ_LENGTH,\n",
        "                      MODEL_NAME,\n",
        "                      MODEL,\n",
        "                      INIT_CHECKPOINT_DIR,\n",
        "                      GCS_OUTPUT_MODEL_DIR,\n",
        "                      DATA_GCS_DIR,\n",
        "                      USING_SHARDS,\n",
        "                      START_SHARD,\n",
        "                      USING_EX_DATA,\n",
        "                      EX_DATA_NUM,\n",
        "                      GCS_LOGGING_DIR,\n",
        "                      CONFIG_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tswiJYA_qCUq"
      },
      "source": [
        "####One model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK3tf7aWqIiR",
        "outputId": "6f4fc2de-bebb-45e0-a45c-16f8c076ba1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-28 09:53:08,083 - tensorflow - INFO - Using data from: gs://theodore_jiang/MRPC_finetune_updated_loaded/512\n",
            "2021-12-28 09:53:08,084 - tensorflow - INFO - Loading model from: gs://theodore_jiang/pretrained_models/MutFormer12L\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/checkpoint#1640683883000169...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/config.json#1640683540286580...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/eval/#1640683662810271...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/eval/events.out.tfevents.1640683663.fc177c076896#1640683916552904...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/events.out.tfevents.1640683561.19298bd56af2#1640683851158774...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-0.data-00000-of-00001#1640683596047838...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-0.index#1640683596674707...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-0.meta#1640683599930824...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-100.data-00000-of-00001#1640683674767846...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/graph.pbtxt#1640683581189201...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-100.index#1640683675083601...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-100.meta#1640683677652220...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-200.data-00000-of-00001#1640683711983015...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-200.index#1640683712317160...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-200.meta#1640683714773782...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-300.data-00000-of-00001#1640683745865951...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-300.index#1640683746194434...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-300.meta#1640683748720693...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-400.data-00000-of-00001#1640683779140473...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-400.index#1640683779467752...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-400.meta#1640683782630470...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-500.data-00000-of-00001#1640683813790609...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-500.index#1640683814150658...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-500.meta#1640683816961299...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-600.index#1640683847805108...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-600.meta#1640683850401680...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-700.data-00000-of-00001#1640683881891846...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-700.index#1640683882235594...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-700.meta#1640683884590024...\n",
            "Removing gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt-600.data-00000-of-00001#1640683847462502...\n",
            "/ [30/30 objects] 100% Done                                                     \n",
            "Operation completed over 30 objects.                                             \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-28 09:53:10,996 - tensorflow - WARNING - From /content/mutformer/modeling.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "init checkpoint: gs://theodore_jiang/pretrained_models/MutFormer12L/model.ckpt-2002192 restore/save checkpont: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-28 09:53:12,836 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f700505f560>) includes params argument, but params are not passed to Estimator.\n",
            "2021-12-28 09:53:12,838 - tensorflow - INFO - Using config: {'_model_dir': 'gs://theodore_jiang/bert_model_mrpc_trying_again', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.122.0.234:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f70050b5690>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.122.0.234:8470', '_evaluation_master': 'grpc://10.122.0.234:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f6e6887f450>}\n",
            "2021-12-28 09:53:12,840 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n",
            "2021-12-28 09:53:12,841 - tensorflow - INFO - ***** Running training *****\n",
            "2021-12-28 09:53:12,842 - tensorflow - INFO -   Batch size = 32\n",
            "2021-12-28 09:53:12,844 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:357: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2021-12-28 09:53:13,000 - tensorflow - INFO - Querying Tensorflow master (grpc://10.122.0.234:8470) for TPU system metadata.\n",
            "2021-12-28 09:53:13,025 - tensorflow - INFO - Found TPU system:\n",
            "2021-12-28 09:53:13,026 - tensorflow - INFO - *** Num TPU Cores: 8\n",
            "2021-12-28 09:53:13,027 - tensorflow - INFO - *** Num TPU Workers: 1\n",
            "2021-12-28 09:53:13,028 - tensorflow - INFO - *** Num TPU Cores Per Worker: 8\n",
            "2021-12-28 09:53:13,029 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5777496970213906613)\n",
            "2021-12-28 09:53:13,030 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2807607262086644481)\n",
            "2021-12-28 09:53:13,031 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1208606759586499207)\n",
            "2021-12-28 09:53:13,032 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7422379958042741703)\n",
            "2021-12-28 09:53:13,033 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 834567455576472207)\n",
            "2021-12-28 09:53:13,037 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10905835738766128679)\n",
            "2021-12-28 09:53:13,038 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8327558755439431152)\n",
            "2021-12-28 09:53:13,040 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 810796248590672091)\n",
            "2021-12-28 09:53:13,041 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16555272657220871321)\n",
            "2021-12-28 09:53:13,042 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 13892938660792324679)\n",
            "2021-12-28 09:53:13,043 - tensorflow - INFO - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3479062433315422730)\n",
            "2021-12-28 09:53:13,052 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2021-12-28 09:53:13,054 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2021-12-28 09:53:13,067 - tensorflow - INFO - Calling model_fn.\n",
            "2021-12-28 09:53:13,091 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:404: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2021-12-28 09:53:13,093 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2021-12-28 09:53:13,111 - tensorflow - WARNING - Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f70302ac560> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "2021-12-28 09:53:13,113 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:366: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2021-12-28 09:53:13,121 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:373: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-12-28 09:53:13,199 - tensorflow - INFO - *** Features ***\n",
            "2021-12-28 09:53:13,200 - tensorflow - INFO -   name = input_ids, shape = (4, 512)\n",
            "2021-12-28 09:53:13,201 - tensorflow - INFO -   name = input_mask, shape = (4, 512)\n",
            "2021-12-28 09:53:13,202 - tensorflow - INFO -   name = is_real_example, shape = (4,)\n",
            "2021-12-28 09:53:13,204 - tensorflow - INFO -   name = label_ids, shape = (4,)\n",
            "2021-12-28 09:53:13,205 - tensorflow - INFO -   name = segment_ids, shape = (4, 512)\n",
            "2021-12-28 09:53:13,206 - tensorflow - WARNING - From /content/mutformer/modeling.py:299: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2021-12-28 09:53:13,213 - tensorflow - WARNING - From /content/mutformer/modeling.py:657: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2021-12-28 09:53:13,249 - tensorflow - WARNING - From /content/mutformer/modeling.py:738: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2021-12-28 09:53:13,296 - tensorflow - WARNING - From /content/mutformer/modeling.py:606: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f70302ac560> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-28 09:53:13,391 - tensorflow - WARNING - From /content/mutformer/modeling.py:989: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2021-12-28 09:53:13,393 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2021-12-28 09:53:16,266 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:526: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "2021-12-28 09:53:16,837 - tensorflow - INFO - **** Trainable Variables ****\n",
            "2021-12-28 09:53:16,840 - tensorflow - INFO -   name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,842 - tensorflow - INFO -   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,844 - tensorflow - INFO -   name = bert/embeddings/position_embeddings:0, shape = (1024, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,845 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,847 - tensorflow - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,849 - tensorflow - INFO -   name = bert/embeddings/conv1d/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,851 - tensorflow - INFO -   name = bert/embeddings/conv1d/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,852 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/kernel:0, shape = (3, 768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,855 - tensorflow - INFO -   name = bert/embeddings/conv1d_1/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,856 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,857 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,858 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,859 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,861 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,862 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,863 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,864 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,865 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,867 - tensorflow - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,867 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,868 - tensorflow - INFO -   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,869 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,870 - tensorflow - INFO -   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,873 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,874 - tensorflow - INFO -   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,875 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,876 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,877 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,878 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,879 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,881 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,882 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,884 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,892 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,894 - tensorflow - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,895 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,896 - tensorflow - INFO -   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,897 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,899 - tensorflow - INFO -   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,900 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,901 - tensorflow - INFO -   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,902 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,903 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,904 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,909 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,910 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,911 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,913 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,913 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,914 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,916 - tensorflow - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,917 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,918 - tensorflow - INFO -   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,918 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,920 - tensorflow - INFO -   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,921 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,922 - tensorflow - INFO -   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,925 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,928 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,929 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,931 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,932 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,933 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,934 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,935 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,936 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,937 - tensorflow - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,938 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,939 - tensorflow - INFO -   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,940 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,941 - tensorflow - INFO -   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,942 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,943 - tensorflow - INFO -   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,945 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,947 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,948 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,949 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,950 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,952 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,953 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,956 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,957 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,958 - tensorflow - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,959 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,960 - tensorflow - INFO -   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,961 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,962 - tensorflow - INFO -   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,963 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,965 - tensorflow - INFO -   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,967 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,968 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,969 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,970 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,976 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,977 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,979 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,980 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,981 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,983 - tensorflow - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,984 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,985 - tensorflow - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,986 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,987 - tensorflow - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,988 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,991 - tensorflow - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,992 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,993 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,995 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,996 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,997 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,998 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:16,999 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,001 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,003 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,004 - tensorflow - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,005 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,006 - tensorflow - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,009 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,010 - tensorflow - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,011 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,012 - tensorflow - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,013 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,014 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,015 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,016 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,017 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,018 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,019 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,020 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,024 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,025 - tensorflow - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,027 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,028 - tensorflow - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,029 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,030 - tensorflow - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,032 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,033 - tensorflow - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,035 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,036 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,037 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,038 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,039 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,040 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,041 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,044 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,045 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,047 - tensorflow - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,049 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,050 - tensorflow - INFO -   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,051 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,052 - tensorflow - INFO -   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,053 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,054 - tensorflow - INFO -   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,055 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,056 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,057 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,058 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,059 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,060 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,061 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,063 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,065 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,067 - tensorflow - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,068 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,069 - tensorflow - INFO -   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,070 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,071 - tensorflow - INFO -   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,072 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,073 - tensorflow - INFO -   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,074 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,080 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,082 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,084 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,085 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,086 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,088 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,089 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,090 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,091 - tensorflow - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,093 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,094 - tensorflow - INFO -   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,097 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,098 - tensorflow - INFO -   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,101 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,101 - tensorflow - INFO -   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,103 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,104 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,105 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,106 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,107 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,110 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,111 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,112 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,113 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,114 - tensorflow - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,115 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,116 - tensorflow - INFO -   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,117 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,118 - tensorflow - INFO -   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,119 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,120 - tensorflow - INFO -   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,121 - tensorflow - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,122 - tensorflow - INFO -   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-12-28 09:53:17,123 - tensorflow - INFO -   name = output_weights:0, shape = (2, 768), *INIT_NEW*\n",
            "2021-12-28 09:53:17,124 - tensorflow - INFO -   name = output_bias:0, shape = (2,), *INIT_NEW*\n",
            "2021-12-28 09:53:17,125 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:572: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2021-12-28 09:53:17,388 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2021-12-28 09:53:27,182 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:535: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2021-12-28 09:53:27,449 - tensorflow - WARNING - From /content/mutformer/run_classifier.py:540: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "2021-12-28 09:53:28,515 - tensorflow - INFO - Create CheckpointSaverHook.\n",
            "2021-12-28 09:53:28,860 - tensorflow - INFO - Done calling model_fn.\n",
            "2021-12-28 09:53:31,482 - tensorflow - INFO - TPU job name worker\n",
            "2021-12-28 09:53:32,994 - tensorflow - INFO - Graph was finalized.\n",
            "2021-12-28 09:53:38,545 - tensorflow - INFO - Restoring parameters from gs://theodore_jiang/pretrained_models/MutFormer12L/model.ckpt-2002192\n",
            "2021-12-28 09:53:50,820 - tensorflow - INFO - Running local_init_op.\n",
            "2021-12-28 09:53:51,349 - tensorflow - INFO - Done running local_init_op.\n",
            "2021-12-28 09:53:59,186 - tensorflow - INFO - Saving checkpoints for 0 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:54:17,407 - tensorflow - WARNING - From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2021-12-28 09:54:18,486 - tensorflow - INFO - Initialized dataset iterators in 0 seconds\n",
            "2021-12-28 09:54:18,487 - tensorflow - INFO - Installing graceful shutdown hook.\n",
            "2021-12-28 09:54:18,494 - tensorflow - INFO - Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2021-12-28 09:54:18,498 - tensorflow - INFO - Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2021-12-28 09:54:18,503 - tensorflow - INFO - Init TPU system\n",
            "2021-12-28 09:54:26,368 - tensorflow - INFO - Initialized TPU in 7 seconds\n",
            "2021-12-28 09:54:27,229 - tensorflow - INFO - Starting infeed thread controller.\n",
            "2021-12-28 09:54:27,230 - tensorflow - INFO - Starting outfeed thread controller.\n",
            "2021-12-28 09:54:27,780 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:54:27,782 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:55:04,157 - tensorflow - INFO - Outfeed finished for iteration (0, 0)\n",
            "2021-12-28 09:55:15,565 - tensorflow - INFO - Saving checkpoints for 100 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:55:37,836 - tensorflow - INFO - loss = 1.0916303, step = 100\n",
            "2021-12-28 09:55:37,841 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:55:37,842 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:55:54,507 - tensorflow - INFO - Saving checkpoints for 200 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:56:05,694 - tensorflow - INFO - Outfeed finished for iteration (1, 83)\n",
            "2021-12-28 09:56:16,332 - tensorflow - INFO - loss = 1.3937702, step = 200 (38.496 sec)\n",
            "2021-12-28 09:56:16,335 - tensorflow - INFO - global_step/sec: 2.59769\n",
            "2021-12-28 09:56:16,337 - tensorflow - INFO - examples/sec: 83.1261\n",
            "2021-12-28 09:56:16,339 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:56:16,341 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:56:28,803 - tensorflow - INFO - Saving checkpoints for 300 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:56:50,456 - tensorflow - INFO - loss = 1.6197338, step = 300 (34.124 sec)\n",
            "2021-12-28 09:56:50,459 - tensorflow - INFO - global_step/sec: 2.9305\n",
            "2021-12-28 09:56:50,460 - tensorflow - INFO - examples/sec: 93.7761\n",
            "2021-12-28 09:56:50,463 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:56:50,464 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:57:02,871 - tensorflow - INFO - Saving checkpoints for 400 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:57:06,469 - tensorflow - INFO - Outfeed finished for iteration (3, 61)\n",
            "2021-12-28 09:57:24,378 - tensorflow - INFO - loss = 0.563612, step = 400 (33.922 sec)\n",
            "2021-12-28 09:57:24,381 - tensorflow - INFO - global_step/sec: 2.94793\n",
            "2021-12-28 09:57:24,383 - tensorflow - INFO - examples/sec: 94.3337\n",
            "2021-12-28 09:57:24,387 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:57:24,388 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:57:36,853 - tensorflow - INFO - Saving checkpoints for 500 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:57:58,457 - tensorflow - INFO - loss = 1.6748056, step = 500 (34.079 sec)\n",
            "2021-12-28 09:57:58,461 - tensorflow - INFO - global_step/sec: 2.93427\n",
            "2021-12-28 09:57:58,463 - tensorflow - INFO - examples/sec: 93.8965\n",
            "2021-12-28 09:57:58,465 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:57:58,467 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:58:06,474 - tensorflow - INFO - Outfeed finished for iteration (5, 31)\n",
            "2021-12-28 09:58:10,933 - tensorflow - INFO - Saving checkpoints for 600 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:58:32,365 - tensorflow - INFO - loss = 1.7387781, step = 600 (33.907 sec)\n",
            "2021-12-28 09:58:32,367 - tensorflow - INFO - global_step/sec: 2.94931\n",
            "2021-12-28 09:58:32,369 - tensorflow - INFO - examples/sec: 94.378\n",
            "2021-12-28 09:58:32,373 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:58:32,374 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:58:44,796 - tensorflow - INFO - Saving checkpoints for 700 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:59:06,329 - tensorflow - INFO - loss = 0.56120384, step = 700 (33.964 sec)\n",
            "2021-12-28 09:59:06,332 - tensorflow - INFO - global_step/sec: 2.94428\n",
            "2021-12-28 09:59:06,333 - tensorflow - INFO - examples/sec: 94.217\n",
            "2021-12-28 09:59:06,337 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:59:06,338 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:59:07,721 - tensorflow - INFO - Outfeed finished for iteration (7, 0)\n",
            "2021-12-28 09:59:18,820 - tensorflow - INFO - Saving checkpoints for 800 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 09:59:40,993 - tensorflow - INFO - loss = 0.33927903, step = 800 (34.664 sec)\n",
            "2021-12-28 09:59:40,996 - tensorflow - INFO - global_step/sec: 2.88481\n",
            "2021-12-28 09:59:40,997 - tensorflow - INFO - examples/sec: 92.3138\n",
            "2021-12-28 09:59:41,000 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 09:59:41,002 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 09:59:53,439 - tensorflow - INFO - Saving checkpoints for 900 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 10:00:07,852 - tensorflow - INFO - Outfeed finished for iteration (8, 81)\n",
            "2021-12-28 10:00:15,753 - tensorflow - INFO - loss = 0.7874867, step = 900 (34.760 sec)\n",
            "2021-12-28 10:00:15,756 - tensorflow - INFO - global_step/sec: 2.87687\n",
            "2021-12-28 10:00:15,758 - tensorflow - INFO - examples/sec: 92.06\n",
            "2021-12-28 10:00:15,761 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 10:00:15,762 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 10:00:28,184 - tensorflow - INFO - Saving checkpoints for 1000 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 10:00:49,886 - tensorflow - INFO - loss = 1.2941273, step = 1000 (34.133 sec)\n",
            "2021-12-28 10:00:49,889 - tensorflow - INFO - global_step/sec: 2.92968\n",
            "2021-12-28 10:00:49,891 - tensorflow - INFO - examples/sec: 93.7497\n",
            "2021-12-28 10:00:49,894 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 10:00:49,895 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n",
            "2021-12-28 10:01:02,409 - tensorflow - INFO - Saving checkpoints for 1100 into gs://theodore_jiang/bert_model_mrpc_trying_again/model.ckpt.\n",
            "2021-12-28 10:01:08,157 - tensorflow - INFO - Outfeed finished for iteration (10, 74)\n",
            "2021-12-28 10:01:23,440 - tensorflow - INFO - loss = 3.1501164, step = 1100 (33.554 sec)\n",
            "2021-12-28 10:01:23,443 - tensorflow - INFO - global_step/sec: 2.98032\n",
            "2021-12-28 10:01:23,444 - tensorflow - INFO - examples/sec: 95.3702\n",
            "2021-12-28 10:01:23,447 - tensorflow - INFO - Enqueue next (100) batch(es) of data to infeed.\n",
            "2021-12-28 10:01:23,448 - tensorflow - INFO - Dequeue next (100) batch(es) of data from outfeed.\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### IO config\n",
        "#@markdown Folder in GCS where the pretrained models needs to be loaded from:\n",
        "INIT_MODEL_DIR = \"pretrained_models\" #@param {type:\"string\"}\n",
        "#@markdown Name of the folder to the pretrained model to load from inside INIT_MODEL_DIR\n",
        "MODEL_NAME=\"MutFormer12L\" #@param {type:\"string\"}\n",
        "#@markdown Model architecture to use BertModel indicates the original BERT, BertModelModified indicates MutFormer's architecture\n",
        "MODEL_ARCHITECTURE = BertModelModified #@param\n",
        "#@markdown Folder for where to save the finetuned model\n",
        "OUTPUT_MODEL_DIR = \"bert_model_mrpc_trying_again\" #@param {type:\"string\"}\n",
        "#@markdown Which folder inside of LOGGING_DIR to store the logs in\n",
        "RUN_NAME = \"mutformer_trying_again\" #@param {type:\"string\"}\n",
        "#@markdown \\\n",
        "#@markdown \n",
        "#@markdown \n",
        "#@markdown ### Training procedure config\n",
        "#@markdown Batch size to use\n",
        "BATCH_SIZE = 32 #@param {type:\"integer\"}\n",
        "#@markdown Maximum sequence length to use\n",
        "MAX_SEQ_LENGTH = 512 #@param {type:\"integer\"}\n",
        "#@markdown Whether or not to resume training from a previous checkpoint; if no, always train from scratch\n",
        "RESUMING = False #@param {type:\"boolean\"}\n",
        "#@markdown Whether or not data was generated in shards (for really large databases)\n",
        "USING_SHARDS = False #@param {type:\"boolean\"}\n",
        "#@markdown * If using shards, which shard index to start at (defualt 0 for first shard)\n",
        "START_SHARD = 0 #@param {type:\"integer\"}\n",
        "#@markdown Training uses a linear learning rate.\n",
        "#@markdown * Start learning rate: training will start with this learning rate on the step that learning rate warmup is complete\n",
        "INIT_LEARNING_RATE =  1e-5 #@param {type:\"number\"}\n",
        "#@markdown * End learning rate: training will alter the learning rate every step linearly so that it finishes with this learning rate on the last step.\n",
        "END_LEARNING_RATE = 1e-6 #@param {type:\"number\"}\n",
        "#@markdown How many steps during training to perform learning rate warmup for (start from learning rate 0 and increase to INIT_LEARNING_RATE): Set to 0 for no warmup.\n",
        "NUM_WARMUP_STEPS = 10 #@param {type:\"integer\"}\n",
        "#@markdown What weight decay value to use (MutFormer uses 0.01; a higher weight decay is more resistant to exploding gradients, but also limits the model's ability to learn)\n",
        "WEIGHT_DECAY = 0.01 #@param {type:\"number\"}\n",
        "#@markdown Save a checkpoint every this amount of steps:\n",
        "SAVE_CHECKPOINTS_STEPS =  100 #@param {type:\"integer\"}\n",
        "#@markdown TPUEstimator will keep this number of checkpoints at a time; older checkpoints will all be deleted:\n",
        "KEEP_N_CHECKPOINTS_AT_A_TIME =  100 #@param {type:\"integer\"}\n",
        "#@markdown How many sequences should the model train on before stopping:\n",
        "PLANNED_TOTAL_SEQUENCES_SEEN =  2e5 #@param {type:\"number\"}\n",
        "#@markdown How many steps should the model train for before stopping (number of total sequences trained on will depend on the batch size used). NOTE: PLANNED_TOTAL_STEPS will override PLANNED_TOTAL_SEQUENCES_SEEN; if using PLANNED_TOTAL_SEQUENCES_SEEN, set PLANNED_TOTAL_STEPS to -1 (PLANNED TOTAL STEPS will be based on the train batch size used, which can be specified later)\n",
        "PLANNED_TOTAL_STEPS = 10000 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "PLANNED_TOTAL_STEPS = PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS != -1 else PLANNED_TOTAL_SEQUENCES_SEEN//BATCH_SIZE\n",
        "DECAY_PER_STEP = (END_LEARNING_RATE-INIT_LEARNING_RATE)/(PLANNED_TOTAL_STEPS if PLANNED_TOTAL_STEPS!=-1 else PLANNED_TOTAL_SEQUENCES_SEEN/BATCH_SIZE) \n",
        "\n",
        "MODEL = MODEL_ARCHITECTURE\n",
        "INIT_CHECKPOINT_DIR = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME\n",
        "GCS_OUTPUT_MODEL_DIR = BUCKET_PATH+\"/\"+OUTPUT_MODEL_DIR\n",
        "DATA_GCS_DIR = BUCKET_PATH+\"/\"+PROCESSED_DATA_DIR+\"/\"+str(MAX_SEQ_LENGTH)\n",
        "\n",
        "GCS_LOGGING_DIR = BUCKET_PATH+\"/\"+LOGGING_DIR+\"/\"+RUN_NAME\n",
        "\n",
        "CONFIG_FILE = BUCKET_PATH+\"/\"+INIT_MODEL_DIR+\"/\"+MODEL_NAME+\"/config.json\"\n",
        "\n",
        "DATA_INFO = json.load(tf.gfile.Open(DATA_GCS_DIR+\"/info.json\"))   ##get the data info dictionary\n",
        "EX_DATA_NUM = DATA_INFO[\"ex_data_num\"] if USING_EX_DATA else 0\n",
        "\n",
        "training_loop(BATCH_SIZE,\n",
        "              RESUMING,\n",
        "              PLANNED_TOTAL_STEPS,\n",
        "              DECAY_PER_STEP,\n",
        "              MAX_SEQ_LENGTH,\n",
        "              MODEL_NAME,\n",
        "              MODEL,\n",
        "              INIT_CHECKPOINT_DIR,\n",
        "              GCS_OUTPUT_MODEL_DIR,\n",
        "              DATA_GCS_DIR,\n",
        "              USING_SHARDS,\n",
        "              START_SHARD,\n",
        "              USING_EX_DATA,\n",
        "              EX_DATA_NUM,\n",
        "              GCS_LOGGING_DIR,\n",
        "              CONFIG_FILE)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "SaNhPg7sG2DS",
        "WQ322RGr5ykF",
        "tswiJYA_qCUq"
      ],
      "machine_shape": "hm",
      "name": "Copy of mutformer_finetuning_benchmark(mrpc_ex_data_all_preds).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}