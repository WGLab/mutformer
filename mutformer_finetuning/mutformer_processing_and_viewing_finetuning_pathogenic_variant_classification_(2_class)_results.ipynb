{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mutformer_processing_and_viewing_finetuning_pathogenic_variant_classification_(2_class)_results.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I-x6AH2RVjm"
      },
      "source": [
        "#Viewing finetuning curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nznrpNrKapKZ"
      },
      "source": [
        "###Mount drive and Authenticate for GCP & Copy tfevents from GCS into drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWySbUNaPw38"
      },
      "source": [
        "from google.colab import auth,drive\n",
        "print(\"Mount drive:\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_PATH=\"/content/drive/My Drive\"\n",
        "import os\n",
        "print(\"Authenticate for GCS:\")\n",
        "auth.authenticate_user()\n",
        "\n",
        "BUCKET_NAME = \"theodore_jiang\" #@param{type:\"string\"}\n",
        "TFEVENTs_DESTINATION_PATH = \"/content/drive/My Drive\" #@param{type:\"string\"}\n",
        "\n",
        "runs = [\"mrpc_loss_spam_model_comparison_final\",\n",
        "        \"re_loss_spam_model_comparison_final\",\n",
        "        \"ner_loss_spam_model_comparison_final\"]\n",
        "\n",
        "for run in runs: ##This will copy all of the tfevent files from GCS into drive, and will also delete all of the files from GCS\n",
        "  cmd = \"gsutil -m cp -r \\\"gs://\"+BUCKET_NAME+\"/\"+run+\"\\\" \\\"\"+TFEVENTs_DESTINATION_PATH+\"\\\"\"\n",
        "  !{cmd}\n",
        "  cmd = \"gsutil -m rm -r \"+\"\\\"gs://\"+BUCKET_NAME+\"/\"+run+\"\\\"\"\n",
        "  !{cmd}\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnvbKLqVawMp"
      },
      "source": [
        "###Just mount drive (use this if you wish to only use existing tfevent files from drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZidFzKyqvU"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_PATH = \"/content/drive/My Drive\"\n",
        "TFEVENTs_DESTINATION_PATH = \"/content/drive/My Drive\" #@param{type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYQENqLQTuqM"
      },
      "source": [
        "###Obtain events from tfevents for finetuning graphs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wK8Nw9gA37E"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import defaultdict\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "runs = [\"mrpc_loss_spam_model_comparison_final\",\n",
        "        \"re_loss_spam_model_comparison_final\",\n",
        "        \"ner_loss_spam_model_comparison_final\"]\n",
        "\n",
        "#@markdown ######only the (skip)-th tfevent file will be considered (useful when amount of tfevent files is more than what is necessary for viewing curves) (if no tfevents should be skipped, set to 1)\n",
        "skip = 500 #@param {type:\"integer\"}\n",
        "\n",
        "def tabulate_events(dpath,out_dict = {}):\n",
        "    for dname in tqdm(os.listdir(dpath),\"converting to dict\"):\n",
        "        if \"tfevents\" not in dname:\n",
        "          continue\n",
        "        ea = EventAccumulator(os.path.join(dpath, dname)).Reload()\n",
        "        tags = ea.Tags()['scalars']\n",
        "\n",
        "        for tag in tags:\n",
        "            tag_values=[]\n",
        "            wall_time=[]\n",
        "            steps=[]\n",
        "\n",
        "            for event in ea.Scalars(tag):\n",
        "                 if event.step%skip==0 or \"eval\" in tag:\n",
        "                    try:\n",
        "                        out_dict[tag].append((event.step,event.value))\n",
        "                    except:\n",
        "                        out_dict[tag] = [(event.step,event.value)]\n",
        "    return out_dict\n",
        "\n",
        "graph_data = {}\n",
        "\n",
        "for run in runs:\n",
        "    for subrun in os.listdir(\"/content/drive/My Drive/\"+run):\n",
        "      if \"predictions\" in subrun:\n",
        "        continue\n",
        "      data = tabulate_events(\"/content/drive/My Drive/\"+run+\"/\"+subrun)\n",
        "      print(subrun,subrun.count(\"_\"))\n",
        "      for metric,datapoints in tqdm(data.items(),run+\"_\"+subrun):\n",
        "          try:\n",
        "              graph_data[metric][run+\"-\"+subrun].append(datapoints)\n",
        "          except:\n",
        "              try:\n",
        "                  graph_data[metric][subrun] = [datapoints]\n",
        "              except:\n",
        "                  graph_data[metric] = {}\n",
        "                  graph_data[metric][subrun] = [datapoints]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fmmecLvTp7S"
      },
      "source": [
        "###Plotting smoothed average curves using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw4p4eBN3YTW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import re\n",
        "\n",
        "#@markdown range of the local average for viewing training graphs (to disable local averaging, set it to 0)\n",
        "avg_range = 100 #@param {type:\"integer\"}\n",
        "#@markdown destination path for saving graphs (for no saving set to None)\n",
        "outfolder = DRIVE_PATH+\"/training graphs\" #@param\n",
        "\n",
        "if not os.path.exists(outfolder):\n",
        "  os.makedirs(outfolder)\n",
        "\n",
        "for metric,runs in graph_data.items():\n",
        "    if \"rando\" in metric:\n",
        "      continue\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(metric+\" graph\")\n",
        "    plt.xlabel(\"steps\")\n",
        "    plt.ylabel(metric)\n",
        "    for run,run_data in runs.items():\n",
        "        run_data = run_data[0]\n",
        "        steps = []\n",
        "        values = []\n",
        "        nan = 0\n",
        "        for datapt in run_data:\n",
        "            if not math.isnan(datapt[1]):\n",
        "                values.append(datapt[1])\n",
        "                steps.append(datapt[0])\n",
        "            else:\n",
        "                nan+=1\n",
        "        print(\"nan values:\",nan)\n",
        "        values = [x for _, x in sorted(zip(steps, values), key=lambda pair: pair[0])]\n",
        "\n",
        "        if \"eval\" in metric or avg_range == 0:\n",
        "          avged_values = values\n",
        "        else:\n",
        "          avged_values = [sum(values[max(n-avg_range,0):min(n+avg_range,len(values))])/len(values[max(n-avg_range,0):min(n+avg_range,len(values))]) for n,value in enumerate(values)]\n",
        "        steps = sorted(steps)\n",
        "        plt.plot(steps,avged_values,label=run)\n",
        "                \n",
        "    plt.legend()\n",
        "    if outfolder:\n",
        "      plt.savefig(outfolder+\"/\"+metric.replace(\"/\",\"_\")+\".png\")\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbXhWZ7tTm76"
      },
      "source": [
        "###Tensorboard viewing (If you wish to use tensorboard instead)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvVNtrI1cH-H"
      },
      "source": [
        "LOGS_DIR = \"/content/drive/My Drive\" #@param (type:\"string\")\n",
        "LOGS_DIR = \"\\\"\"+LOGS_DIR+\"\\\"\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $LOGS_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op5ZqhKaR5ir"
      },
      "source": [
        "#Predictions Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5KuZA6dR857"
      },
      "source": [
        "###Download prediction files from GCS (if used EVALUATE_WHILE_PREDICT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yey0qTh4R8ii"
      },
      "source": [
        "from google.colab import auth,drive\n",
        "print(\"Mount drive:\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_PATH=\"/content/drive/My Drive\"\n",
        "import os\n",
        "print(\"Authenticate for GCS:\")\n",
        "auth.authenticate_user()\n",
        "\n",
        "BUCKET_NAME = \"theodore_jiang\" #@param{type:\"string\"}\n",
        "#@markdown where to download the tfevent files into\n",
        "TFEVENTs_DESTINATION_PATH = \"/content/drive/My Drive\" #@param{type:\"string\"}\n",
        "\n",
        "runs = [\"ner_loss_spam_model_comparison_final_predictions\",\n",
        "        \"mrpc_loss_spam_model_comparison_final_predictions\"]\n",
        "\n",
        "for run in runs[1:]: ##This will copy all of the tfevent files from GCS into drive, and will also delete all of the files from GCS\n",
        "  cmd = \"gsutil -m cp -r \\\"gs://\"+BUCKET_NAME+\"/\"+run+\"\\\" \\\"\"+TFEVENTs_DESTINATION_PATH+\"\\\"\"\n",
        "  !{cmd}\n",
        "  cmd = \"gsutil -m rm -r \"+\"\\\"gs://\"+BUCKET_NAME+\"/\"+run+\"\\\"\"\n",
        "  !{cmd}\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWZpsjOcpgx-"
      },
      "source": [
        "###Convert tfevents into txts (if used EVALUATE_WHILE_PREDICT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eDrQ8MRpkP2"
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "runs = [\"ner_loss_spam_model_comparison_final_predictions\",\n",
        "        \"mrpc_loss_spam_model_comparison_final_predictions\"]\n",
        "\n",
        "\n",
        "def tabulate_events(dpath):\n",
        "    out_dict = {}\n",
        "    stepsa = []\n",
        "    for dname in os.listdir(dpath):\n",
        "      if \"tfevents\" not in dname:\n",
        "        continue\n",
        "      ea = EventAccumulator(os.path.join(dpath, dname)).Reload()\n",
        "      tags = ea.Tags()['scalars']\n",
        "\n",
        "      out = {}\n",
        "\n",
        "      for tag in tags:\n",
        "          steps=[]\n",
        "          \n",
        "          for event in ea.Scalars(tag):\n",
        "            if not event.step in steps:\n",
        "              steps.append(event.step)\n",
        "\n",
        "          for n,event in enumerate(ea.Scalars(tag)):\n",
        "            if event.step not in stepsa:\n",
        "              stepsa.append(event.step)\n",
        "            try:\n",
        "                out_dict[tag].append((event.value,n,event.step))\n",
        "            except:\n",
        "                out_dict[tag] = [(event.value,n,event.step)]\n",
        "    return out_dict\n",
        "\n",
        "graph_data = {}\n",
        "\n",
        "for run in runs:\n",
        "    for subrun in os.listdir(TFEVENTs_DESTINATION_PATH+\"/\"+run):\n",
        "      if not os.path.isdir(TFEVENTs_DESTINATION_PATH+\"/\"+run+\"/\"+subrun):\n",
        "        continue\n",
        "      data = tabulate_events(TFEVENTs_DESTINATION_PATH+\"/\"+run+\"/\"+subrun)\n",
        "      data_polished = {}\n",
        "      for k,v in data.items():\n",
        "        key=re.sub(\"\\_\\d+$\",\"\",k)\n",
        "        for value in v:\n",
        "          try:\n",
        "            data_polished[key].append(value)\n",
        "          except:\n",
        "            data_polished[key] = [value]\n",
        "      pred_probs = [x[0] for x in sorted(sorted(list(data_polished[\"probability\"]),key=lambda x:x[2]),key=lambda x:x[1])]\n",
        "      labels = [x[0] for x in sorted(sorted(list(data_polished[\"label\"]),key=lambda x:x[2]),key=lambda x:x[1])]\n",
        "      input_ids = [x[0] for x in sorted(sorted(list(data_polished[\"input_id\"]),key=lambda x:x[2]),key=lambda x:x[1])]\n",
        "\n",
        "      pred_probs = pred_probs[:min(len(input_ids),len(labels),len(pred_probs))]\n",
        "      labels = labels[:min(len(input_ids),len(labels),len(pred_probs))]\n",
        "      input_ids = input_ids[:min(len(input_ids),len(labels),len(pred_probs))]\n",
        "\n",
        "      with open(TFEVENTs_DESTINATION_PATH+\"/\"+run+\"/\"+subrun+\"_predictions.txt\",\"w+\") as out:\n",
        "        for n,prob in enumerate(tqdm(pred_probs,run+\"_\"+subrun)):\n",
        "          out.write(\"probabilities:\"+str(prob)+\"\\t\"+\n",
        "                    \"labels:\"+str(labels[n])+\"\\t\"+\n",
        "                    \"input_ids:\"+str(input_ids[n])+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEKO9DHZvgYY"
      },
      "source": [
        "###Just Mount drive (if not used EVALUATE_WHILE_PREDICT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j1rIYPrvcOg"
      },
      "source": [
        "from google.colab import drive,auth\n",
        "import os\n",
        "import shutil\n",
        "!fusermount -u /content/drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "TFEVENTs_DESTINATION_PATH = \"/content/drive/My Drive\"\n",
        "DRIVE_PATH = \"/content/drive/My Drive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLZ-4p3-3lwU"
      },
      "source": [
        "###Plot ROC Curves using txts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OLsc3mH3pKN"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "runs = [\"ner_loss_spam_model_comparison_final_predictions\",  ## where the predictions were stored (should match up with \n",
        "        \"mrpc_loss_spam_model_comparison_final_predictions\",\n",
        "        \"re_loss_spam_model_comparison_final_predictions\"]  ## the PREDICTIONS_FOLDER parameter in the eval script)\n",
        "#@markdown destination path for saving ROC curves (for no saving set to None)\n",
        "outfolder = DRIVE_PATH+\"/ROC curves final\" #@param\n",
        "if outfolder and not os.path.exists(outfolder):\n",
        "  os.makedirs(outfolder)\n",
        "\n",
        "AUCs = {}\n",
        "for run in runs:\n",
        "  plt.figure(figsize=(20,10))\n",
        "  for subrun in os.listdir(TFEVENTs_DESTINATION_PATH+\"/\"+run):\n",
        "    \n",
        "    labels = []\n",
        "    pred_probs = []\n",
        "    tp=0\n",
        "    tn=0\n",
        "    fp=0\n",
        "    fn=0\n",
        "    if os.path.isdir(TFEVENTs_DESTINATION_PATH+\"/\"+run+\"/\"+subrun):\n",
        "      continue\n",
        "    print(\"Stats for:\",subrun,\"\\n\")\n",
        "\n",
        "    for n,line in enumerate(open(TFEVENTs_DESTINATION_PATH+\"/\"+run+\"/\"+subrun).read().split(\"\\n\")):\n",
        "      line_dict = {}\n",
        "      try:\n",
        "        for item in line.split(\"\\t\"):\n",
        "            line_dict[item.split(\":\")[0]] = item.split(\":\")[1]\n",
        "        label = float(line_dict[\"labels\"])\n",
        "        pred = float(line_dict[\"probabilities\"])\n",
        "        pred_probs.append(pred)\n",
        "        labels.append(label)\n",
        "        if label == 1 and pred>0.5:\n",
        "          tp+=1\n",
        "        elif label == 0 and pred<0.5:\n",
        "          tn+=1\n",
        "        elif label == 0 and pred>0.5:\n",
        "          fp+=1\n",
        "        elif label == 1 and pred<0.5:\n",
        "          fn+=1\n",
        "      except Exception as e:\n",
        "        print(e,line,n)\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "      acc = (tp+tn)/(tp+tn+fp+fn)\n",
        "      recall = tp/(tp+fn)\n",
        "      precision = tp/(tp+fp)\n",
        "      f1 = 2*precision*recall/(precision+recall)\n",
        "      pred_auc = roc_auc_score(labels, pred_probs)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    print(\"tp:\",tp,\n",
        "          \"tn:\",tn,\n",
        "          \"fp:\",fp,\n",
        "          \"fn:\",fn)\n",
        "    print(\"acc:\",acc)\n",
        "    print(\"recall_total:\",recall)\n",
        "    print(\"precision_total:\",precision)\n",
        "    print(\"f1_total:\",f1,\"\\n\")\n",
        "\n",
        "    # summarize scores\n",
        "    # calculate roc curves\n",
        "    pred_fpr, pred_tpr, _ = roc_curve(labels, pred_probs)\n",
        "    # plot the roc curve for the model\n",
        "    plt.plot(pred_fpr, pred_tpr, linestyle=\"-\", label=subrun+': Area under curve: '+str(round(pred_auc,3)))\n",
        "    # axis labels\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    # show the legend\n",
        "    plt.legend()\n",
        "    # show the plot\n",
        "    AUCs[subrun] = round(pred_auc,3)\n",
        "  plt.title(\"ROC for: \"+run)\n",
        "  if outfolder:\n",
        "      plt.savefig(outfolder+\"/\"+run.replace(\".txt\",\".png\"))\n",
        "  plt.show()\n",
        "\n",
        "AUCs = {k:v for k,v in sorted([(k,v) for k,v in AUCs.items()],key=lambda x:x[1])}\n",
        "print(\"Printing all AUCs...\")\n",
        "for k,v in AUCs.items():\n",
        "  print(\"model:\",k,\"\\tAUC:\",v)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}